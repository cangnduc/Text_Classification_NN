{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from langid.langid import LanguageIdentifier, model\n",
    "import time\n",
    "import numpy as np\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_path(folder_path):\n",
    "    examples = []\n",
    "    for label in os.listdir(folder_path):\n",
    "        full_path = os.path.join(folder_path, label)\n",
    "        for file_name in os.listdir(full_path):\n",
    "            file_path = os.path.join(full_path, file_name)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                lines = f.readlines()\n",
    "            sentence = \" \".join(lines)\n",
    "            if label == \"neg\":\n",
    "                label = 0\n",
    "            if label == \"pos\":\n",
    "                label = 1\n",
    "            data = {\n",
    "                'sentence': sentence,\n",
    "                'label': label\n",
    "            }\n",
    "            examples.append(data)\n",
    "    return pd.DataFrame(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = {\n",
    "    'train': './data_train/train',\n",
    "    'valid': './data_train/test',\n",
    "    'test': './data_test/test'\n",
    "}\n",
    "\n",
    "train_df = load_data_from_path(folder_paths['train'])\n",
    "valid_df = load_data_from_path(folder_paths['valid'])\n",
    "test_df = load_data_from_path(folder_paths['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mua c√≥ m·ªói Bingsu th·∫≠p_c·∫©m 45k m√† m√¨nh f ƒë·ª£i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th·ª© 6 n√†o ta c√πng qu·∫©y üí£ üí£ üí£\\n Vuvuzela beer c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M√¨nh ƒëi v·ªõi nh√≥m , t·ªïng_c·ªông 4 ng∆∞·ªùi ƒÉn ch·ªâ c√≥...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nh√¢n_vi√™n ph·ª•c_v·ª• kh√¥ng m·∫•y t·∫≠n_t√¨nh , ƒë·ªì_ƒÉn r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V√†o ƒë√¢y th√¨ h·∫øt b√†n , nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0  Mua c√≥ m·ªói Bingsu th·∫≠p_c·∫©m 45k m√† m√¨nh f ƒë·ª£i h...      0\n",
       "1  Th·ª© 6 n√†o ta c√πng qu·∫©y üí£ üí£ üí£\\n Vuvuzela beer c...      0\n",
       "2  M√¨nh ƒëi v·ªõi nh√≥m , t·ªïng_c·ªông 4 ng∆∞·ªùi ƒÉn ch·ªâ c√≥...      0\n",
       "3  nh√¢n_vi√™n ph·ª•c_v·ª• kh√¥ng m·∫•y t·∫≠n_t√¨nh , ƒë·ªì_ƒÉn r...      0\n",
       "4  V√†o ƒë√¢y th√¨ h·∫øt b√†n , nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i ...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_vn(df):\n",
    "    identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)\n",
    "    not_vi_idx = set()\n",
    "    THRESHOLD = 0.9\n",
    "    for idx, row in df.iterrows():\n",
    "        score = identifier.classify(row[\"sentence\"])\n",
    "        if score[0] != \"vi\" or (score[0] == \"vi\" and score[1] <= THRESHOLD):\n",
    "            not_vi_idx.add(idx)\n",
    "    vi_df = df[~df.index.isin(not_vi_idx)]\n",
    "    not_vi_df = df[df.index.isin(not_vi_idx)]\n",
    "    return vi_df, not_vi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    url_pattern = re.compile(r'https?://\\s+\\wwww\\.\\s+')\n",
    "    text = url_pattern.sub(r\" \", text)\n",
    "\n",
    "    html_pattern = re.compile(r'<[^<>]+>')\n",
    "    text = html_pattern.sub(\" \", text)\n",
    "\n",
    "    replace_chars = list(string.punctuation + string.digits)\n",
    "    for char in replace_chars:\n",
    "        text = text.replace(char, \" \")\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "                               u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "                               u\"\\U0001F600-\\U0001F64F\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U0001F1F2\"\n",
    "                               u\"\\U0001F1F4\"\n",
    "                               u\"\\U0001F620\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r\" \", text)\n",
    "\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cang_\\AppData\\Local\\Temp\\ipykernel_3676\\1279447063.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df_vi.loc[:, 'preprocess_sentence'] = train_df_vi['sentence'].apply(\n",
      "C:\\Users\\cang_\\AppData\\Local\\Temp\\ipykernel_3676\\1279447063.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_df_vi.loc[:, 'preprocess_sentence'] = valid_df_vi['sentence'].apply(\n",
      "C:\\Users\\cang_\\AppData\\Local\\Temp\\ipykernel_3676\\1279447063.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_vi.loc[:, 'preprocess_sentence'] = test_df_vi['sentence'].apply(\n"
     ]
    }
   ],
   "source": [
    "train_df_vi, train_df_other = identify_vn(train_df)\n",
    "\n",
    "train_df_vi.loc[:, 'preprocess_sentence'] = train_df_vi['sentence'].apply(\n",
    "    preprocess_text)\n",
    "valid_df_vi, valid_df_other = identify_vn(valid_df)\n",
    "valid_df_vi.loc[:, 'preprocess_sentence'] = valid_df_vi['sentence'].apply(\n",
    "    preprocess_text)\n",
    "test_df_vi, test_df_other = identify_vn(test_df)\n",
    "test_df_vi.loc[:, 'preprocess_sentence'] = test_df_vi['sentence'].apply(\n",
    "    preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocess_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mua c√≥ m·ªói Bingsu th·∫≠p_c·∫©m 45k m√† m√¨nh f ƒë·ª£i h...</td>\n",
       "      <td>0</td>\n",
       "      <td>mua c√≥ m·ªói bingsu th·∫≠p c·∫©m k m√† m√¨nh f ƒë·ª£i h∆°n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th·ª© 6 n√†o ta c√πng qu·∫©y üí£ üí£ üí£\\n Vuvuzela beer c...</td>\n",
       "      <td>0</td>\n",
       "      <td>th·ª© n√†o ta c√πng qu·∫©y vuvuzela beer club chung ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M√¨nh ƒëi v·ªõi nh√≥m , t·ªïng_c·ªông 4 ng∆∞·ªùi ƒÉn ch·ªâ c√≥...</td>\n",
       "      <td>0</td>\n",
       "      <td>m√¨nh ƒëi v·ªõi nh√≥m t·ªïng c·ªông ng∆∞·ªùi ƒÉn ch·ªâ c√≥ kh√¥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nh√¢n_vi√™n ph·ª•c_v·ª• kh√¥ng m·∫•y t·∫≠n_t√¨nh , ƒë·ªì_ƒÉn r...</td>\n",
       "      <td>0</td>\n",
       "      <td>nh√¢n vi√™n ph·ª•c v·ª• kh√¥ng m·∫•y t·∫≠n t√¨nh ƒë·ªì ƒÉn ra ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V√†o ƒë√¢y th√¨ h·∫øt b√†n , nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>v√†o ƒë√¢y th√¨ h·∫øt b√†n nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i b√¨...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  \\\n",
       "0  Mua c√≥ m·ªói Bingsu th·∫≠p_c·∫©m 45k m√† m√¨nh f ƒë·ª£i h...      0   \n",
       "1  Th·ª© 6 n√†o ta c√πng qu·∫©y üí£ üí£ üí£\\n Vuvuzela beer c...      0   \n",
       "2  M√¨nh ƒëi v·ªõi nh√≥m , t·ªïng_c·ªông 4 ng∆∞·ªùi ƒÉn ch·ªâ c√≥...      0   \n",
       "3  nh√¢n_vi√™n ph·ª•c_v·ª• kh√¥ng m·∫•y t·∫≠n_t√¨nh , ƒë·ªì_ƒÉn r...      0   \n",
       "4  V√†o ƒë√¢y th√¨ h·∫øt b√†n , nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i ...      0   \n",
       "\n",
       "                                 preprocess_sentence  \n",
       "0  mua c√≥ m·ªói bingsu th·∫≠p c·∫©m k m√† m√¨nh f ƒë·ª£i h∆°n...  \n",
       "1  th·ª© n√†o ta c√πng qu·∫©y vuvuzela beer club chung ...  \n",
       "2  m√¨nh ƒëi v·ªõi nh√≥m t·ªïng c·ªông ng∆∞·ªùi ƒÉn ch·ªâ c√≥ kh√¥...  \n",
       "3  nh√¢n vi√™n ph·ª•c v·ª• kh√¥ng m·∫•y t·∫≠n t√¨nh ƒë·ªì ƒÉn ra ...  \n",
       "4  v√†o ƒë√¢y th√¨ h·∫øt b√†n nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i b√¨...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_vi[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.07200026903416"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(x.split()) for x in train_df_vi['preprocess_sentence']]) / \\\n",
    "    len(train_df_vi['preprocess_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_has = [torch.tensor([hash(word) % 15000 for word in review.split()])\n",
    "                for review in train_df_vi['preprocess_sentence']]\n",
    "valid_df_has = [torch.tensor([hash(word) % 15000 for word in review.split()])\n",
    "                for review in valid_df_vi['preprocess_sentence']]\n",
    "test_df_has = [torch.tensor([hash(word) % 15000 for word in review.split()])\n",
    "               for review in test_df_vi['preprocess_sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(\n",
    "    train_df,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_df,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14028,  5557, 11241,  5681,  2405,  5207,  4925,  9507,  2430,   640,\n",
      "         10430, 12785,  2102, 10244, 14010,  3303,  1200,  5557, 12121,  2463,\n",
      "          8304,  6629,  1943,  9921,  9224, 11232, 10082,  6664,  2430,  4925,\n",
      "         14984,  5557,  7108,  4925,  2463,  7307, 13356,  7094,   891,  2943,\n",
      "          7492,  3303,  2817,  4183,  3032, 10244, 11106,  7965,  8028,   662,\n",
      "         13018,  9241,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [10049, 14004,   641,  1348, 14378,  5973, 14061, 14799, 12699,  7582,\n",
      "          4596,  2578,  5448,  1560, 10774, 10774,  4183, 11055,  7307, 12916,\n",
      "         14534, 10204,    35,  5794,  8421,  6840,  9493,   820,  9983,  7323,\n",
      "          7094, 14949,  3029,   820,  9983,  7307,  7020,  8807, 14974,  9043,\n",
      "          7307,  5190,  7323,  7094,  7307, 11250,  5557,  6121, 12570,  9033,\n",
      "         14044,   684, 13725,  3314,  9349,  6338, 14004,  7714,  4183, 11196,\n",
      "         10565,  7094,  4304,  9507,  7315,  6121, 12570, 11521,  7307, 10762,\n",
      "          5557,  8730,  3091, 11530,  8811, 10310, 11045,  9033, 11265, 11530,\n",
      "          8811,  9507,  8941, 13881,  6358,  9967,   523,  8811,   557,  9967],\n",
      "        [ 2430, 10181, 10958,   978, 11289,  7384,   982,  7094,  6358,  5557,\n",
      "           557, 11560,  4925,  9507,  4004, 10683, 14146,  8255, 11265, 13414,\n",
      "          7010,  2610, 10111,  8730, 10111, 10093, 10958,   430,  6642, 11370,\n",
      "          5627,  4617, 11646, 10683,  7663,  5557,  4925, 11074,  4789,  6145,\n",
      "          4925,  7127,  8772, 10804,  5627,  4617, 12699, 11370,  1943,  4925,\n",
      "          5627,  4617,  1943,  4925,  9921, 11646,  7094,  9069,  4816, 11260,\n",
      "          7094,  1096, 12967,  7884, 12526,  4119, 13876,   329, 12597,  2430,\n",
      "          9967,  7970,   825,   557,  7108,  6957, 11484,  5557,    99, 14322,\n",
      "          7094, 11287, 11287, 13414, 14010,  8699,  3632,  7573,  7663,  2610],\n",
      "        [ 1929, 11180,  4681, 12521,   557,  6121,  9391,  4033, 11646,  7094,\n",
      "          3029,  1583,  8028,   557, 14673, 12570, 12209,  8085, 10277,  2610,\n",
      "          7108, 10970, 11093,  7069,  9204,   557,  5281,  7108, 12526, 12961,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 7108, 10565, 14010,  1556,  4500,  6653,  2430,  3763,  8807, 10430,\n",
      "         12979,  6188,  7127,  1929, 11180, 12765,  4500, 12591,  9088, 12765,\n",
      "          1483,  2604, 12526, 12437,  9241,  6543,  7108,  8807, 10970,  2430,\n",
      "         14010,  6964, 11196, 10310,  9144, 13402,  2430,  1405,  4968,  5201,\n",
      "          7016, 11542,  3029, 13912,  2817,  5557, 11682, 13568,  2430, 10181,\n",
      "          2430,  4183,  2604,  5308,  3949,   978, 14242,   982, 13568,  1533,\n",
      "         12743,  9507,  3032,  6188,  9241,  4681, 12521,  8028,  3732, 11106,\n",
      "          5677, 14869,  3632, 12313,  9171, 12916,  7094,  6653, 14794,  5557,\n",
      "          7108, 14010, 10958, 11106,  5962, 13490,  6819,  3682, 14010,  2430]])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "MAX_LENGTH = 90\n",
    "train_df_pad = pad_sequence(\n",
    "    train_df_has, batch_first=True, padding_value=0).narrow(1, 0, MAX_LENGTH)\n",
    "valid_df_pad = pad_sequence(\n",
    "    valid_df_has, batch_first=True, padding_value=0).narrow(1, 0, MAX_LENGTH)\n",
    "test_df_pad = pad_sequence(\n",
    "    test_df_has, batch_first=True, padding_value=0).narrow(1, 0, MAX_LENGTH)\n",
    "\n",
    "print(train_df_pad[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = torch.tensor(train_df_vi['label'].values)\n",
    "valid_label = torch.tensor(valid_df_vi['label'].values)\n",
    "test_label = torch.tensor(test_df_vi['label'].values)\n",
    "# get the 5 items from train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.utils.data.TensorDataset(train_df_pad, train_label)\n",
    "valid_data = torch.utils.data.TensorDataset(valid_df_pad, valid_label)\n",
    "test_data = torch.utils.data.TensorDataset(test_df_pad, test_label)\n",
    "# move train_data to device\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(valid_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class, seq_len):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.ft = torch.nn.Linear(MAX_LENGTH * embed_dim, MAX_LENGTH * embed_dim)\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.ft2 = torch.nn.Linear(MAX_LENGTH * embed_dim, num_class)\n",
    "        # self.out = torch.nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.ft.weight.data.uniform_(-initrange, initrange)\n",
    "        self.ft.bias.data.zero_()\n",
    "        self.ft2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.ft2.bias.data.zero_()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embedded = self.embedding(inputs)\n",
    "        x = torch.nn.Flatten()(embedded)\n",
    "        #x = self.ft(x)\n",
    "        #x = self.elu(x)\n",
    "        x = self.ft2(x)\n",
    "        x = self.dropout(x)\n",
    "        #x = self.simoid(x)\n",
    "        # x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 15000\n",
    "embed_dim = 100\n",
    "num_class = 2\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "model = TextClassificationModel(\n",
    "    vocab_size, embed_dim, num_class, MAX_LENGTH).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss, train_dataloader, epoch=0, log_interval=50):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs)\n",
    "        \n",
    "        # compute loss\n",
    "        loss_value = loss(predictions, labels)\n",
    "        losses.append(loss_value.item())\n",
    "\n",
    "        # backward\n",
    "        loss_value.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "        total_count += labels.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(train_dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, valid_dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(valid_dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            predictions = model(inputs)\n",
    "            \n",
    "            loss = criterion(predictions, labels)\n",
    "            losses.append(loss.item())\n",
    "           \n",
    "            total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  233 batches | accuracy    0.577\n",
      "| epoch   1 |   100/  233 batches | accuracy    0.644\n",
      "| epoch   1 |   150/  233 batches | accuracy    0.649\n",
      "| epoch   1 |   200/  233 batches | accuracy    0.671\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 10.16s | valid accuracy    0.758 | valid loss    0.543\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   2 |    50/  233 batches | accuracy    0.830\n",
      "| epoch   2 |   100/  233 batches | accuracy    0.830\n",
      "| epoch   2 |   150/  233 batches | accuracy    0.827\n",
      "| epoch   2 |   200/  233 batches | accuracy    0.840\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  9.04s | valid accuracy    0.757 | valid loss    0.654\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   3 |    50/  233 batches | accuracy    0.884\n",
      "| epoch   3 |   100/  233 batches | accuracy    0.894\n",
      "| epoch   3 |   150/  233 batches | accuracy    0.899\n",
      "| epoch   3 |   200/  233 batches | accuracy    0.895\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  9.18s | valid accuracy    0.781 | valid loss    0.717\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   4 |    50/  233 batches | accuracy    0.926\n",
      "| epoch   4 |   100/  233 batches | accuracy    0.920\n",
      "| epoch   4 |   150/  233 batches | accuracy    0.924\n",
      "| epoch   4 |   200/  233 batches | accuracy    0.928\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time:  9.75s | valid accuracy    0.789 | valid loss    0.823\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   5 |    50/  233 batches | accuracy    0.942\n",
      "| epoch   5 |   100/  233 batches | accuracy    0.943\n",
      "| epoch   5 |   150/  233 batches | accuracy    0.942\n",
      "| epoch   5 |   200/  233 batches | accuracy    0.942\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 10.64s | valid accuracy    0.811 | valid loss    0.908\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   6 |    50/  233 batches | accuracy    0.954\n",
      "| epoch   6 |   100/  233 batches | accuracy    0.948\n",
      "| epoch   6 |   150/  233 batches | accuracy    0.953\n",
      "| epoch   6 |   200/  233 batches | accuracy    0.947\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 11.66s | valid accuracy    0.800 | valid loss    1.013\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   7 |    50/  233 batches | accuracy    0.959\n",
      "| epoch   7 |   100/  233 batches | accuracy    0.959\n",
      "| epoch   7 |   150/  233 batches | accuracy    0.964\n",
      "| epoch   7 |   200/  233 batches | accuracy    0.964\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 13.23s | valid accuracy    0.807 | valid loss    1.207\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   8 |    50/  233 batches | accuracy    0.972\n",
      "| epoch   8 |   100/  233 batches | accuracy    0.972\n",
      "| epoch   8 |   150/  233 batches | accuracy    0.967\n",
      "| epoch   8 |   200/  233 batches | accuracy    0.969\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 14.38s | valid accuracy    0.800 | valid loss    1.404\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   9 |    50/  233 batches | accuracy    0.972\n",
      "| epoch   9 |   100/  233 batches | accuracy    0.966\n",
      "| epoch   9 |   150/  233 batches | accuracy    0.960\n",
      "| epoch   9 |   200/  233 batches | accuracy    0.961\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 15.04s | valid accuracy    0.789 | valid loss    1.268\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  10 |    50/  233 batches | accuracy    0.964\n",
      "| epoch  10 |   100/  233 batches | accuracy    0.957\n",
      "| epoch  10 |   150/  233 batches | accuracy    0.963\n",
      "| epoch  10 |   200/  233 batches | accuracy    0.953\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 14.53s | valid accuracy    0.799 | valid loss    1.345\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  11 |    50/  233 batches | accuracy    0.959\n",
      "| epoch  11 |   100/  233 batches | accuracy    0.948\n",
      "| epoch  11 |   150/  233 batches | accuracy    0.948\n",
      "| epoch  11 |   200/  233 batches | accuracy    0.937\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 15.66s | valid accuracy    0.800 | valid loss    1.468\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  12 |    50/  233 batches | accuracy    0.956\n",
      "| epoch  12 |   100/  233 batches | accuracy    0.957\n",
      "| epoch  12 |   150/  233 batches | accuracy    0.948\n",
      "| epoch  12 |   200/  233 batches | accuracy    0.941\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 16.42s | valid accuracy    0.802 | valid loss    1.301\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  13 |    50/  233 batches | accuracy    0.955\n",
      "| epoch  13 |   100/  233 batches | accuracy    0.958\n",
      "| epoch  13 |   150/  233 batches | accuracy    0.952\n",
      "| epoch  13 |   200/  233 batches | accuracy    0.947\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 18.84s | valid accuracy    0.805 | valid loss    1.406\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  14 |    50/  233 batches | accuracy    0.961\n",
      "| epoch  14 |   100/  233 batches | accuracy    0.963\n",
      "| epoch  14 |   150/  233 batches | accuracy    0.956\n",
      "| epoch  14 |   200/  233 batches | accuracy    0.955\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 22.28s | valid accuracy    0.810 | valid loss    1.631\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  15 |    50/  233 batches | accuracy    0.963\n",
      "| epoch  15 |   100/  233 batches | accuracy    0.966\n",
      "| epoch  15 |   150/  233 batches | accuracy    0.963\n",
      "| epoch  15 |   200/  233 batches | accuracy    0.962\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 25.90s | valid accuracy    0.808 | valid loss    1.602\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  16 |    50/  233 batches | accuracy    0.965\n",
      "| epoch  16 |   100/  233 batches | accuracy    0.970\n",
      "| epoch  16 |   150/  233 batches | accuracy    0.964\n",
      "| epoch  16 |   200/  233 batches | accuracy    0.956\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 29.87s | valid accuracy    0.804 | valid loss    2.008\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  17 |    50/  233 batches | accuracy    0.959\n",
      "| epoch  17 |   100/  233 batches | accuracy    0.954\n",
      "| epoch  17 |   150/  233 batches | accuracy    0.961\n",
      "| epoch  17 |   200/  233 batches | accuracy    0.958\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 34.05s | valid accuracy    0.796 | valid loss    1.752\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  18 |    50/  233 batches | accuracy    0.957\n",
      "| epoch  18 |   100/  233 batches | accuracy    0.952\n",
      "| epoch  18 |   150/  233 batches | accuracy    0.954\n",
      "| epoch  18 |   200/  233 batches | accuracy    0.950\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 36.34s | valid accuracy    0.810 | valid loss    1.719\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  19 |    50/  233 batches | accuracy    0.959\n",
      "| epoch  19 |   100/  233 batches | accuracy    0.953\n",
      "| epoch  19 |   150/  233 batches | accuracy    0.951\n",
      "| epoch  19 |   200/  233 batches | accuracy    0.950\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 41.57s | valid accuracy    0.816 | valid loss    1.858\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  20 |    50/  233 batches | accuracy    0.965\n",
      "| epoch  20 |   100/  233 batches | accuracy    0.962\n",
      "| epoch  20 |   150/  233 batches | accuracy    0.956\n",
      "| epoch  20 |   200/  233 batches | accuracy    0.958\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 42.75s | valid accuracy    0.788 | valid loss    2.418\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  21 |    50/  233 batches | accuracy    0.954\n",
      "| epoch  21 |   100/  233 batches | accuracy    0.956\n",
      "| epoch  21 |   150/  233 batches | accuracy    0.944\n",
      "| epoch  21 |   200/  233 batches | accuracy    0.946\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 42.17s | valid accuracy    0.818 | valid loss    2.169\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  22 |    50/  233 batches | accuracy    0.957\n",
      "| epoch  22 |   100/  233 batches | accuracy    0.960\n",
      "| epoch  22 |   150/  233 batches | accuracy    0.956\n",
      "| epoch  22 |   200/  233 batches | accuracy    0.957\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 41.40s | valid accuracy    0.806 | valid loss    2.071\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  23 |    50/  233 batches | accuracy    0.962\n",
      "| epoch  23 |   100/  233 batches | accuracy    0.963\n",
      "| epoch  23 |   150/  233 batches | accuracy    0.956\n",
      "| epoch  23 |   200/  233 batches | accuracy    0.955\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 35.75s | valid accuracy    0.805 | valid loss    3.299\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  24 |    50/  233 batches | accuracy    0.967\n",
      "| epoch  24 |   100/  233 batches | accuracy    0.967\n",
      "| epoch  24 |   150/  233 batches | accuracy    0.966\n",
      "| epoch  24 |   200/  233 batches | accuracy    0.965\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 29.25s | valid accuracy    0.815 | valid loss    3.365\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  25 |    50/  233 batches | accuracy    0.965\n",
      "| epoch  25 |   100/  233 batches | accuracy    0.966\n",
      "| epoch  25 |   150/  233 batches | accuracy    0.967\n",
      "| epoch  25 |   200/  233 batches | accuracy    0.964\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 26.91s | valid accuracy    0.810 | valid loss    3.919\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  26 |    50/  233 batches | accuracy    0.970\n",
      "| epoch  26 |   100/  233 batches | accuracy    0.972\n",
      "| epoch  26 |   150/  233 batches | accuracy    0.968\n",
      "| epoch  26 |   200/  233 batches | accuracy    0.963\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 25.32s | valid accuracy    0.820 | valid loss    3.210\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  27 |    50/  233 batches | accuracy    0.970\n",
      "| epoch  27 |   100/  233 batches | accuracy    0.972\n",
      "| epoch  27 |   150/  233 batches | accuracy    0.971\n",
      "| epoch  27 |   200/  233 batches | accuracy    0.965\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 22.71s | valid accuracy    0.805 | valid loss    3.905\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  28 |    50/  233 batches | accuracy    0.969\n",
      "| epoch  28 |   100/  233 batches | accuracy    0.965\n",
      "| epoch  28 |   150/  233 batches | accuracy    0.963\n",
      "| epoch  28 |   200/  233 batches | accuracy    0.960\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 20.69s | valid accuracy    0.816 | valid loss    3.881\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  29 |    50/  233 batches | accuracy    0.964\n",
      "| epoch  29 |   100/  233 batches | accuracy    0.963\n",
      "| epoch  29 |   150/  233 batches | accuracy    0.968\n",
      "| epoch  29 |   200/  233 batches | accuracy    0.958\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 20.57s | valid accuracy    0.808 | valid loss    3.225\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  30 |    50/  233 batches | accuracy    0.971\n",
      "| epoch  30 |   100/  233 batches | accuracy    0.964\n",
      "| epoch  30 |   150/  233 batches | accuracy    0.968\n",
      "| epoch  30 |   200/  233 batches | accuracy    0.964\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 19.62s | valid accuracy    0.817 | valid loss    5.137\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  31 |    50/  233 batches | accuracy    0.965\n",
      "| epoch  31 |   100/  233 batches | accuracy    0.958\n",
      "| epoch  31 |   150/  233 batches | accuracy    0.954\n",
      "| epoch  31 |   200/  233 batches | accuracy    0.955\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 16.03s | valid accuracy    0.811 | valid loss    3.873\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  32 |    50/  233 batches | accuracy    0.969\n",
      "| epoch  32 |   100/  233 batches | accuracy    0.968\n",
      "| epoch  32 |   150/  233 batches | accuracy    0.965\n",
      "| epoch  32 |   200/  233 batches | accuracy    0.963\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 14.92s | valid accuracy    0.804 | valid loss    4.243\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  33 |    50/  233 batches | accuracy    0.970\n",
      "| epoch  33 |   100/  233 batches | accuracy    0.971\n",
      "| epoch  33 |   150/  233 batches | accuracy    0.967\n",
      "| epoch  33 |   200/  233 batches | accuracy    0.966\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 14.22s | valid accuracy    0.813 | valid loss    5.738\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  34 |    50/  233 batches | accuracy    0.965\n",
      "| epoch  34 |   100/  233 batches | accuracy    0.964\n",
      "| epoch  34 |   150/  233 batches | accuracy    0.965\n",
      "| epoch  34 |   200/  233 batches | accuracy    0.969\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 13.21s | valid accuracy    0.820 | valid loss    5.103\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  35 |    50/  233 batches | accuracy    0.969\n",
      "| epoch  35 |   100/  233 batches | accuracy    0.974\n",
      "| epoch  35 |   150/  233 batches | accuracy    0.971\n",
      "| epoch  35 |   200/  233 batches | accuracy    0.970\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 12.92s | valid accuracy    0.819 | valid loss    4.364\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  36 |    50/  233 batches | accuracy    0.973\n",
      "| epoch  36 |   100/  233 batches | accuracy    0.976\n",
      "| epoch  36 |   150/  233 batches | accuracy    0.971\n",
      "| epoch  36 |   200/  233 batches | accuracy    0.976\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 13.06s | valid accuracy    0.800 | valid loss    5.921\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  37 |    50/  233 batches | accuracy    0.973\n",
      "| epoch  37 |   100/  233 batches | accuracy    0.973\n",
      "| epoch  37 |   150/  233 batches | accuracy    0.972\n",
      "| epoch  37 |   200/  233 batches | accuracy    0.970\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 12.56s | valid accuracy    0.814 | valid loss    6.346\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  38 |    50/  233 batches | accuracy    0.974\n",
      "| epoch  38 |   100/  233 batches | accuracy    0.972\n",
      "| epoch  38 |   150/  233 batches | accuracy    0.970\n",
      "| epoch  38 |   200/  233 batches | accuracy    0.969\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 12.51s | valid accuracy    0.811 | valid loss    6.312\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  39 |    50/  233 batches | accuracy    0.971\n",
      "| epoch  39 |   100/  233 batches | accuracy    0.972\n",
      "| epoch  39 |   150/  233 batches | accuracy    0.968\n",
      "| epoch  39 |   200/  233 batches | accuracy    0.970\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 12.12s | valid accuracy    0.821 | valid loss    6.759\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  40 |    50/  233 batches | accuracy    0.970\n",
      "| epoch  40 |   100/  233 batches | accuracy    0.971\n",
      "| epoch  40 |   150/  233 batches | accuracy    0.970\n",
      "| epoch  40 |   200/  233 batches | accuracy    0.971\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 11.90s | valid accuracy    0.813 | valid loss    6.823\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  41 |    50/  233 batches | accuracy    0.968\n",
      "| epoch  41 |   100/  233 batches | accuracy    0.969\n",
      "| epoch  41 |   150/  233 batches | accuracy    0.974\n",
      "| epoch  41 |   200/  233 batches | accuracy    0.970\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 11.81s | valid accuracy    0.814 | valid loss    8.939\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  42 |    50/  233 batches | accuracy    0.970\n",
      "| epoch  42 |   100/  233 batches | accuracy    0.970\n",
      "| epoch  42 |   150/  233 batches | accuracy    0.971\n",
      "| epoch  42 |   200/  233 batches | accuracy    0.967\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 11.42s | valid accuracy    0.814 | valid loss    7.439\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  43 |    50/  233 batches | accuracy    0.969\n",
      "| epoch  43 |   100/  233 batches | accuracy    0.967\n",
      "| epoch  43 |   150/  233 batches | accuracy    0.968\n",
      "| epoch  43 |   200/  233 batches | accuracy    0.967\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 11.32s | valid accuracy    0.824 | valid loss    7.499\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  44 |    50/  233 batches | accuracy    0.968\n",
      "| epoch  44 |   100/  233 batches | accuracy    0.974\n",
      "| epoch  44 |   150/  233 batches | accuracy    0.973\n",
      "| epoch  44 |   200/  233 batches | accuracy    0.967\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 11.37s | valid accuracy    0.819 | valid loss    8.073\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  45 |    50/  233 batches | accuracy    0.968\n",
      "| epoch  45 |   100/  233 batches | accuracy    0.977\n",
      "| epoch  45 |   150/  233 batches | accuracy    0.969\n",
      "| epoch  45 |   200/  233 batches | accuracy    0.973\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 12.00s | valid accuracy    0.816 | valid loss    8.846\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  46 |    50/  233 batches | accuracy    0.973\n",
      "| epoch  46 |   100/  233 batches | accuracy    0.976\n",
      "| epoch  46 |   150/  233 batches | accuracy    0.973\n",
      "| epoch  46 |   200/  233 batches | accuracy    0.971\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 11.90s | valid accuracy    0.814 | valid loss    9.657\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  47 |    50/  233 batches | accuracy    0.972\n",
      "| epoch  47 |   100/  233 batches | accuracy    0.973\n",
      "| epoch  47 |   150/  233 batches | accuracy    0.971\n",
      "| epoch  47 |   200/  233 batches | accuracy    0.973\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 11.59s | valid accuracy    0.819 | valid loss    8.407\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  48 |    50/  233 batches | accuracy    0.975\n",
      "| epoch  48 |   100/  233 batches | accuracy    0.973\n",
      "| epoch  48 |   150/  233 batches | accuracy    0.972\n",
      "| epoch  48 |   200/  233 batches | accuracy    0.972\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 11.59s | valid accuracy    0.820 | valid loss    9.815\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  49 |    50/  233 batches | accuracy    0.979\n",
      "| epoch  49 |   100/  233 batches | accuracy    0.977\n",
      "| epoch  49 |   150/  233 batches | accuracy    0.974\n",
      "| epoch  49 |   200/  233 batches | accuracy    0.977\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 11.80s | valid accuracy    0.821 | valid loss    9.285\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  50 |    50/  233 batches | accuracy    0.982\n",
      "| epoch  50 |   100/  233 batches | accuracy    0.974\n",
      "| epoch  50 |   150/  233 batches | accuracy    0.977\n",
      "| epoch  50 |   200/  233 batches | accuracy    0.975\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 12.06s | valid accuracy    0.820 | valid loss    9.635\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  51 |    50/  233 batches | accuracy    0.977\n",
      "| epoch  51 |   100/  233 batches | accuracy    0.977\n",
      "| epoch  51 |   150/  233 batches | accuracy    0.973\n",
      "| epoch  51 |   200/  233 batches | accuracy    0.977\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time: 11.96s | valid accuracy    0.819 | valid loss    9.872\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  52 |    50/  233 batches | accuracy    0.978\n",
      "| epoch  52 |   100/  233 batches | accuracy    0.976\n",
      "| epoch  52 |   150/  233 batches | accuracy    0.973\n",
      "| epoch  52 |   200/  233 batches | accuracy    0.972\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time: 12.07s | valid accuracy    0.814 | valid loss    9.953\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  53 |    50/  233 batches | accuracy    0.975\n",
      "| epoch  53 |   100/  233 batches | accuracy    0.975\n",
      "| epoch  53 |   150/  233 batches | accuracy    0.972\n",
      "| epoch  53 |   200/  233 batches | accuracy    0.972\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time: 11.51s | valid accuracy    0.804 | valid loss    9.759\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  54 |    50/  233 batches | accuracy    0.975\n",
      "| epoch  54 |   100/  233 batches | accuracy    0.970\n",
      "| epoch  54 |   150/  233 batches | accuracy    0.970\n",
      "| epoch  54 |   200/  233 batches | accuracy    0.970\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time: 11.54s | valid accuracy    0.800 | valid loss   12.316\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  55 |    50/  233 batches | accuracy    0.971\n",
      "| epoch  55 |   100/  233 batches | accuracy    0.973\n",
      "| epoch  55 |   150/  233 batches | accuracy    0.973\n",
      "| epoch  55 |   200/  233 batches | accuracy    0.970\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time: 11.50s | valid accuracy    0.818 | valid loss   11.668\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  56 |    50/  233 batches | accuracy    0.971\n",
      "| epoch  56 |   100/  233 batches | accuracy    0.974\n",
      "| epoch  56 |   150/  233 batches | accuracy    0.971\n",
      "| epoch  56 |   200/  233 batches | accuracy    0.970\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time: 11.57s | valid accuracy    0.818 | valid loss   12.142\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  57 |    50/  233 batches | accuracy    0.970\n",
      "| epoch  57 |   100/  233 batches | accuracy    0.976\n",
      "| epoch  57 |   150/  233 batches | accuracy    0.971\n",
      "| epoch  57 |   200/  233 batches | accuracy    0.975\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time: 11.79s | valid accuracy    0.814 | valid loss   12.907\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  58 |    50/  233 batches | accuracy    0.968\n",
      "| epoch  58 |   100/  233 batches | accuracy    0.970\n",
      "| epoch  58 |   150/  233 batches | accuracy    0.971\n",
      "| epoch  58 |   200/  233 batches | accuracy    0.967\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time: 11.69s | valid accuracy    0.814 | valid loss   11.484\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  59 |    50/  233 batches | accuracy    0.975\n",
      "| epoch  59 |   100/  233 batches | accuracy    0.975\n",
      "| epoch  59 |   150/  233 batches | accuracy    0.970\n",
      "| epoch  59 |   200/  233 batches | accuracy    0.971\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time: 12.02s | valid accuracy    0.819 | valid loss   12.637\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  60 |    50/  233 batches | accuracy    0.976\n",
      "| epoch  60 |   100/  233 batches | accuracy    0.973\n",
      "| epoch  60 |   150/  233 batches | accuracy    0.977\n",
      "| epoch  60 |   200/  233 batches | accuracy    0.975\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time: 12.47s | valid accuracy    0.816 | valid loss   12.453\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  61 |    50/  233 batches | accuracy    0.977\n",
      "| epoch  61 |   100/  233 batches | accuracy    0.978\n",
      "| epoch  61 |   150/  233 batches | accuracy    0.976\n",
      "| epoch  61 |   200/  233 batches | accuracy    0.971\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time: 12.47s | valid accuracy    0.807 | valid loss   15.088\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  62 |    50/  233 batches | accuracy    0.972\n",
      "| epoch  62 |   100/  233 batches | accuracy    0.976\n",
      "| epoch  62 |   150/  233 batches | accuracy    0.977\n",
      "| epoch  62 |   200/  233 batches | accuracy    0.974\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time: 12.68s | valid accuracy    0.820 | valid loss   13.626\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  63 |    50/  233 batches | accuracy    0.974\n",
      "| epoch  63 |   100/  233 batches | accuracy    0.975\n",
      "| epoch  63 |   150/  233 batches | accuracy    0.973\n",
      "| epoch  63 |   200/  233 batches | accuracy    0.971\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time: 12.45s | valid accuracy    0.823 | valid loss   13.299\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  64 |    50/  233 batches | accuracy    0.978\n",
      "| epoch  64 |   100/  233 batches | accuracy    0.977\n",
      "| epoch  64 |   150/  233 batches | accuracy    0.977\n",
      "| epoch  64 |   200/  233 batches | accuracy    0.978\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time: 12.62s | valid accuracy    0.812 | valid loss   12.374\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  65 |    50/  233 batches | accuracy    0.981\n",
      "| epoch  65 |   100/  233 batches | accuracy    0.980\n",
      "| epoch  65 |   150/  233 batches | accuracy    0.981\n",
      "| epoch  65 |   200/  233 batches | accuracy    0.978\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time: 12.77s | valid accuracy    0.817 | valid loss   12.582\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  66 |    50/  233 batches | accuracy    0.970\n",
      "| epoch  66 |   100/  233 batches | accuracy    0.974\n",
      "| epoch  66 |   150/  233 batches | accuracy    0.980\n",
      "| epoch  66 |   200/  233 batches | accuracy    0.973\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time: 12.87s | valid accuracy    0.820 | valid loss   14.402\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  67 |    50/  233 batches | accuracy    0.978\n",
      "| epoch  67 |   100/  233 batches | accuracy    0.975\n",
      "| epoch  67 |   150/  233 batches | accuracy    0.977\n",
      "| epoch  67 |   200/  233 batches | accuracy    0.976\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time: 12.78s | valid accuracy    0.817 | valid loss   13.928\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  68 |    50/  233 batches | accuracy    0.971\n",
      "| epoch  68 |   100/  233 batches | accuracy    0.972\n",
      "| epoch  68 |   150/  233 batches | accuracy    0.981\n",
      "| epoch  68 |   200/  233 batches | accuracy    0.971\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time: 12.97s | valid accuracy    0.810 | valid loss   17.438\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  69 |    50/  233 batches | accuracy    0.975\n",
      "| epoch  69 |   100/  233 batches | accuracy    0.974\n",
      "| epoch  69 |   150/  233 batches | accuracy    0.975\n",
      "| epoch  69 |   200/  233 batches | accuracy    0.975\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time: 12.76s | valid accuracy    0.817 | valid loss   14.863\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  70 |    50/  233 batches | accuracy    0.973\n",
      "| epoch  70 |   100/  233 batches | accuracy    0.976\n",
      "| epoch  70 |   150/  233 batches | accuracy    0.971\n",
      "| epoch  70 |   200/  233 batches | accuracy    0.977\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time: 12.80s | valid accuracy    0.819 | valid loss   14.291\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  71 |    50/  233 batches | accuracy    0.976\n",
      "| epoch  71 |   100/  233 batches | accuracy    0.974\n",
      "| epoch  71 |   150/  233 batches | accuracy    0.980\n",
      "| epoch  71 |   200/  233 batches | accuracy    0.981\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time: 13.04s | valid accuracy    0.813 | valid loss   16.347\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  72 |    50/  233 batches | accuracy    0.976\n",
      "| epoch  72 |   100/  233 batches | accuracy    0.978\n",
      "| epoch  72 |   150/  233 batches | accuracy    0.976\n",
      "| epoch  72 |   200/  233 batches | accuracy    0.976\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time: 13.30s | valid accuracy    0.818 | valid loss   18.358\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  73 |    50/  233 batches | accuracy    0.974\n",
      "| epoch  73 |   100/  233 batches | accuracy    0.975\n",
      "| epoch  73 |   150/  233 batches | accuracy    0.973\n",
      "| epoch  73 |   200/  233 batches | accuracy    0.972\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time: 13.48s | valid accuracy    0.818 | valid loss   16.892\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  74 |    50/  233 batches | accuracy    0.970\n",
      "| epoch  74 |   100/  233 batches | accuracy    0.975\n",
      "| epoch  74 |   150/  233 batches | accuracy    0.977\n",
      "| epoch  74 |   200/  233 batches | accuracy    0.974\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time: 12.93s | valid accuracy    0.816 | valid loss   20.925\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  75 |    50/  233 batches | accuracy    0.977\n",
      "| epoch  75 |   100/  233 batches | accuracy    0.975\n",
      "| epoch  75 |   150/  233 batches | accuracy    0.974\n",
      "| epoch  75 |   200/  233 batches | accuracy    0.977\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time: 12.97s | valid accuracy    0.807 | valid loss   19.971\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  76 |    50/  233 batches | accuracy    0.973\n",
      "| epoch  76 |   100/  233 batches | accuracy    0.975\n",
      "| epoch  76 |   150/  233 batches | accuracy    0.973\n",
      "| epoch  76 |   200/  233 batches | accuracy    0.976\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time: 12.28s | valid accuracy    0.819 | valid loss   19.922\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  77 |    50/  233 batches | accuracy    0.973\n",
      "| epoch  77 |   100/  233 batches | accuracy    0.973\n",
      "| epoch  77 |   150/  233 batches | accuracy    0.977\n",
      "| epoch  77 |   200/  233 batches | accuracy    0.975\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time: 12.86s | valid accuracy    0.819 | valid loss   19.857\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  78 |    50/  233 batches | accuracy    0.975\n",
      "| epoch  78 |   100/  233 batches | accuracy    0.980\n",
      "| epoch  78 |   150/  233 batches | accuracy    0.977\n",
      "| epoch  78 |   200/  233 batches | accuracy    0.976\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time: 14.05s | valid accuracy    0.818 | valid loss   24.583\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  79 |    50/  233 batches | accuracy    0.979\n",
      "| epoch  79 |   100/  233 batches | accuracy    0.975\n",
      "| epoch  79 |   150/  233 batches | accuracy    0.978\n",
      "| epoch  79 |   200/  233 batches | accuracy    0.974\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time: 13.69s | valid accuracy    0.815 | valid loss   22.328\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  80 |    50/  233 batches | accuracy    0.977\n",
      "| epoch  80 |   100/  233 batches | accuracy    0.978\n",
      "| epoch  80 |   150/  233 batches | accuracy    0.972\n",
      "| epoch  80 |   200/  233 batches | accuracy    0.974\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time: 13.23s | valid accuracy    0.813 | valid loss   18.114\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  81 |    50/  233 batches | accuracy    0.975\n",
      "| epoch  81 |   100/  233 batches | accuracy    0.973\n",
      "| epoch  81 |   150/  233 batches | accuracy    0.976\n",
      "| epoch  81 |   200/  233 batches | accuracy    0.977\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time: 13.40s | valid accuracy    0.811 | valid loss   21.083\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  82 |    50/  233 batches | accuracy    0.979\n",
      "| epoch  82 |   100/  233 batches | accuracy    0.976\n",
      "| epoch  82 |   150/  233 batches | accuracy    0.979\n",
      "| epoch  82 |   200/  233 batches | accuracy    0.979\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time: 13.38s | valid accuracy    0.822 | valid loss   20.813\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  83 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  83 |   100/  233 batches | accuracy    0.977\n",
      "| epoch  83 |   150/  233 batches | accuracy    0.977\n",
      "| epoch  83 |   200/  233 batches | accuracy    0.975\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time: 13.72s | valid accuracy    0.816 | valid loss   20.273\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  84 |    50/  233 batches | accuracy    0.976\n",
      "| epoch  84 |   100/  233 batches | accuracy    0.976\n",
      "| epoch  84 |   150/  233 batches | accuracy    0.976\n",
      "| epoch  84 |   200/  233 batches | accuracy    0.977\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time: 13.94s | valid accuracy    0.820 | valid loss   22.788\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  85 |    50/  233 batches | accuracy    0.975\n",
      "| epoch  85 |   100/  233 batches | accuracy    0.974\n",
      "| epoch  85 |   150/  233 batches | accuracy    0.974\n",
      "| epoch  85 |   200/  233 batches | accuracy    0.979\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time: 13.89s | valid accuracy    0.821 | valid loss   25.967\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  86 |    50/  233 batches | accuracy    0.978\n",
      "| epoch  86 |   100/  233 batches | accuracy    0.977\n",
      "| epoch  86 |   150/  233 batches | accuracy    0.977\n",
      "| epoch  86 |   200/  233 batches | accuracy    0.974\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time: 13.55s | valid accuracy    0.817 | valid loss   28.312\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  87 |    50/  233 batches | accuracy    0.974\n",
      "| epoch  87 |   100/  233 batches | accuracy    0.977\n",
      "| epoch  87 |   150/  233 batches | accuracy    0.974\n",
      "| epoch  87 |   200/  233 batches | accuracy    0.975\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time: 13.70s | valid accuracy    0.821 | valid loss   25.159\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  88 |    50/  233 batches | accuracy    0.976\n",
      "| epoch  88 |   100/  233 batches | accuracy    0.973\n",
      "| epoch  88 |   150/  233 batches | accuracy    0.978\n",
      "| epoch  88 |   200/  233 batches | accuracy    0.976\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time: 13.74s | valid accuracy    0.816 | valid loss   21.881\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  89 |    50/  233 batches | accuracy    0.977\n",
      "| epoch  89 |   100/  233 batches | accuracy    0.977\n",
      "| epoch  89 |   150/  233 batches | accuracy    0.974\n",
      "| epoch  89 |   200/  233 batches | accuracy    0.974\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time: 13.46s | valid accuracy    0.820 | valid loss   23.924\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  90 |    50/  233 batches | accuracy    0.977\n",
      "| epoch  90 |   100/  233 batches | accuracy    0.976\n",
      "| epoch  90 |   150/  233 batches | accuracy    0.973\n",
      "| epoch  90 |   200/  233 batches | accuracy    0.977\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time: 13.95s | valid accuracy    0.816 | valid loss   21.342\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  91 |    50/  233 batches | accuracy    0.978\n",
      "| epoch  91 |   100/  233 batches | accuracy    0.978\n",
      "| epoch  91 |   150/  233 batches | accuracy    0.980\n",
      "| epoch  91 |   200/  233 batches | accuracy    0.978\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time: 14.05s | valid accuracy    0.822 | valid loss   24.196\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  92 |    50/  233 batches | accuracy    0.977\n",
      "| epoch  92 |   100/  233 batches | accuracy    0.977\n",
      "| epoch  92 |   150/  233 batches | accuracy    0.974\n",
      "| epoch  92 |   200/  233 batches | accuracy    0.975\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time: 14.27s | valid accuracy    0.815 | valid loss   23.475\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  93 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  93 |   100/  233 batches | accuracy    0.978\n",
      "| epoch  93 |   150/  233 batches | accuracy    0.976\n",
      "| epoch  93 |   200/  233 batches | accuracy    0.975\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time: 14.30s | valid accuracy    0.817 | valid loss   28.093\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  94 |    50/  233 batches | accuracy    0.974\n",
      "| epoch  94 |   100/  233 batches | accuracy    0.977\n",
      "| epoch  94 |   150/  233 batches | accuracy    0.976\n",
      "| epoch  94 |   200/  233 batches | accuracy    0.981\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time: 14.40s | valid accuracy    0.813 | valid loss   24.209\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  95 |    50/  233 batches | accuracy    0.975\n",
      "| epoch  95 |   100/  233 batches | accuracy    0.981\n",
      "| epoch  95 |   150/  233 batches | accuracy    0.977\n",
      "| epoch  95 |   200/  233 batches | accuracy    0.977\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time: 14.71s | valid accuracy    0.812 | valid loss   22.502\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  96 |    50/  233 batches | accuracy    0.974\n",
      "| epoch  96 |   100/  233 batches | accuracy    0.976\n",
      "| epoch  96 |   150/  233 batches | accuracy    0.973\n",
      "| epoch  96 |   200/  233 batches | accuracy    0.975\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time: 14.23s | valid accuracy    0.814 | valid loss   29.881\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  97 |    50/  233 batches | accuracy    0.978\n",
      "| epoch  97 |   100/  233 batches | accuracy    0.976\n",
      "| epoch  97 |   150/  233 batches | accuracy    0.976\n",
      "| epoch  97 |   200/  233 batches | accuracy    0.975\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time: 13.74s | valid accuracy    0.815 | valid loss   26.070\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  98 |    50/  233 batches | accuracy    0.976\n",
      "| epoch  98 |   100/  233 batches | accuracy    0.980\n",
      "| epoch  98 |   150/  233 batches | accuracy    0.976\n",
      "| epoch  98 |   200/  233 batches | accuracy    0.974\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time: 13.70s | valid accuracy    0.817 | valid loss   27.257\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  99 |    50/  233 batches | accuracy    0.976\n",
      "| epoch  99 |   100/  233 batches | accuracy    0.978\n",
      "| epoch  99 |   150/  233 batches | accuracy    0.975\n",
      "| epoch  99 |   200/  233 batches | accuracy    0.979\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  99 | time: 13.74s | valid accuracy    0.819 | valid loss   28.994\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc, train_loss = train(\n",
    "        model, optimizer, loss, train_dataloader, epoch)\n",
    "    valid_acc, valid_loss = evaluate(model, loss, valid_dataloader)\n",
    "    print(\"-\" * 80)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | valid accuracy {:8.3f} | valid loss {:8.3f}\".format(\n",
    "            epoch, time.time() - epoch_start_time, valid_acc, valid_loss\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data using torch.nn.functional.normalize\n",
    "train_data_normalized = torch.nn.functional.normalize(train_data.tensors[0].float(), dim=1)\n",
    "valid_data_normalized = torch.nn.functional.normalize(valid_data.tensors[0].float(), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalized = torch.utils.data.TensorDataset(train_df_pad, train_label)\n",
    "valid_data_normalized = torch.utils.data.TensorDataset(valid_df_pad, valid_label)\n",
    "#test_data_normalized = torch.utils.data.TensorDataset(test_df_pad, test_label)\n",
    "\n",
    "train_dataloader_nor = DataLoader(train_data_normalized, shuffle=True, batch_size=batch_size)\n",
    "valid_dataloader_nor = DataLoader(valid_data_normalized, shuffle=False, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  233 batches | accuracy    0.982\n",
      "| epoch   1 |   100/  233 batches | accuracy    0.978\n",
      "| epoch   1 |   150/  233 batches | accuracy    0.981\n",
      "| epoch   1 |   200/  233 batches | accuracy    0.981\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  1.92s | valid accuracy    0.789 | valid loss    1.772\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   2 |    50/  233 batches | accuracy    0.980\n",
      "| epoch   2 |   100/  233 batches | accuracy    0.981\n",
      "| epoch   2 |   150/  233 batches | accuracy    0.981\n",
      "| epoch   2 |   200/  233 batches | accuracy    0.981\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  2.03s | valid accuracy    0.791 | valid loss    1.774\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   3 |    50/  233 batches | accuracy    0.983\n",
      "| epoch   3 |   100/  233 batches | accuracy    0.980\n",
      "| epoch   3 |   150/  233 batches | accuracy    0.979\n",
      "| epoch   3 |   200/  233 batches | accuracy    0.982\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  1.85s | valid accuracy    0.793 | valid loss    1.778\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   4 |    50/  233 batches | accuracy    0.980\n",
      "| epoch   4 |   100/  233 batches | accuracy    0.982\n",
      "| epoch   4 |   150/  233 batches | accuracy    0.981\n",
      "| epoch   4 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time:  1.86s | valid accuracy    0.793 | valid loss    1.785\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   5 |    50/  233 batches | accuracy    0.979\n",
      "| epoch   5 |   100/  233 batches | accuracy    0.980\n",
      "| epoch   5 |   150/  233 batches | accuracy    0.978\n",
      "| epoch   5 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time:  1.88s | valid accuracy    0.794 | valid loss    1.797\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   6 |    50/  233 batches | accuracy    0.982\n",
      "| epoch   6 |   100/  233 batches | accuracy    0.982\n",
      "| epoch   6 |   150/  233 batches | accuracy    0.978\n",
      "| epoch   6 |   200/  233 batches | accuracy    0.982\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time:  1.83s | valid accuracy    0.796 | valid loss    1.809\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   7 |    50/  233 batches | accuracy    0.981\n",
      "| epoch   7 |   100/  233 batches | accuracy    0.981\n",
      "| epoch   7 |   150/  233 batches | accuracy    0.980\n",
      "| epoch   7 |   200/  233 batches | accuracy    0.979\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time:  1.88s | valid accuracy    0.791 | valid loss    1.833\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   8 |    50/  233 batches | accuracy    0.977\n",
      "| epoch   8 |   100/  233 batches | accuracy    0.980\n",
      "| epoch   8 |   150/  233 batches | accuracy    0.982\n",
      "| epoch   8 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time:  1.87s | valid accuracy    0.793 | valid loss    1.845\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch   9 |    50/  233 batches | accuracy    0.979\n",
      "| epoch   9 |   100/  233 batches | accuracy    0.978\n",
      "| epoch   9 |   150/  233 batches | accuracy    0.980\n",
      "| epoch   9 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time:  1.98s | valid accuracy    0.794 | valid loss    1.852\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  10 |    50/  233 batches | accuracy    0.979\n",
      "| epoch  10 |   100/  233 batches | accuracy    0.980\n",
      "| epoch  10 |   150/  233 batches | accuracy    0.980\n",
      "| epoch  10 |   200/  233 batches | accuracy    0.978\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time:  1.90s | valid accuracy    0.795 | valid loss    1.869\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  11 |    50/  233 batches | accuracy    0.979\n",
      "| epoch  11 |   100/  233 batches | accuracy    0.979\n",
      "| epoch  11 |   150/  233 batches | accuracy    0.980\n",
      "| epoch  11 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time:  1.92s | valid accuracy    0.794 | valid loss    1.881\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  12 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  12 |   100/  233 batches | accuracy    0.982\n",
      "| epoch  12 |   150/  233 batches | accuracy    0.979\n",
      "| epoch  12 |   200/  233 batches | accuracy    0.981\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time:  1.93s | valid accuracy    0.794 | valid loss    1.896\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  13 |    50/  233 batches | accuracy    0.978\n",
      "| epoch  13 |   100/  233 batches | accuracy    0.980\n",
      "| epoch  13 |   150/  233 batches | accuracy    0.979\n",
      "| epoch  13 |   200/  233 batches | accuracy    0.981\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time:  1.98s | valid accuracy    0.793 | valid loss    1.916\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  14 |    50/  233 batches | accuracy    0.983\n",
      "| epoch  14 |   100/  233 batches | accuracy    0.979\n",
      "| epoch  14 |   150/  233 batches | accuracy    0.978\n",
      "| epoch  14 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time:  1.95s | valid accuracy    0.793 | valid loss    1.940\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  15 |    50/  233 batches | accuracy    0.979\n",
      "| epoch  15 |   100/  233 batches | accuracy    0.981\n",
      "| epoch  15 |   150/  233 batches | accuracy    0.979\n",
      "| epoch  15 |   200/  233 batches | accuracy    0.981\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time:  1.94s | valid accuracy    0.793 | valid loss    1.950\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  16 |    50/  233 batches | accuracy    0.978\n",
      "| epoch  16 |   100/  233 batches | accuracy    0.981\n",
      "| epoch  16 |   150/  233 batches | accuracy    0.978\n",
      "| epoch  16 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time:  1.91s | valid accuracy    0.784 | valid loss    2.123\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  17 |    50/  233 batches | accuracy    0.981\n",
      "| epoch  17 |   100/  233 batches | accuracy    0.980\n",
      "| epoch  17 |   150/  233 batches | accuracy    0.981\n",
      "| epoch  17 |   200/  233 batches | accuracy    0.978\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time:  1.92s | valid accuracy    0.790 | valid loss    2.058\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  18 |    50/  233 batches | accuracy    0.977\n",
      "| epoch  18 |   100/  233 batches | accuracy    0.982\n",
      "| epoch  18 |   150/  233 batches | accuracy    0.982\n",
      "| epoch  18 |   200/  233 batches | accuracy    0.978\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time:  1.92s | valid accuracy    0.792 | valid loss    2.056\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  19 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  19 |   100/  233 batches | accuracy    0.981\n",
      "| epoch  19 |   150/  233 batches | accuracy    0.977\n",
      "| epoch  19 |   200/  233 batches | accuracy    0.979\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time:  1.93s | valid accuracy    0.792 | valid loss    2.055\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  20 |    50/  233 batches | accuracy    0.977\n",
      "| epoch  20 |   100/  233 batches | accuracy    0.978\n",
      "| epoch  20 |   150/  233 batches | accuracy    0.980\n",
      "| epoch  20 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time:  2.01s | valid accuracy    0.794 | valid loss    2.056\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  21 |    50/  233 batches | accuracy    0.978\n",
      "| epoch  21 |   100/  233 batches | accuracy    0.980\n",
      "| epoch  21 |   150/  233 batches | accuracy    0.979\n",
      "| epoch  21 |   200/  233 batches | accuracy    0.978\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time:  1.92s | valid accuracy    0.793 | valid loss    2.064\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  22 |    50/  233 batches | accuracy    0.981\n",
      "| epoch  22 |   100/  233 batches | accuracy    0.983\n",
      "| epoch  22 |   150/  233 batches | accuracy    0.978\n",
      "| epoch  22 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time:  1.90s | valid accuracy    0.794 | valid loss    2.061\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  23 |    50/  233 batches | accuracy    0.979\n",
      "| epoch  23 |   100/  233 batches | accuracy    0.979\n",
      "| epoch  23 |   150/  233 batches | accuracy    0.979\n",
      "| epoch  23 |   200/  233 batches | accuracy    0.982\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time:  1.93s | valid accuracy    0.792 | valid loss    2.075\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  24 |    50/  233 batches | accuracy    0.987\n",
      "| epoch  24 |   100/  233 batches | accuracy    0.981\n",
      "| epoch  24 |   150/  233 batches | accuracy    0.979\n",
      "| epoch  24 |   200/  233 batches | accuracy    0.978\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time:  2.01s | valid accuracy    0.794 | valid loss    2.073\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  25 |    50/  233 batches | accuracy    0.982\n",
      "| epoch  25 |   100/  233 batches | accuracy    0.982\n",
      "| epoch  25 |   150/  233 batches | accuracy    0.980\n",
      "| epoch  25 |   200/  233 batches | accuracy    0.982\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time:  1.95s | valid accuracy    0.793 | valid loss    2.082\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  26 |    50/  233 batches | accuracy    0.982\n",
      "| epoch  26 |   100/  233 batches | accuracy    0.980\n",
      "| epoch  26 |   150/  233 batches | accuracy    0.982\n",
      "| epoch  26 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time:  1.98s | valid accuracy    0.794 | valid loss    2.085\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  27 |    50/  233 batches | accuracy    0.978\n",
      "| epoch  27 |   100/  233 batches | accuracy    0.979\n",
      "| epoch  27 |   150/  233 batches | accuracy    0.982\n",
      "| epoch  27 |   200/  233 batches | accuracy    0.981\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time:  2.11s | valid accuracy    0.794 | valid loss    2.084\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  28 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  28 |   100/  233 batches | accuracy    0.979\n",
      "| epoch  28 |   150/  233 batches | accuracy    0.982\n",
      "| epoch  28 |   200/  233 batches | accuracy    0.982\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time:  1.94s | valid accuracy    0.792 | valid loss    2.099\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  29 |    50/  233 batches | accuracy    0.981\n",
      "| epoch  29 |   100/  233 batches | accuracy    0.983\n",
      "| epoch  29 |   150/  233 batches | accuracy    0.980\n",
      "| epoch  29 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time:  2.04s | valid accuracy    0.792 | valid loss    2.136\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  30 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  30 |   100/  233 batches | accuracy    0.980\n",
      "| epoch  30 |   150/  233 batches | accuracy    0.983\n",
      "| epoch  30 |   200/  233 batches | accuracy    0.979\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time:  1.95s | valid accuracy    0.794 | valid loss    2.150\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  31 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  31 |   100/  233 batches | accuracy    0.981\n",
      "| epoch  31 |   150/  233 batches | accuracy    0.982\n",
      "| epoch  31 |   200/  233 batches | accuracy    0.978\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time:  1.98s | valid accuracy    0.795 | valid loss    2.145\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  32 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  32 |   100/  233 batches | accuracy    0.985\n",
      "| epoch  32 |   150/  233 batches | accuracy    0.984\n",
      "| epoch  32 |   200/  233 batches | accuracy    0.981\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time:  1.93s | valid accuracy    0.795 | valid loss    2.151\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  33 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  33 |   100/  233 batches | accuracy    0.981\n",
      "| epoch  33 |   150/  233 batches | accuracy    0.978\n",
      "| epoch  33 |   200/  233 batches | accuracy    0.979\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time:  1.91s | valid accuracy    0.796 | valid loss    2.160\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  34 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  34 |   100/  233 batches | accuracy    0.984\n",
      "| epoch  34 |   150/  233 batches | accuracy    0.978\n",
      "| epoch  34 |   200/  233 batches | accuracy    0.978\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time:  1.93s | valid accuracy    0.799 | valid loss    2.175\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  35 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  35 |   100/  233 batches | accuracy    0.979\n",
      "| epoch  35 |   150/  233 batches | accuracy    0.981\n",
      "| epoch  35 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time:  1.95s | valid accuracy    0.797 | valid loss    2.166\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  36 |    50/  233 batches | accuracy    0.981\n",
      "| epoch  36 |   100/  233 batches | accuracy    0.979\n",
      "| epoch  36 |   150/  233 batches | accuracy    0.983\n",
      "| epoch  36 |   200/  233 batches | accuracy    0.984\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time:  1.94s | valid accuracy    0.797 | valid loss    2.175\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  37 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  37 |   100/  233 batches | accuracy    0.980\n",
      "| epoch  37 |   150/  233 batches | accuracy    0.976\n",
      "| epoch  37 |   200/  233 batches | accuracy    0.981\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time:  1.92s | valid accuracy    0.797 | valid loss    2.179\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  38 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  38 |   100/  233 batches | accuracy    0.978\n",
      "| epoch  38 |   150/  233 batches | accuracy    0.981\n",
      "| epoch  38 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time:  2.02s | valid accuracy    0.797 | valid loss    2.192\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  39 |    50/  233 batches | accuracy    0.981\n",
      "| epoch  39 |   100/  233 batches | accuracy    0.980\n",
      "| epoch  39 |   150/  233 batches | accuracy    0.980\n",
      "| epoch  39 |   200/  233 batches | accuracy    0.978\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time:  1.99s | valid accuracy    0.797 | valid loss    2.195\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  40 |    50/  233 batches | accuracy    0.981\n",
      "| epoch  40 |   100/  233 batches | accuracy    0.978\n",
      "| epoch  40 |   150/  233 batches | accuracy    0.980\n",
      "| epoch  40 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time:  1.97s | valid accuracy    0.796 | valid loss    2.204\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  41 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  41 |   100/  233 batches | accuracy    0.980\n",
      "| epoch  41 |   150/  233 batches | accuracy    0.980\n",
      "| epoch  41 |   200/  233 batches | accuracy    0.979\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time:  1.93s | valid accuracy    0.797 | valid loss    2.210\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  42 |    50/  233 batches | accuracy    0.980\n",
      "| epoch  42 |   100/  233 batches | accuracy    0.979\n",
      "| epoch  42 |   150/  233 batches | accuracy    0.978\n",
      "| epoch  42 |   200/  233 batches | accuracy    0.979\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time:  1.98s | valid accuracy    0.797 | valid loss    2.215\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  43 |    50/  233 batches | accuracy    0.982\n",
      "| epoch  43 |   100/  233 batches | accuracy    0.980\n",
      "| epoch  43 |   150/  233 batches | accuracy    0.978\n",
      "| epoch  43 |   200/  233 batches | accuracy    0.978\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time:  1.99s | valid accuracy    0.798 | valid loss    2.221\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  44 |    50/  233 batches | accuracy    0.979\n",
      "| epoch  44 |   100/  233 batches | accuracy    0.984\n",
      "| epoch  44 |   150/  233 batches | accuracy    0.982\n",
      "| epoch  44 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time:  1.97s | valid accuracy    0.799 | valid loss    2.230\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  45 |    50/  233 batches | accuracy    0.978\n",
      "| epoch  45 |   100/  233 batches | accuracy    0.982\n",
      "| epoch  45 |   150/  233 batches | accuracy    0.981\n",
      "| epoch  45 |   200/  233 batches | accuracy    0.983\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time:  2.04s | valid accuracy    0.800 | valid loss    2.238\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  46 |    50/  233 batches | accuracy    0.979\n",
      "| epoch  46 |   100/  233 batches | accuracy    0.981\n",
      "| epoch  46 |   150/  233 batches | accuracy    0.979\n",
      "| epoch  46 |   200/  233 batches | accuracy    0.981\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time:  2.01s | valid accuracy    0.799 | valid loss    2.257\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  47 |    50/  233 batches | accuracy    0.977\n",
      "| epoch  47 |   100/  233 batches | accuracy    0.978\n",
      "| epoch  47 |   150/  233 batches | accuracy    0.983\n",
      "| epoch  47 |   200/  233 batches | accuracy    0.976\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time:  2.00s | valid accuracy    0.796 | valid loss    2.276\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  48 |    50/  233 batches | accuracy    0.979\n",
      "| epoch  48 |   100/  233 batches | accuracy    0.979\n",
      "| epoch  48 |   150/  233 batches | accuracy    0.982\n",
      "| epoch  48 |   200/  233 batches | accuracy    0.977\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time:  2.04s | valid accuracy    0.798 | valid loss    2.278\n",
      "--------------------------------------------------------------------------------\n",
      "| epoch  49 |    50/  233 batches | accuracy    0.979\n",
      "| epoch  49 |   100/  233 batches | accuracy    0.981\n",
      "| epoch  49 |   150/  233 batches | accuracy    0.981\n",
      "| epoch  49 |   200/  233 batches | accuracy    0.980\n",
      "--------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time:  1.98s | valid accuracy    0.797 | valid loss    2.303\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 50):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc, train_loss = train(\n",
    "        model, optimizer, loss, train_dataloader_nor, epoch)\n",
    "    valid_acc, valid_loss = evaluate(model, loss, valid_dataloader_nor)\n",
    "    print(\"-\" * 80)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | valid accuracy {:8.3f} | valid loss {:8.3f}\".format(\n",
    "            epoch, time.time() - epoch_start_time, valid_acc, valid_loss\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
