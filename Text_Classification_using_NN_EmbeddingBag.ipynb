{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taaQW5YzqXCf"
      },
      "source": [
        "\n",
        "#**Text Classification using Neural Network (Torchtext)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6VH4oC_qgd3"
      },
      "source": [
        "#**I. Pytorch & Torchtext**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrMGVUn0q6YT"
      },
      "source": [
        "##**1. Index-based Representation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "175VD-_CqnM-",
        "outputId": "2ba43813-1e7a-4e62-bca0-0b1f7228c824"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'food': 6,\n",
              " 'dog': 1,\n",
              " '<unk>': 0,\n",
              " 'man': 2,\n",
              " 'bites': 3,\n",
              " 'meat': 7,\n",
              " 'eats': 4,\n",
              " 'break': 5}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "data = [\"dog bites man\", \"man bites dog\", \"dog eats meat break\", \"man eats food\"]\n",
        "\n",
        "# Define the max vocabulary size\n",
        "vocab_size = 10\n",
        "\n",
        "# Define tokenizer function\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Create a function to yield list of tokens\n",
        "def yield_tokens(examples):\n",
        "    for text in examples:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Create vocabulary\n",
        "vocab = build_vocab_from_iterator(\n",
        "    yield_tokens(data),\n",
        "    max_tokens=vocab_size,\n",
        "    specials=[\"<unk>\"]\n",
        ")\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "vocab.get_stoi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5kUZZ8irLLx",
        "outputId": "231f2933-732b-4f39-bc84-c191bb944fd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 0, 2]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab(tokenizer(\"dog and man\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO0R_l0MrVdY"
      },
      "source": [
        "##**2. Padding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJSMYLmMrX1V",
        "outputId": "ef7f56df-bbc6-4617-b370-3084fdda29c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "data = [\"dog bites man\", \"man bites dog\", \"dog eats meat\", \"man eats food\"]\n",
        "\n",
        "# Define the max vocabulary size\n",
        "vocab_size = 8\n",
        "\n",
        "# Define tokenizer function\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Create a function to yield list of tokens\n",
        "def yield_tokens(examples):\n",
        "    for text in examples:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Create vocabulary\n",
        "vocab = build_vocab_from_iterator(\n",
        "    yield_tokens(data),\n",
        "    max_tokens=vocab_size,\n",
        "    specials=[\"<pad>\", \"<unk>\"]\n",
        ")\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "vocab.get_stoi()['<pad>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK6ETXOircBi",
        "outputId": "02accc67-06f2-45a3-9c92-62cbe7c066c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2, 4, 3, 0])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchtext.transforms import PadTransform\n",
        "\n",
        "# define padding\n",
        "max_len = 4\n",
        "pad_id = vocab.get_stoi()['<pad>']\n",
        "padder = PadTransform(max_len, pad_id)\n",
        "\n",
        "input = torch.tensor([2, 4, 3])\n",
        "padded_input = padder(input)\n",
        "padded_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2YWSqGnrmWb"
      },
      "source": [
        "##**3. Truncating**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMTbpkmyrpZN",
        "outputId": "22992c52-06eb-4818-95b9-e3485253068a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2, 2, 4]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchtext.transforms import Truncate\n",
        "\n",
        "# define padding\n",
        "max_len = 3\n",
        "truncater = Truncate(max_len)\n",
        "\n",
        "input = [2, 2, 4, 3]\n",
        "truncated_input = truncater(input)\n",
        "truncated_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cim-c7C0rvlb"
      },
      "source": [
        "##**4. Embedding Layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPVzaMwhryuM",
        "outputId": "fc6e4e06-a6fc-43e0-f4e4-bc6f1ecb2fd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.6559,  1.3594,  0.1479],\n",
              "        [-1.8895, -2.0806,  0.5763],\n",
              "        [ 0.3984, -0.4017,  0.2369],\n",
              "        [-0.4685,  0.4417,  0.2814],\n",
              "        [ 0.8080,  0.3747,  1.2526],\n",
              "        [ 1.4169, -0.2143,  1.6728],\n",
              "        [-0.1761,  0.8684,  0.6982]], requires_grad=True)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "vocab_size = 7\n",
        "embedding_dim = 3\n",
        "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "embedding.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNLfTWGQr3Yp",
        "outputId": "d48f3be9-74ed-48b4-ba7f-a5631a7dec0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-1.8895, -2.0806,  0.5763],\n",
              "         [ 0.3984, -0.4017,  0.2369],\n",
              "         [ 0.8080,  0.3747,  1.2526]],\n",
              "\n",
              "        [[ 0.8080,  0.3747,  1.2526],\n",
              "         [-0.4685,  0.4417,  0.2814],\n",
              "         [ 0.3984, -0.4017,  0.2369]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "input = torch.LongTensor([[1, 2, 4], [4, 3, 2]])\n",
        "embedding(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkAYWWrGr6KB"
      },
      "source": [
        "##**5. EmbeddingBag**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD5u7gcLr8pc",
        "outputId": "d28d8aa8-ebe9-4477-d5b2-07dbe27866d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1.1380, -1.0332,  0.3145,  0.3978],\n",
              "        [-0.2621,  0.5047,  0.6283, -0.9858],\n",
              "        [ 2.8303, -0.5140, -0.1121,  1.1000],\n",
              "        [-0.3895, -0.2760,  1.2807, -0.7265],\n",
              "        [-1.2690,  0.3354, -0.2880, -1.4561],\n",
              "        [-0.1139, -0.9135, -0.1265,  0.9945],\n",
              "        [-0.8233, -0.2780,  2.2734, -1.7664]], requires_grad=True)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "vocab_size = 7\n",
        "embedding_dim = 4\n",
        "embedding_sum = nn.EmbeddingBag(vocab_size, embedding_dim, mode='sum')\n",
        "embedding_sum.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdpnoMNysAwj",
        "outputId": "0187cdec-095d-4a40-c3de-12c0bc1c49e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.2992,  0.3261,  0.2283, -1.3419],\n",
              "        [-1.7724, -0.8541,  0.8663, -1.1881]], grad_fn=<EmbeddingBagBackward0>)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.tensor([1, 2, 4, 5, 4, 3], dtype=torch.long)\n",
        "offsets = torch.tensor([0, 3], dtype=torch.long)\n",
        "embedding_sum(inputs, offsets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rct1KtdysFDM",
        "outputId": "9786bc55-24a5-43b3-e003-e9e98cd872c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 3.0254e-01, -4.6935e-01,  4.4714e-01,  4.6225e-01],\n",
              "        [ 1.3913e+00,  8.4724e-03, -6.7528e-01,  8.6682e-01],\n",
              "        [ 5.6138e-01, -1.2469e-01,  1.4979e-03, -2.0303e-01],\n",
              "        [-2.6869e+00, -3.8463e-01,  2.4544e-01, -1.0190e+00],\n",
              "        [ 2.0376e+00,  3.3820e-01,  2.9438e+00, -3.0470e-01],\n",
              "        [ 4.9471e-02, -1.7743e+00,  1.9325e+00,  3.5303e-01],\n",
              "        [-3.3324e-01, -8.1543e-02,  4.9799e-01, -6.0619e-01]],\n",
              "       requires_grad=True)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "vocab_size = 7\n",
        "embedding_dim = 4\n",
        "embedding_sum = nn.EmbeddingBag(vocab_size, embedding_dim, mode='mean')\n",
        "embedding_sum.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHJXnxYxsHzs",
        "outputId": "4a9c3558-9faf-4513-a874-0a7d360c5763"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.3301,  0.0740,  0.7567,  0.1197],\n",
              "        [-0.2000, -0.6069,  1.7072, -0.3236]], grad_fn=<EmbeddingBagBackward0>)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.tensor([1, 2, 4, 5, 4, 3], dtype=torch.long)\n",
        "offsets = torch.tensor([0, 3], dtype=torch.long)\n",
        "embedding_sum(inputs, offsets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNLm4l85rQN4"
      },
      "source": [
        "#**II. Text Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbtPHUfVrkrB"
      },
      "source": [
        "##**1. Download Dataset from Github**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0DiBQK5rkrD",
        "outputId": "31e26d7e-fdd5-4531-fb03-95da3490b417"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'ntc-scv'...\n",
            "Updating files:  81% (9/11)\n",
            "Updating files:  90% (10/11)\n",
            "Updating files: 100% (11/11)\n",
            "Updating files: 100% (11/11), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/congnghia0609/ntc-scv.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU1hU_UvrkrE",
        "outputId": "bf5ef4fe-70bb-4b1e-fd47-406096ae64f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'rm' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!unzip ./ntc-scv/data/data_test.zip -d ./data\n",
        "!unzip ./ntc-scv/data/data_train.zip -d ./data\n",
        "!rm -rf ./ntc-scv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q0jHeUN7rkrE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def load_data_from_path(folder_path):\n",
        "    examples = []\n",
        "    for label in os.listdir(folder_path):\n",
        "        full_path = os.path.join(folder_path, label)\n",
        "        for file_name in os.listdir(full_path):\n",
        "            file_path = os.path.join(full_path, file_name)\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                lines = f.readlines()\n",
        "            sentence = \" \".join(lines)\n",
        "            if label == \"neg\":\n",
        "                label = 0\n",
        "            if label == \"pos\":\n",
        "                label = 1\n",
        "            data = {\n",
        "                'sentence': sentence,\n",
        "                'label': label\n",
        "            }\n",
        "            examples.append(data)\n",
        "    return pd.DataFrame(examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GZxIF6mCrkrF"
      },
      "outputs": [],
      "source": [
        "folder_paths = {\n",
        "    'train': './data_train/train',\n",
        "    'valid': './data_train/test',\n",
        "    'test': './data_test/test'\n",
        "}\n",
        "\n",
        "train_df = load_data_from_path(folder_paths['train'])\n",
        "valid_df = load_data_from_path(folder_paths['valid'])\n",
        "test_df = load_data_from_path(folder_paths['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YXEhAwXorkrF",
        "outputId": "dd125e80-639b-4eed-9f3f-524ee31f6338"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mua có mỗi Bingsu thập_cẩm 45k mà mình f đợi h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thứ 6 nào ta cùng quẩy 💣 💣 💣\\n Vuvuzela beer c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mình đi với nhóm , tổng_cộng 4 người ăn chỉ có...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nhân_viên phục_vụ không mấy tận_tình , đồ_ăn r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vào đây thì hết bàn , nhưng mình vẫn ngồi đợi ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  label\n",
              "0  Mua có mỗi Bingsu thập_cẩm 45k mà mình f đợi h...      0\n",
              "1  Thứ 6 nào ta cùng quẩy 💣 💣 💣\\n Vuvuzela beer c...      0\n",
              "2  Mình đi với nhóm , tổng_cộng 4 người ăn chỉ có...      0\n",
              "3  nhân_viên phục_vụ không mấy tận_tình , đồ_ăn r...      0\n",
              "4  Vào đây thì hết bàn , nhưng mình vẫn ngồi đợi ...      0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC3Wgc0UrkrF"
      },
      "source": [
        "##**2. Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRer6QHhrkrG"
      },
      "source": [
        "###**2.1. Language Detection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "67SMB4OsrkrG"
      },
      "outputs": [],
      "source": [
        "from langid.langid import LanguageIdentifier, model\n",
        "\n",
        "def identify_vn(df):\n",
        "    identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)\n",
        "    not_vi_idx = set()\n",
        "    THRESHOLD = 0.9\n",
        "    for idx, row in df.iterrows():\n",
        "        score = identifier.classify(row[\"sentence\"])\n",
        "        if score[0] != \"vi\" or (score[0] == \"vi\" and score[1] <= THRESHOLD):\n",
        "            not_vi_idx.add(idx)\n",
        "    vi_df = df[~df.index.isin(not_vi_idx)]\n",
        "    not_vi_df = df[df.index.isin(not_vi_idx)]\n",
        "    return vi_df, not_vi_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8hR7Y4w8rkrG"
      },
      "outputs": [],
      "source": [
        "train_df_vi, train_df_other = identify_vn(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "w_9nfPzxrkrG",
        "outputId": "4d26d2b3-7213-46f0-ce85-b69cd514e83a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mua có mỗi Bingsu thập_cẩm 45k mà mình f đợi h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thứ 6 nào ta cùng quẩy 💣 💣 💣\\n Vuvuzela beer c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mình đi với nhóm , tổng_cộng 4 người ăn chỉ có...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nhân_viên phục_vụ không mấy tận_tình , đồ_ăn r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vào đây thì hết bàn , nhưng mình vẫn ngồi đợi ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>2-9 mình đi với nhóm bạn tổng_cộng là 8ng.Thiệ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>sushi bình_dân mà chất_lượng không bình_dân ch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>Trời_ơi từ bé đến lớn chưa thử món kem nào bằn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>Nge mn cũng ns ngon nên hni đến coi thế_nào .\\...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>Ks đẹp . Thoág mát . Lại gần vs phố cổ nữa nên...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29736 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence  label\n",
              "0      Mua có mỗi Bingsu thập_cẩm 45k mà mình f đợi h...      0\n",
              "1      Thứ 6 nào ta cùng quẩy 💣 💣 💣\\n Vuvuzela beer c...      0\n",
              "2      Mình đi với nhóm , tổng_cộng 4 người ăn chỉ có...      0\n",
              "3      nhân_viên phục_vụ không mấy tận_tình , đồ_ăn r...      0\n",
              "4      Vào đây thì hết bàn , nhưng mình vẫn ngồi đợi ...      0\n",
              "...                                                  ...    ...\n",
              "29995  2-9 mình đi với nhóm bạn tổng_cộng là 8ng.Thiệ...      1\n",
              "29996  sushi bình_dân mà chất_lượng không bình_dân ch...      1\n",
              "29997  Trời_ơi từ bé đến lớn chưa thử món kem nào bằn...      1\n",
              "29998  Nge mn cũng ns ngon nên hni đến coi thế_nào .\\...      1\n",
              "29999  Ks đẹp . Thoág mát . Lại gần vs phố cổ nữa nên...      1\n",
              "\n",
              "[29736 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df_vi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "vajiWpYNrkrH",
        "outputId": "146ad0a1-b11e-476a-e0b2-2e69bd2d1297"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>Minh da den them 1 lan vao buoi trua ma van do...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>The drink taste not good as Shanghai . The tas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>I work in District 1 not far from Taco_King . ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>Service is worst . . waiter and waitress messi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>809</th>\n",
              "      <td>Day la lan dau cung nhu lan cuoi minh ghe quan...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29571</th>\n",
              "      <td>We had high expectations of this place and my ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29687</th>\n",
              "      <td>My name is Luan ,   A_Local_Travel_Consultant ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29757</th>\n",
              "      <td>Art of lanterns , super nice and acceptable pr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29853</th>\n",
              "      <td>The 200k buffet is really worth it ! Good meat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29940</th>\n",
              "      <td>Brilliant juices ! ! They have some mixes that...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>264 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence  label\n",
              "446    Minh da den them 1 lan vao buoi trua ma van do...      0\n",
              "523    The drink taste not good as Shanghai . The tas...      0\n",
              "582    I work in District 1 not far from Taco_King . ...      0\n",
              "802    Service is worst . . waiter and waitress messi...      0\n",
              "809    Day la lan dau cung nhu lan cuoi minh ghe quan...      0\n",
              "...                                                  ...    ...\n",
              "29571  We had high expectations of this place and my ...      1\n",
              "29687  My name is Luan ,   A_Local_Travel_Consultant ...      1\n",
              "29757  Art of lanterns , super nice and acceptable pr...      1\n",
              "29853  The 200k buffet is really worth it ! Good meat...      1\n",
              "29940  Brilliant juices ! ! They have some mixes that...      1\n",
              "\n",
              "[264 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df_other"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-g6dtCHrkrH"
      },
      "source": [
        "###**2.2. Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5-RIlCStrkrH"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    url_pattern = re.compile(r'https?://\\s+\\wwww\\.\\s+')\n",
        "    text = url_pattern.sub(r\" \", text)\n",
        "\n",
        "    html_pattern = re.compile(r'<[^<>]+>')\n",
        "    text = html_pattern.sub(\" \", text)\n",
        "\n",
        "    replace_chars = list(string.punctuation + string.digits)\n",
        "    for char in replace_chars:\n",
        "        text = text.replace(char, \" \")\n",
        "\n",
        "    \n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
        "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
        "        u\"\\U0001F600-\\U0001F64F\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U0001F1F2\"\n",
        "        u\"\\U0001F1F4\"\n",
        "        u\"\\U0001F620\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r\" \", text)\n",
        "\n",
        "    text = \" \".join(text.split())\n",
        "\n",
        "    return text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "5x3vZZwprkrH",
        "outputId": "a433746d-9b96-4c31-c72e-dc1bbf4260f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    Mua có mỗi Bingsu thập_cẩm 45k mà mình f đợi h...\n",
              "1    Thứ 6 nào ta cùng quẩy 💣 💣 💣\\n Vuvuzela beer c...\n",
              "2    Mình đi với nhóm , tổng_cộng 4 người ăn chỉ có...\n",
              "3    nhân_viên phục_vụ không mấy tận_tình , đồ_ăn r...\n",
              "4    Vào đây thì hết bàn , nhưng mình vẫn ngồi đợi ...\n",
              "Name: sentence, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df_vi['sentence'][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "9p825QUyrkrH",
        "outputId": "2267c95b-5820-4fd8-d618-ab4a92aece57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'mua có mỗi bingsu thập cẩm k mà mình f đợi hơn hỏi lại thì nv tl có r nhg bảo chờ thêm nữa tụi e lm liền mình k biết có ngon k nhg cũng muốn ăn thử thiết nghĩ nv quán nên xem lại cách pv và nc vs khách'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocess_text(train_df_vi['sentence'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxI--G8grkrH",
        "outputId": "335fecfb-a7a7-4279-ba15-b626d345d8c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\cang_\\AppData\\Local\\Temp\\ipykernel_21004\\1058621333.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df_vi['preprocess_sentence'] = [preprocess_text(row['sentence']) for index, row in train_df_vi.iterrows()]\n"
          ]
        }
      ],
      "source": [
        "train_df_vi['preprocess_sentence'] = [preprocess_text(row['sentence']) for index, row in train_df_vi.iterrows()]\n",
        "valid_df['preprocess_sentence'] = [preprocess_text(row['sentence']) for index, row in valid_df.iterrows()]\n",
        "test_df['preprocess_sentence'] = [preprocess_text(row['sentence']) for index, row in test_df.iterrows()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iI3r_zmmrkrH",
        "outputId": "d2627846-0c10-4211-a8d9-1f848c7a6e54"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>preprocess_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mua có mỗi Bingsu thập_cẩm 45k mà mình f đợi h...</td>\n",
              "      <td>0</td>\n",
              "      <td>mua có mỗi bingsu thập cẩm k mà mình f đợi hơn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thứ 6 nào ta cùng quẩy 💣 💣 💣\\n Vuvuzela beer c...</td>\n",
              "      <td>0</td>\n",
              "      <td>thứ nào ta cùng quẩy vuvuzela beer club chung ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mình đi với nhóm , tổng_cộng 4 người ăn chỉ có...</td>\n",
              "      <td>0</td>\n",
              "      <td>mình đi với nhóm tổng cộng người ăn chỉ có khô...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nhân_viên phục_vụ không mấy tận_tình , đồ_ăn r...</td>\n",
              "      <td>0</td>\n",
              "      <td>nhân viên phục vụ không mấy tận tình đồ ăn ra ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vào đây thì hết bàn , nhưng mình vẫn ngồi đợi ...</td>\n",
              "      <td>0</td>\n",
              "      <td>vào đây thì hết bàn nhưng mình vẫn ngồi đợi bì...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>2-9 mình đi với nhóm bạn tổng_cộng là 8ng.Thiệ...</td>\n",
              "      <td>1</td>\n",
              "      <td>mình đi với nhóm bạn tổng cộng là ng thiệt hại...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>sushi bình_dân mà chất_lượng không bình_dân ch...</td>\n",
              "      <td>1</td>\n",
              "      <td>sushi bình dân mà chất lượng không bình dân ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>Trời_ơi từ bé đến lớn chưa thử món kem nào bằn...</td>\n",
              "      <td>1</td>\n",
              "      <td>trời ơi từ bé đến lớn chưa thử món kem nào bằn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>Nge mn cũng ns ngon nên hni đến coi thế_nào .\\...</td>\n",
              "      <td>1</td>\n",
              "      <td>nge mn cũng ns ngon nên hni đến coi thế nào qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>Ks đẹp . Thoág mát . Lại gần vs phố cổ nữa nên...</td>\n",
              "      <td>1</td>\n",
              "      <td>ks đẹp thoág mát lại gần vs phố cổ nữa nên rất...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29736 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence  label  \\\n",
              "0      Mua có mỗi Bingsu thập_cẩm 45k mà mình f đợi h...      0   \n",
              "1      Thứ 6 nào ta cùng quẩy 💣 💣 💣\\n Vuvuzela beer c...      0   \n",
              "2      Mình đi với nhóm , tổng_cộng 4 người ăn chỉ có...      0   \n",
              "3      nhân_viên phục_vụ không mấy tận_tình , đồ_ăn r...      0   \n",
              "4      Vào đây thì hết bàn , nhưng mình vẫn ngồi đợi ...      0   \n",
              "...                                                  ...    ...   \n",
              "29995  2-9 mình đi với nhóm bạn tổng_cộng là 8ng.Thiệ...      1   \n",
              "29996  sushi bình_dân mà chất_lượng không bình_dân ch...      1   \n",
              "29997  Trời_ơi từ bé đến lớn chưa thử món kem nào bằn...      1   \n",
              "29998  Nge mn cũng ns ngon nên hni đến coi thế_nào .\\...      1   \n",
              "29999  Ks đẹp . Thoág mát . Lại gần vs phố cổ nữa nên...      1   \n",
              "\n",
              "                                     preprocess_sentence  \n",
              "0      mua có mỗi bingsu thập cẩm k mà mình f đợi hơn...  \n",
              "1      thứ nào ta cùng quẩy vuvuzela beer club chung ...  \n",
              "2      mình đi với nhóm tổng cộng người ăn chỉ có khô...  \n",
              "3      nhân viên phục vụ không mấy tận tình đồ ăn ra ...  \n",
              "4      vào đây thì hết bàn nhưng mình vẫn ngồi đợi bì...  \n",
              "...                                                  ...  \n",
              "29995  mình đi với nhóm bạn tổng cộng là ng thiệt hại...  \n",
              "29996  sushi bình dân mà chất lượng không bình dân ch...  \n",
              "29997  trời ơi từ bé đến lớn chưa thử món kem nào bằn...  \n",
              "29998  nge mn cũng ns ngon nên hni đến coi thế nào qu...  \n",
              "29999  ks đẹp thoág mát lại gần vs phố cổ nữa nên rất...  \n",
              "\n",
              "[29736 rows x 3 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df_vi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vNMsPhdlrkrH",
        "outputId": "55937f23-7c72-4db5-ab4b-bdb500880f70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>preprocess_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lần đầu_tiên ăn chắc cũng là lần cuối ăn_ở đây...</td>\n",
              "      <td>0</td>\n",
              "      <td>lần đầu tiên ăn chắc cũng là lần cuối ăn ở đây...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Khi mình vào thì bàn chưa dọn , dơ kinh . Cái ...</td>\n",
              "      <td>0</td>\n",
              "      <td>khi mình vào thì bàn chưa dọn dơ kinh cái bếp ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Haiz ! Không biết đúng hương_vị của bánh thế_n...</td>\n",
              "      <td>0</td>\n",
              "      <td>haiz không biết đúng hương vị của bánh thế nào...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mình ghé quán này vì thấy có cơm theo kiểu Việ...</td>\n",
              "      <td>0</td>\n",
              "      <td>mình ghé quán này vì thấy có cơm theo kiểu việ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quán xịn ở Quan_Hoa - Cầu_Giấy , biển_hiệu màu...</td>\n",
              "      <td>0</td>\n",
              "      <td>quán xịn ở quan hoa cầu giấy biển hiệu màu xan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>Quán không_gian nhỏ nhưng khá lịch_sự , sạch_s...</td>\n",
              "      <td>1</td>\n",
              "      <td>quán không gian nhỏ nhưng khá lịch sự sạch sẽ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>đi ăn lần 2 : ) ) ) lần này rút kinh_nghiệm ki...</td>\n",
              "      <td>1</td>\n",
              "      <td>đi ăn lần lần này rút kinh nghiệm kiu đồ ăn ít...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>Mình ăn 2 món , mà quên tên mất rồi , toàn từ ...</td>\n",
              "      <td>1</td>\n",
              "      <td>mình ăn món mà quên tên mất rồi toàn từ cá hồi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Trong ảnh là\\n • 1 phần mì udon xào\\n • 1 phần...</td>\n",
              "      <td>1</td>\n",
              "      <td>trong ảnh là • phần mì udon xào • phần cuốn ki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>địa_điểm : dễ tìm , mậu thân quẹo vào đường bờ...</td>\n",
              "      <td>1</td>\n",
              "      <td>địa điểm dễ tìm mậu thân quẹo vào đường bờ hồ ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label  \\\n",
              "0     Lần đầu_tiên ăn chắc cũng là lần cuối ăn_ở đây...      0   \n",
              "1     Khi mình vào thì bàn chưa dọn , dơ kinh . Cái ...      0   \n",
              "2     Haiz ! Không biết đúng hương_vị của bánh thế_n...      0   \n",
              "3     Mình ghé quán này vì thấy có cơm theo kiểu Việ...      0   \n",
              "4     Quán xịn ở Quan_Hoa - Cầu_Giấy , biển_hiệu màu...      0   \n",
              "...                                                 ...    ...   \n",
              "9995  Quán không_gian nhỏ nhưng khá lịch_sự , sạch_s...      1   \n",
              "9996  đi ăn lần 2 : ) ) ) lần này rút kinh_nghiệm ki...      1   \n",
              "9997  Mình ăn 2 món , mà quên tên mất rồi , toàn từ ...      1   \n",
              "9998  Trong ảnh là\\n • 1 phần mì udon xào\\n • 1 phần...      1   \n",
              "9999  địa_điểm : dễ tìm , mậu thân quẹo vào đường bờ...      1   \n",
              "\n",
              "                                    preprocess_sentence  \n",
              "0     lần đầu tiên ăn chắc cũng là lần cuối ăn ở đây...  \n",
              "1     khi mình vào thì bàn chưa dọn dơ kinh cái bếp ...  \n",
              "2     haiz không biết đúng hương vị của bánh thế nào...  \n",
              "3     mình ghé quán này vì thấy có cơm theo kiểu việ...  \n",
              "4     quán xịn ở quan hoa cầu giấy biển hiệu màu xan...  \n",
              "...                                                 ...  \n",
              "9995  quán không gian nhỏ nhưng khá lịch sự sạch sẽ ...  \n",
              "9996  đi ăn lần lần này rút kinh nghiệm kiu đồ ăn ít...  \n",
              "9997  mình ăn món mà quên tên mất rồi toàn từ cá hồi...  \n",
              "9998  trong ảnh là • phần mì udon xào • phần cuốn ki...  \n",
              "9999  địa điểm dễ tìm mậu thân quẹo vào đường bờ hồ ...  \n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2E1Aor_QrkrH",
        "outputId": "a6082d23-c12f-449e-eacd-1aeca9c36143"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>preprocess_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Quán này khá là nổi_tiếng nay mới có dịp ghé t...</td>\n",
              "      <td>0</td>\n",
              "      <td>quán này khá là nổi tiếng nay mới có dịp ghé t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Đây là lần đầu_tiên mình ăn_ở đây , và có_lẽ c...</td>\n",
              "      <td>0</td>\n",
              "      <td>đây là lần đầu tiên mình ăn ở đây và có lẽ cũn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tha ́ i đô ̣ phu ̣ c vu ̣ nhân_viên không tô ́...</td>\n",
              "      <td>0</td>\n",
              "      <td>tha ́ i đô ̣ phu ̣ c vu ̣ nhân viên không tô ́...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Đồ_ăn bình_thường . Cần chăm_chút không_gian h...</td>\n",
              "      <td>0</td>\n",
              "      <td>đồ ăn bình thường cần chăm chút không gian hơn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Phục_vụ lâu , giá thì ổn thôi nhưng chất_lượng...</td>\n",
              "      <td>0</td>\n",
              "      <td>phục vụ lâu giá thì ổn thôi nhưng chất lượng b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>Gia re , mon an ngon , view dep va nhan vien n...</td>\n",
              "      <td>1</td>\n",
              "      <td>gia re mon an ngon view dep va nhan vien nhiet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Quán nằm trên đường Thạch_Thị_Thanh , dễ tìm ....</td>\n",
              "      <td>1</td>\n",
              "      <td>quán nằm trên đường thạch thị thanh dễ tìm khô...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>Mình đã đến ăn_ở quán này vài lần . Đồ_ăn ngon...</td>\n",
              "      <td>1</td>\n",
              "      <td>mình đã đến ăn ở quán này vài lần đồ ăn ngon g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Nhà_hàng trang_trí độc_đáo .\\n Món ăn mới_lạ n...</td>\n",
              "      <td>1</td>\n",
              "      <td>nhà hàng trang trí độc đáo món ăn mới lạ nhiều...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>Quán có đồ uống hạt_dẻ nhất khu_vực TC . Siêu ...</td>\n",
              "      <td>1</td>\n",
              "      <td>quán có đồ uống hạt dẻ nhất khu vực tc siêu rẻ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label  \\\n",
              "0     Quán này khá là nổi_tiếng nay mới có dịp ghé t...      0   \n",
              "1     Đây là lần đầu_tiên mình ăn_ở đây , và có_lẽ c...      0   \n",
              "2     tha ́ i đô ̣ phu ̣ c vu ̣ nhân_viên không tô ́...      0   \n",
              "3     Đồ_ăn bình_thường . Cần chăm_chút không_gian h...      0   \n",
              "4     Phục_vụ lâu , giá thì ổn thôi nhưng chất_lượng...      0   \n",
              "...                                                 ...    ...   \n",
              "9995  Gia re , mon an ngon , view dep va nhan vien n...      1   \n",
              "9996  Quán nằm trên đường Thạch_Thị_Thanh , dễ tìm ....      1   \n",
              "9997  Mình đã đến ăn_ở quán này vài lần . Đồ_ăn ngon...      1   \n",
              "9998  Nhà_hàng trang_trí độc_đáo .\\n Món ăn mới_lạ n...      1   \n",
              "9999  Quán có đồ uống hạt_dẻ nhất khu_vực TC . Siêu ...      1   \n",
              "\n",
              "                                    preprocess_sentence  \n",
              "0     quán này khá là nổi tiếng nay mới có dịp ghé t...  \n",
              "1     đây là lần đầu tiên mình ăn ở đây và có lẽ cũn...  \n",
              "2     tha ́ i đô ̣ phu ̣ c vu ̣ nhân viên không tô ́...  \n",
              "3     đồ ăn bình thường cần chăm chút không gian hơn...  \n",
              "4     phục vụ lâu giá thì ổn thôi nhưng chất lượng b...  \n",
              "...                                                 ...  \n",
              "9995  gia re mon an ngon view dep va nhan vien nhiet...  \n",
              "9996  quán nằm trên đường thạch thị thanh dễ tìm khô...  \n",
              "9997  mình đã đến ăn ở quán này vài lần đồ ăn ngon g...  \n",
              "9998  nhà hàng trang trí độc đáo món ăn mới lạ nhiều...  \n",
              "9999  quán có đồ uống hạt dẻ nhất khu vực tc siêu rẻ...  \n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTCMBQYBrkrH"
      },
      "source": [
        "###**2.3. EDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "COQLpMherkrI",
        "outputId": "a931d19e-1021-4224-99c7-47f69424c275"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist([len(sentence.split()) for sentence in train_df_vi['preprocess_sentence']], bins=128, range=(0, 500))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\cang_\\AppData\\Local\\Temp\\ipykernel_21004\\2327715662.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df_vi['word_length'] = [len(sentence.split()) for sentence in train_df_vi['preprocess_sentence']]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "96.07200026903416"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df_vi['word_length'] = [len(sentence.split()) for sentence in train_df_vi['preprocess_sentence']]\n",
        "train_df_vi['word_length'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gelwynLrkrI",
        "outputId": "302cfd5f-bee1-49be-b266-4e98b5ee105b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(17244, 2856797)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count: words and vocabulary\n",
        "from collections import Counter\n",
        "\n",
        "words = []\n",
        "[[words.append(word) for word in sentence.split()] for sentence in train_df_vi['preprocess_sentence']]\n",
        "vocabulary = Counter(words)\n",
        "len(vocabulary), len(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTngnKOjrkrI"
      },
      "source": [
        "##**3. Text Representation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLa5qvofrkrI"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchtext==0.16.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nZ4BdhivrkrI"
      },
      "outputs": [],
      "source": [
        "def yield_tokens(sentences, tokenizer):\n",
        "    for sentence in sentences:\n",
        "        yield tokenizer(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "p1UCYZoGrkrI"
      },
      "outputs": [],
      "source": [
        "# word-based tokenizer\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGFoXsI2rkrI",
        "outputId": "0b88db1f-0858-4d9a-e58b-a2f72d89b520"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['mua', 'có', 'mỗi', 'bingsu', 'thập']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(train_df_vi['preprocess_sentence'][0])[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "u-wJZOkyrkrI"
      },
      "outputs": [],
      "source": [
        "# build vocabulary\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "vocab_size = 15000\n",
        "vocabulary = build_vocab_from_iterator(\n",
        "    yield_tokens(train_df_vi['preprocess_sentence'], tokenizer),\n",
        "    max_tokens=vocab_size,\n",
        "    specials=[\"<unk>\"]\n",
        ")\n",
        "vocabulary.set_default_index(vocabulary[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuUHX2ERrkrI",
        "outputId": "4a567df9-5016-44e7-8078-48af4b1d77df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15000"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<unk>', 'ăn', 'mình', 'có', 'là']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get 5 examples from vocabulary\n",
        "[vocabulary.get_itos()[idx] for idx in range(5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juODl39drkrI",
        "outputId": "cdf63648-2766-4adf-800b-d66910c7ad71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[140, 3, 205, 890, 913, 856, 13, 15, 2, 2556, 241, 76, 186, 20, 7, 369, 2495, 3, 565, 1280, 213, 282, 96, 56, 419, 606, 2777, 659, 2, 13, 120, 3, 10, 13, 1280, 9, 175, 1, 98, 648, 331, 369, 6, 17, 287, 20, 189, 1375, 8, 689, 277, 60]\n"
          ]
        }
      ],
      "source": [
        "# encode text\n",
        "\n",
        "print(vocabulary(tokenizer(train_df_vi['preprocess_sentence'][0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2mcguTvNrkrI"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "def prepare_dataset(df):\n",
        "    for index, row in df.iterrows():\n",
        "        sentence = row['preprocess_sentence']\n",
        "        encoded_sentence = vocabulary(tokenizer(sentence))\n",
        "        label = row['label']\n",
        "        yield encoded_sentence, label\n",
        "\n",
        "train_dataset = prepare_dataset(train_df_vi)\n",
        "train_dataset = to_map_style_dataset(train_dataset)\n",
        "\n",
        "valid_dataset = prepare_dataset(valid_df)\n",
        "valid_dataset = to_map_style_dataset(valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60vRr0MprkrI",
        "outputId": "2a976e01-c956-433e-d55c-8e24d7477dc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[([140, 3, 205, 890, 913, 856, 13, 15, 2, 2556, 241, 76, 186, 20, 7, 369, 2495, 3, 565, 1280, 213, 282, 96, 56, 419, 606, 2777, 659, 2, 13, 120, 3, 10, 13, 1280, 9, 175, 1, 98, 648, 331, 369, 6, 17, 287, 20, 189, 1375, 8, 689, 277, 60], 0), ([215, 77, 430, 183, 1519, 3539, 1606, 2040, 114, 1127, 875, 1783, 1847, 5774, 2415, 2415, 17, 30, 9, 125, 1386, 393, 921, 161, 988, 2588, 211, 136, 444, 164, 1, 171, 34, 136, 444, 9, 2454, 84, 539, 1264, 9, 193, 164, 1, 9, 249, 3, 92, 21, 475, 899, 130, 154, 1135, 1558, 94, 77, 195, 17, 159, 19, 1, 425, 15, 61, 92, 21, 78, 9, 25, 3, 110, 736, 1469, 530, 190, 364, 475, 200, 1469, 530, 15, 253, 790, 69, 23, 5589, 530, 5, 23, 107, 1469, 530, 186, 606, 369, 606, 377, 186, 101, 543, 136, 441, 474, 4, 135, 736, 136, 171, 921, 139, 126, 949, 325, 199, 3272, 157, 5, 51, 475, 200, 182, 552, 2296, 40, 115, 68, 819, 123, 333, 22, 1519, 67, 136, 533, 137, 10631, 1974, 136], 0)]\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMKuBpU5rkrI",
        "outputId": "a838e979-5f9a-4d33-9ec2-8b8bff95fccd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29736"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ko0lUrdrkrI"
      },
      "source": [
        "##**4. Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "jOW5Jb5arkrI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def collate_batch(batch):\n",
        "    encoded_sentences, labels, offsets = [], [], [0]\n",
        "    for encoded_sentence, label in batch:\n",
        "        labels.append(label)\n",
        "        encoded_sentence = torch.tensor(encoded_sentence, dtype=torch.int64)\n",
        "        encoded_sentences.append(encoded_sentence)\n",
        "        offsets.append(encoded_sentence.size(0))\n",
        "\n",
        "    labels = torch.tensor(labels, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    encoded_sentences = torch.cat(encoded_sentences)\n",
        "    return encoded_sentences.to(device), offsets.to(device), labels.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "cKL2q3jhrkrI"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni8qkz4ZrkrI",
        "outputId": "e2dfedc6-7e49-4139-ab1d-c8099ac918d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((tensor([141,  66,  65,  ..., 950,   8, 222]),\n",
              "  tensor([    0,    98,   182,   239,   774,   795,   845,  1015,  1084,  1168,\n",
              "           1323,  1394,  1459,  1494,  1523,  1545,  1654,  1690,  1724,  1878,\n",
              "           2185,  2226,  2335,  2424,  2462,  2522,  2637,  2769,  2797,  2862,\n",
              "           2892,  3039,  3110,  3172,  3395,  3516,  3688,  3769,  3799,  3860,\n",
              "           3956,  4066,  4186,  4242,  4266,  4342,  4366,  4732,  4971,  5003,\n",
              "           5125,  5226,  5334,  5448,  5576,  5595,  5622,  5687,  5753,  6340,\n",
              "           6593,  6749,  6846,  6878,  7062,  7118,  7163,  7225,  7315,  7351,\n",
              "           7644,  7666,  7716,  7757,  7789,  7842,  7862,  7905,  8010,  8075,\n",
              "           8112,  8277,  8303,  8342,  8471,  8490,  8517,  8762,  8779,  8850,\n",
              "           9094,  9205,  9318,  9406,  9488,  9546,  9654,  9699,  9714,  9783,\n",
              "           9828,  9956, 10036, 10062, 10252, 10294, 10403, 10449, 10523, 10942,\n",
              "          11026, 11051, 11122, 11168, 11354, 11401, 11451, 11543, 11574, 11643,\n",
              "          11823, 11848, 11955, 12027, 12058, 12205, 12308, 12390]),\n",
              "  tensor([1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "          1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "          1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "          0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "          0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
              "          1, 1, 1, 0, 1, 1, 1, 1])),\n",
              " 233)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(train_dataloader)), len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "fZZSwzRdrkrM"
      },
      "outputs": [],
      "source": [
        "encoded_sentences, offsets, labels = next(iter(train_dataloader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjwdFHzirkrM",
        "outputId": "13147d3e-97f7-4c7b-cb2c-86d9733c4e79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([13922])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_sentences.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWRRzmcsrkrM"
      },
      "source": [
        "##**4. Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cdw4BpxubgL"
      },
      "source": [
        "**Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "BAdJN-qNs4my"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class, seq_len):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.ft = nn.Flatten()\n",
        "        self.fc = nn.Linear(seq_len*embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embedded = self.embedding(inputs)\n",
        "        ouput = self.ft(embedded)\n",
        "        return self.fc(ouput)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUXrU8r1tbaF",
        "outputId": "d4ff0af8-0863-45cf-ff31-29e6d14d4e94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.int32)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 5\n",
        "seq_len = 10\n",
        "input = torch.ones([batch_size, seq_len], dtype=torch.int32)\n",
        "input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "iVj8TDKetVYP"
      },
      "outputs": [],
      "source": [
        "num_class = 2\n",
        "vocab_size = 5000\n",
        "embed_dim = 100\n",
        "model = TextClassificationModel(vocab_size, embed_dim, num_class, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBcAy0sPtZtY",
        "outputId": "93503e72-66d2-48ba-a38a-2ec746c21036"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TextClassificationModel(\n",
              "  (embedding): Embedding(5000, 100)\n",
              "  (ft): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc): Linear(in_features=1000, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXi-FvjqtudC",
        "outputId": "044a501a-0ce6-4dd7-aef3-211325afea3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-5.5052, -2.3935],\n",
              "        [-5.5052, -2.3935],\n",
              "        [-5.5052, -2.3935],\n",
              "        [-5.5052, -2.3935],\n",
              "        [-5.5052, -2.3935]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = model(input)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CO2WbmIuhvi"
      },
      "source": [
        "**EmbeddingBag**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "-MzIQJHHrkrM"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "        self.PReLU1 = nn.PReLU()\n",
        "        self.PReLU2 = nn.PReLU()\n",
        "        self.fc1 = nn.Linear(embed_dim, embed_dim)\n",
        "        self.fc = nn.Linear(embed_dim, embed_dim)\n",
        "        self.fc2 = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, inputs, offsets):\n",
        "        embedded = self.embedding(inputs, offsets)\n",
        "        x = self.fc1(embedded)\n",
        "        x = self.PReLU1(x)\n",
        "        x = self.fc(x)\n",
        "        x = self.PReLU2(x)\n",
        "        return self.fc2(x)\n",
        "        return self.fc(x)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "QCeXbqv_rkrM"
      },
      "outputs": [],
      "source": [
        "num_class = len(set(train_df_vi['label']))\n",
        "vocab_size = len(vocabulary)\n",
        "embed_dim = 100\n",
        "model = TextClassificationModel(vocab_size, embed_dim, num_class).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBQz8qHrrkrM",
        "outputId": "7a3c276e-f0ff-4eff-9b90-2a6147c55e3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TextClassificationModel(\n",
              "  (embedding): EmbeddingBag(15000, 100, mode='mean')\n",
              "  (fc): Linear(in_features=100, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "9-7uJ-BPrkrM"
      },
      "outputs": [],
      "source": [
        "predictions = model(encoded_sentences, offsets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RtSETL2rkrM",
        "outputId": "d2f0893f-9651-46b5-aa9a-57e97053c329"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-2.0086e-02,  2.8112e-01],\n",
              "        [-1.1832e-01, -3.6598e-02],\n",
              "        [-7.9191e-02, -5.1912e-02],\n",
              "        [-4.4154e-02, -6.3796e-03],\n",
              "        [-2.1491e-02, -7.9818e-02],\n",
              "        [-3.4681e-02,  1.6898e-01],\n",
              "        [-7.0273e-02,  8.4102e-02],\n",
              "        [ 7.5822e-02, -1.6786e-02],\n",
              "        [-2.3080e-01, -3.5009e-02],\n",
              "        [-7.4297e-02,  7.4112e-02],\n",
              "        [ 4.7225e-02,  1.4522e-01],\n",
              "        [-1.3493e-01,  3.9849e-01],\n",
              "        [-1.5540e-01, -5.7177e-02],\n",
              "        [ 3.5263e-02,  2.8159e-02],\n",
              "        [-1.0945e-01,  5.6283e-02],\n",
              "        [-1.1328e-01,  1.4030e-01],\n",
              "        [-8.7484e-02,  2.0849e-02],\n",
              "        [-1.1612e-01,  1.3141e-01],\n",
              "        [-1.1125e-01,  1.0637e-01],\n",
              "        [-1.6419e-01,  5.1804e-02],\n",
              "        [-1.1674e-02,  4.0329e-02],\n",
              "        [-2.0917e-02,  3.1015e-02],\n",
              "        [ 5.3730e-02,  2.4477e-01],\n",
              "        [-4.2205e-02,  4.0961e-02],\n",
              "        [-1.1060e-01,  9.4485e-02],\n",
              "        [ 1.6470e-02,  6.2281e-02],\n",
              "        [-1.6819e-02,  1.0195e-02],\n",
              "        [-3.9308e-01, -1.7733e-01],\n",
              "        [-3.5494e-01,  6.7854e-02],\n",
              "        [-1.2255e-02,  3.7442e-02],\n",
              "        [-1.3060e-01,  6.6450e-02],\n",
              "        [-1.2193e-01, -2.8930e-03],\n",
              "        [-7.8611e-02,  3.2768e-01],\n",
              "        [-1.0991e-01,  2.1643e-02],\n",
              "        [ 2.0932e-01,  2.4948e-01],\n",
              "        [-2.4361e-01,  9.0349e-02],\n",
              "        [ 2.3193e-01,  2.1571e-01],\n",
              "        [ 1.8482e-01,  2.5251e-01],\n",
              "        [-1.1528e-01, -4.8291e-02],\n",
              "        [-9.3133e-02, -2.7178e-01],\n",
              "        [-5.8590e-02,  2.9706e-01],\n",
              "        [ 5.5993e-02,  1.6682e-01],\n",
              "        [-4.4626e-02,  8.3575e-02],\n",
              "        [ 1.0078e-01,  7.1908e-02],\n",
              "        [-1.8862e-01, -5.9811e-02],\n",
              "        [-1.4937e-01,  8.6183e-02],\n",
              "        [ 3.9891e-02,  1.2196e-01],\n",
              "        [-7.9986e-02, -4.7731e-02],\n",
              "        [ 7.1763e-02,  2.0720e-01],\n",
              "        [-1.3423e-01,  1.3414e-01],\n",
              "        [-1.0483e-02,  1.9503e-01],\n",
              "        [ 8.8690e-02,  3.6986e-02],\n",
              "        [-2.1095e-01, -1.8589e-02],\n",
              "        [-1.1484e-02,  6.5056e-02],\n",
              "        [-4.8300e-02,  9.3513e-02],\n",
              "        [-1.5765e-02,  3.2029e-02],\n",
              "        [-3.1812e-02, -3.9906e-02],\n",
              "        [-1.1663e-01, -5.1290e-02],\n",
              "        [-1.6945e-01, -5.6626e-02],\n",
              "        [ 1.0760e-02,  1.7561e-01],\n",
              "        [-4.7273e-02,  5.1946e-02],\n",
              "        [ 6.8652e-02, -8.1606e-02],\n",
              "        [-4.0931e-02, -8.1522e-02],\n",
              "        [-4.8149e-03,  8.9452e-02],\n",
              "        [-3.9659e-02, -1.2903e-02],\n",
              "        [ 2.8440e-02,  1.1973e-01],\n",
              "        [-3.7248e-01, -8.6012e-02],\n",
              "        [-3.7654e-02,  2.2554e-03],\n",
              "        [-4.8186e-02,  3.1785e-01],\n",
              "        [-1.0161e-01, -5.1499e-03],\n",
              "        [-1.6588e-01,  1.0249e-01],\n",
              "        [-1.9146e-01, -8.4164e-03],\n",
              "        [ 6.0436e-02,  1.9791e-01],\n",
              "        [-3.2401e-02,  4.4452e-02],\n",
              "        [-4.5664e-02, -2.3181e-01],\n",
              "        [-1.9077e-01,  4.2699e-02],\n",
              "        [-9.3399e-02,  1.1221e-01],\n",
              "        [-1.8259e-02,  1.7193e-01],\n",
              "        [ 6.1982e-02,  1.6600e-01],\n",
              "        [-5.9066e-02,  6.7129e-02],\n",
              "        [-1.3553e-01, -5.9215e-02],\n",
              "        [-1.4257e-01, -3.7592e-01],\n",
              "        [-1.4338e-01,  6.6390e-02],\n",
              "        [-1.1701e-01, -1.3440e-01],\n",
              "        [-2.2381e-01, -1.6785e-04],\n",
              "        [ 6.5010e-02, -4.5415e-03],\n",
              "        [-1.0022e-01,  1.4779e-01],\n",
              "        [ 1.5547e-02,  1.4659e-01],\n",
              "        [ 7.9926e-03,  7.5317e-03],\n",
              "        [-3.5602e-02,  1.1100e-01],\n",
              "        [-1.4009e-01,  3.0540e-01],\n",
              "        [-5.0302e-02,  3.7541e-02],\n",
              "        [ 4.3030e-02,  3.8421e-02],\n",
              "        [ 4.3067e-02, -4.7873e-02],\n",
              "        [-2.2912e-02,  4.1931e-02],\n",
              "        [ 6.2461e-02,  5.5371e-02],\n",
              "        [ 2.3861e-01,  1.0963e-01],\n",
              "        [ 7.6591e-02, -1.5334e-02],\n",
              "        [-1.5997e-01,  8.0801e-02],\n",
              "        [-3.6718e-01, -1.3104e-01],\n",
              "        [ 1.3321e-01, -3.9333e-02],\n",
              "        [ 7.5887e-03, -4.9044e-03],\n",
              "        [-1.0885e-01, -6.0251e-02],\n",
              "        [-2.5074e-01,  4.0423e-01],\n",
              "        [ 3.3658e-01,  1.8214e-01],\n",
              "        [-1.1735e-02, -1.9083e-01],\n",
              "        [-1.3979e-01,  1.8413e-02],\n",
              "        [-1.1995e-01,  9.5046e-02],\n",
              "        [ 1.6863e-01,  6.6369e-02],\n",
              "        [ 3.0960e-03,  3.2615e-02],\n",
              "        [ 3.8231e-02,  9.0653e-02],\n",
              "        [-1.8756e-01, -3.0852e-01],\n",
              "        [-4.6239e-02,  4.3557e-02],\n",
              "        [-1.3610e-01,  7.1738e-02],\n",
              "        [-5.8093e-02,  7.1149e-02],\n",
              "        [ 6.4261e-03,  2.3657e-01],\n",
              "        [-1.4445e-01, -1.5560e-01],\n",
              "        [-7.9740e-02,  9.9143e-02],\n",
              "        [-1.5742e-01, -1.5830e-01],\n",
              "        [ 4.3392e-02,  9.0839e-02],\n",
              "        [-4.4258e-02,  1.4109e-01],\n",
              "        [-6.4203e-02,  4.1162e-02],\n",
              "        [-2.8703e-01,  6.2007e-02],\n",
              "        [ 5.3472e-02,  6.2674e-03],\n",
              "        [-8.2442e-02,  2.7334e-03],\n",
              "        [-1.3759e-01,  6.0443e-02],\n",
              "        [-9.4425e-02, -5.6637e-02],\n",
              "        [-7.5266e-02,  2.0603e-02]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "PqmzZd4LrkrM"
      },
      "outputs": [],
      "source": [
        "learning_rate = 2e-5\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "N35e3MAbrkrN"
      },
      "outputs": [],
      "source": [
        "loss = criterion(predictions, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "o5H5qOf4rkrN",
        "outputId": "88c9251d-1aae-48df-de42-d0b1bc41339e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.6988, grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xk3-L3vrkrN"
      },
      "source": [
        "##**5. Trainer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "_w8deMpMrkrN"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train(model, optimizer, criterion, train_dataloader, epoch=0, log_interval=50):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    losses = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (inputs, offsets, labels) in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(inputs, offsets)\n",
        "\n",
        "        # compute loss\n",
        "        loss = criterion(predictions, labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predictions.argmax(1) == labels).sum().item()\n",
        "        total_count += labels.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
        "                \"| accuracy {:8.3f}\".format(\n",
        "                    epoch, idx, len(train_dataloader), total_acc / total_count\n",
        "                )\n",
        "            )\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "    epoch_acc = total_acc / total_count\n",
        "    epoch_loss = sum(losses) / len(losses)\n",
        "    return epoch_acc, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "oYfPqPCHrkrN",
        "outputId": "df3a401b-3ff2-4c59-88a9-420ecf0a9278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   0 |    50/  233 batches | accuracy    0.516\n",
            "| epoch   0 |   100/  233 batches | accuracy    0.504\n",
            "| epoch   0 |   150/  233 batches | accuracy    0.510\n",
            "| epoch   0 |   200/  233 batches | accuracy    0.519\n"
          ]
        }
      ],
      "source": [
        "epoch_acc, epoch_loss = train(model, optimizer, criterion, train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "a9X0KkvbrkrN",
        "outputId": "db873b22-a20e-4983-c0fa-7260197193cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.5032435129740519, 0.6948716149309674)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epoch_acc, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "hnzySNicrkrN"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, criterion, valid_dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (inputs, offsets, labels) in enumerate(valid_dataloader):\n",
        "            predictions = model(inputs, offsets)\n",
        "            loss = criterion(predictions, labels)\n",
        "            losses.append(loss)\n",
        "            total_acc += (predictions.argmax(1) == labels).sum().item()\n",
        "            total_count += labels.size(0)\n",
        "\n",
        "    epoch_acc = total_acc / total_count\n",
        "    epoch_loss = sum(losses) / len(losses)\n",
        "    return epoch_acc, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "8SrvGy7IrkrN"
      },
      "outputs": [],
      "source": [
        "eval_acc, eval_loss = evaluate(model, criterion, valid_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "uXhewV1WrkrN",
        "outputId": "46851bf5-d939-4a2f-81a0-0117f5bde952"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.5119, tensor(0.6939))"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_acc, eval_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn8cMmQwrkrN"
      },
      "source": [
        "##**6. Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wiGb67FrkrN",
        "outputId": "e7e25301-b9b8-43f1-fc16-55ba3dfc463f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |    50/  233 batches | accuracy    0.545\n",
            "| epoch   1 |   100/  233 batches | accuracy    0.636\n",
            "| epoch   1 |   150/  233 batches | accuracy    0.714\n",
            "| epoch   1 |   200/  233 batches | accuracy    0.759\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   1 | Time:  1.51s | Train Accuracy    0.769 | Train Loss    0.569 | Valid Accuracy    0.792 | Valid Loss    0.464 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |    50/  233 batches | accuracy    0.790\n",
            "| epoch   2 |   100/  233 batches | accuracy    0.796\n",
            "| epoch   2 |   150/  233 batches | accuracy    0.811\n",
            "| epoch   2 |   200/  233 batches | accuracy    0.809\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   2 | Time:  1.45s | Train Accuracy    0.830 | Train Loss    0.433 | Valid Accuracy    0.834 | Valid Loss    0.400 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |    50/  233 batches | accuracy    0.829\n",
            "| epoch   3 |   100/  233 batches | accuracy    0.837\n",
            "| epoch   3 |   150/  233 batches | accuracy    0.843\n",
            "| epoch   3 |   200/  233 batches | accuracy    0.844\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   3 | Time:  1.50s | Train Accuracy    0.851 | Train Loss    0.377 | Valid Accuracy    0.843 | Valid Loss    0.383 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |    50/  233 batches | accuracy    0.851\n",
            "| epoch   4 |   100/  233 batches | accuracy    0.852\n",
            "| epoch   4 |   150/  233 batches | accuracy    0.859\n",
            "| epoch   4 |   200/  233 batches | accuracy    0.855\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   4 | Time:  1.50s | Train Accuracy    0.851 | Train Loss    0.351 | Valid Accuracy    0.851 | Valid Loss    0.371 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |    50/  233 batches | accuracy    0.856\n",
            "| epoch   5 |   100/  233 batches | accuracy    0.862\n",
            "| epoch   5 |   150/  233 batches | accuracy    0.867\n",
            "| epoch   5 |   200/  233 batches | accuracy    0.863\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   5 | Time:  1.41s | Train Accuracy    0.856 | Train Loss    0.331 | Valid Accuracy    0.858 | Valid Loss    0.349 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |    50/  233 batches | accuracy    0.872\n",
            "| epoch   6 |   100/  233 batches | accuracy    0.873\n",
            "| epoch   6 |   150/  233 batches | accuracy    0.872\n",
            "| epoch   6 |   200/  233 batches | accuracy    0.866\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   6 | Time:  1.43s | Train Accuracy    0.869 | Train Loss    0.317 | Valid Accuracy    0.866 | Valid Loss    0.328 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |    50/  233 batches | accuracy    0.885\n",
            "| epoch   7 |   100/  233 batches | accuracy    0.877\n",
            "| epoch   7 |   150/  233 batches | accuracy    0.868\n",
            "| epoch   7 |   200/  233 batches | accuracy    0.871\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   7 | Time:  1.43s | Train Accuracy    0.883 | Train Loss    0.304 | Valid Accuracy    0.860 | Valid Loss    0.348 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |    50/  233 batches | accuracy    0.878\n",
            "| epoch   8 |   100/  233 batches | accuracy    0.875\n",
            "| epoch   8 |   150/  233 batches | accuracy    0.881\n",
            "| epoch   8 |   200/  233 batches | accuracy    0.883\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   8 | Time:  1.43s | Train Accuracy    0.880 | Train Loss    0.297 | Valid Accuracy    0.869 | Valid Loss    0.327 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |    50/  233 batches | accuracy    0.884\n",
            "| epoch   9 |   100/  233 batches | accuracy    0.881\n",
            "| epoch   9 |   150/  233 batches | accuracy    0.885\n",
            "| epoch   9 |   200/  233 batches | accuracy    0.878\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   9 | Time:  1.46s | Train Accuracy    0.883 | Train Loss    0.287 | Valid Accuracy    0.867 | Valid Loss    0.333 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |    50/  233 batches | accuracy    0.881\n",
            "| epoch  10 |   100/  233 batches | accuracy    0.888\n",
            "| epoch  10 |   150/  233 batches | accuracy    0.887\n",
            "| epoch  10 |   200/  233 batches | accuracy    0.888\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  10 | Time:  1.43s | Train Accuracy    0.887 | Train Loss    0.279 | Valid Accuracy    0.859 | Valid Loss    0.332 \n",
            "-----------------------------------------------------------\n",
            "| epoch  11 |    50/  233 batches | accuracy    0.889\n",
            "| epoch  11 |   100/  233 batches | accuracy    0.896\n",
            "| epoch  11 |   150/  233 batches | accuracy    0.880\n",
            "| epoch  11 |   200/  233 batches | accuracy    0.886\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  11 | Time:  1.41s | Train Accuracy    0.891 | Train Loss    0.273 | Valid Accuracy    0.864 | Valid Loss    0.332 \n",
            "-----------------------------------------------------------\n",
            "| epoch  12 |    50/  233 batches | accuracy    0.891\n",
            "| epoch  12 |   100/  233 batches | accuracy    0.900\n",
            "| epoch  12 |   150/  233 batches | accuracy    0.892\n",
            "| epoch  12 |   200/  233 batches | accuracy    0.887\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  12 | Time:  1.42s | Train Accuracy    0.890 | Train Loss    0.267 | Valid Accuracy    0.865 | Valid Loss    0.327 \n",
            "-----------------------------------------------------------\n",
            "| epoch  13 |    50/  233 batches | accuracy    0.891\n",
            "| epoch  13 |   100/  233 batches | accuracy    0.888\n",
            "| epoch  13 |   150/  233 batches | accuracy    0.889\n",
            "| epoch  13 |   200/  233 batches | accuracy    0.899\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  13 | Time:  1.45s | Train Accuracy    0.905 | Train Loss    0.261 | Valid Accuracy    0.872 | Valid Loss    0.337 \n",
            "-----------------------------------------------------------\n",
            "| epoch  14 |    50/  233 batches | accuracy    0.900\n",
            "| epoch  14 |   100/  233 batches | accuracy    0.892\n",
            "| epoch  14 |   150/  233 batches | accuracy    0.896\n",
            "| epoch  14 |   200/  233 batches | accuracy    0.895\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  14 | Time:  1.43s | Train Accuracy    0.890 | Train Loss    0.257 | Valid Accuracy    0.867 | Valid Loss    0.324 \n",
            "-----------------------------------------------------------\n",
            "| epoch  15 |    50/  233 batches | accuracy    0.898\n",
            "| epoch  15 |   100/  233 batches | accuracy    0.897\n",
            "| epoch  15 |   150/  233 batches | accuracy    0.900\n",
            "| epoch  15 |   200/  233 batches | accuracy    0.907\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  15 | Time:  1.46s | Train Accuracy    0.896 | Train Loss    0.250 | Valid Accuracy    0.872 | Valid Loss    0.340 \n",
            "-----------------------------------------------------------\n",
            "| epoch  16 |    50/  233 batches | accuracy    0.904\n",
            "| epoch  16 |   100/  233 batches | accuracy    0.902\n",
            "| epoch  16 |   150/  233 batches | accuracy    0.902\n",
            "| epoch  16 |   200/  233 batches | accuracy    0.900\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  16 | Time:  1.43s | Train Accuracy    0.903 | Train Loss    0.244 | Valid Accuracy    0.873 | Valid Loss    0.358 \n",
            "-----------------------------------------------------------\n",
            "| epoch  17 |    50/  233 batches | accuracy    0.902\n",
            "| epoch  17 |   100/  233 batches | accuracy    0.898\n",
            "| epoch  17 |   150/  233 batches | accuracy    0.902\n",
            "| epoch  17 |   200/  233 batches | accuracy    0.907\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  17 | Time:  1.46s | Train Accuracy    0.906 | Train Loss    0.241 | Valid Accuracy    0.874 | Valid Loss    0.326 \n",
            "-----------------------------------------------------------\n",
            "| epoch  18 |    50/  233 batches | accuracy    0.905\n",
            "| epoch  18 |   100/  233 batches | accuracy    0.906\n",
            "| epoch  18 |   150/  233 batches | accuracy    0.907\n",
            "| epoch  18 |   200/  233 batches | accuracy    0.906\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  18 | Time:  1.45s | Train Accuracy    0.905 | Train Loss    0.235 | Valid Accuracy    0.875 | Valid Loss    0.308 \n",
            "-----------------------------------------------------------\n",
            "| epoch  19 |    50/  233 batches | accuracy    0.909\n",
            "| epoch  19 |   100/  233 batches | accuracy    0.910\n",
            "| epoch  19 |   150/  233 batches | accuracy    0.902\n",
            "| epoch  19 |   200/  233 batches | accuracy    0.907\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  19 | Time:  1.41s | Train Accuracy    0.909 | Train Loss    0.231 | Valid Accuracy    0.875 | Valid Loss    0.318 \n",
            "-----------------------------------------------------------\n",
            "| epoch  20 |    50/  233 batches | accuracy    0.916\n",
            "| epoch  20 |   100/  233 batches | accuracy    0.907\n",
            "| epoch  20 |   150/  233 batches | accuracy    0.910\n",
            "| epoch  20 |   200/  233 batches | accuracy    0.907\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  20 | Time:  1.44s | Train Accuracy    0.906 | Train Loss    0.226 | Valid Accuracy    0.876 | Valid Loss    0.317 \n",
            "-----------------------------------------------------------\n",
            "| epoch  21 |    50/  233 batches | accuracy    0.914\n",
            "| epoch  21 |   100/  233 batches | accuracy    0.911\n",
            "| epoch  21 |   150/  233 batches | accuracy    0.913\n",
            "| epoch  21 |   200/  233 batches | accuracy    0.910\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  21 | Time:  1.44s | Train Accuracy    0.909 | Train Loss    0.221 | Valid Accuracy    0.850 | Valid Loss    0.384 \n",
            "-----------------------------------------------------------\n",
            "| epoch  22 |    50/  233 batches | accuracy    0.908\n",
            "| epoch  22 |   100/  233 batches | accuracy    0.923\n",
            "| epoch  22 |   150/  233 batches | accuracy    0.914\n",
            "| epoch  22 |   200/  233 batches | accuracy    0.913\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  22 | Time:  1.44s | Train Accuracy    0.907 | Train Loss    0.217 | Valid Accuracy    0.876 | Valid Loss    0.330 \n",
            "-----------------------------------------------------------\n",
            "| epoch  23 |    50/  233 batches | accuracy    0.919\n",
            "| epoch  23 |   100/  233 batches | accuracy    0.910\n",
            "| epoch  23 |   150/  233 batches | accuracy    0.912\n",
            "| epoch  23 |   200/  233 batches | accuracy    0.917\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  23 | Time:  1.44s | Train Accuracy    0.923 | Train Loss    0.212 | Valid Accuracy    0.873 | Valid Loss    0.340 \n",
            "-----------------------------------------------------------\n",
            "| epoch  24 |    50/  233 batches | accuracy    0.919\n",
            "| epoch  24 |   100/  233 batches | accuracy    0.915\n",
            "| epoch  24 |   150/  233 batches | accuracy    0.911\n",
            "| epoch  24 |   200/  233 batches | accuracy    0.920\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  24 | Time:  1.45s | Train Accuracy    0.918 | Train Loss    0.209 | Valid Accuracy    0.858 | Valid Loss    0.358 \n",
            "-----------------------------------------------------------\n",
            "| epoch  25 |    50/  233 batches | accuracy    0.922\n",
            "| epoch  25 |   100/  233 batches | accuracy    0.918\n",
            "| epoch  25 |   150/  233 batches | accuracy    0.919\n",
            "| epoch  25 |   200/  233 batches | accuracy    0.917\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  25 | Time:  1.45s | Train Accuracy    0.918 | Train Loss    0.203 | Valid Accuracy    0.866 | Valid Loss    0.365 \n",
            "-----------------------------------------------------------\n",
            "| epoch  26 |    50/  233 batches | accuracy    0.921\n",
            "| epoch  26 |   100/  233 batches | accuracy    0.924\n",
            "| epoch  26 |   150/  233 batches | accuracy    0.916\n",
            "| epoch  26 |   200/  233 batches | accuracy    0.924\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  26 | Time:  1.45s | Train Accuracy    0.918 | Train Loss    0.197 | Valid Accuracy    0.868 | Valid Loss    0.350 \n",
            "-----------------------------------------------------------\n",
            "| epoch  27 |    50/  233 batches | accuracy    0.928\n",
            "| epoch  27 |   100/  233 batches | accuracy    0.924\n",
            "| epoch  27 |   150/  233 batches | accuracy    0.919\n",
            "| epoch  27 |   200/  233 batches | accuracy    0.922\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  27 | Time:  1.45s | Train Accuracy    0.924 | Train Loss    0.194 | Valid Accuracy    0.871 | Valid Loss    0.359 \n",
            "-----------------------------------------------------------\n",
            "| epoch  28 |    50/  233 batches | accuracy    0.930\n",
            "| epoch  28 |   100/  233 batches | accuracy    0.928\n",
            "| epoch  28 |   150/  233 batches | accuracy    0.922\n",
            "| epoch  28 |   200/  233 batches | accuracy    0.928\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  28 | Time:  1.43s | Train Accuracy    0.925 | Train Loss    0.185 | Valid Accuracy    0.873 | Valid Loss    0.342 \n",
            "-----------------------------------------------------------\n",
            "| epoch  29 |    50/  233 batches | accuracy    0.933\n",
            "| epoch  29 |   100/  233 batches | accuracy    0.929\n",
            "| epoch  29 |   150/  233 batches | accuracy    0.932\n",
            "| epoch  29 |   200/  233 batches | accuracy    0.925\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  29 | Time:  1.42s | Train Accuracy    0.929 | Train Loss    0.183 | Valid Accuracy    0.850 | Valid Loss    0.431 \n",
            "-----------------------------------------------------------\n",
            "| epoch  30 |    50/  233 batches | accuracy    0.934\n",
            "| epoch  30 |   100/  233 batches | accuracy    0.934\n",
            "| epoch  30 |   150/  233 batches | accuracy    0.928\n",
            "| epoch  30 |   200/  233 batches | accuracy    0.931\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  30 | Time:  1.42s | Train Accuracy    0.930 | Train Loss    0.175 | Valid Accuracy    0.860 | Valid Loss    0.386 \n",
            "-----------------------------------------------------------\n",
            "| epoch  31 |    50/  233 batches | accuracy    0.932\n",
            "| epoch  31 |   100/  233 batches | accuracy    0.936\n",
            "| epoch  31 |   150/  233 batches | accuracy    0.935\n",
            "| epoch  31 |   200/  233 batches | accuracy    0.927\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  31 | Time:  1.46s | Train Accuracy    0.934 | Train Loss    0.173 | Valid Accuracy    0.869 | Valid Loss    0.359 \n",
            "-----------------------------------------------------------\n",
            "| epoch  32 |    50/  233 batches | accuracy    0.938\n",
            "| epoch  32 |   100/  233 batches | accuracy    0.936\n",
            "| epoch  32 |   150/  233 batches | accuracy    0.935\n",
            "| epoch  32 |   200/  233 batches | accuracy    0.932\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  32 | Time:  1.41s | Train Accuracy    0.930 | Train Loss    0.166 | Valid Accuracy    0.873 | Valid Loss    0.369 \n",
            "-----------------------------------------------------------\n",
            "| epoch  33 |    50/  233 batches | accuracy    0.938\n",
            "| epoch  33 |   100/  233 batches | accuracy    0.939\n",
            "| epoch  33 |   150/  233 batches | accuracy    0.939\n",
            "| epoch  33 |   200/  233 batches | accuracy    0.938\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  33 | Time:  1.45s | Train Accuracy    0.935 | Train Loss    0.160 | Valid Accuracy    0.865 | Valid Loss    0.400 \n",
            "-----------------------------------------------------------\n",
            "| epoch  34 |    50/  233 batches | accuracy    0.938\n",
            "| epoch  34 |   100/  233 batches | accuracy    0.942\n",
            "| epoch  34 |   150/  233 batches | accuracy    0.936\n",
            "| epoch  34 |   200/  233 batches | accuracy    0.936\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  34 | Time:  1.44s | Train Accuracy    0.940 | Train Loss    0.157 | Valid Accuracy    0.853 | Valid Loss    0.407 \n",
            "-----------------------------------------------------------\n",
            "| epoch  35 |    50/  233 batches | accuracy    0.946\n",
            "| epoch  35 |   100/  233 batches | accuracy    0.939\n",
            "| epoch  35 |   150/  233 batches | accuracy    0.941\n",
            "| epoch  35 |   200/  233 batches | accuracy    0.942\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  35 | Time:  1.46s | Train Accuracy    0.941 | Train Loss    0.149 | Valid Accuracy    0.854 | Valid Loss    0.500 \n",
            "-----------------------------------------------------------\n",
            "| epoch  36 |    50/  233 batches | accuracy    0.946\n",
            "| epoch  36 |   100/  233 batches | accuracy    0.943\n",
            "| epoch  36 |   150/  233 batches | accuracy    0.946\n",
            "| epoch  36 |   200/  233 batches | accuracy    0.942\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  36 | Time:  1.47s | Train Accuracy    0.942 | Train Loss    0.145 | Valid Accuracy    0.867 | Valid Loss    0.441 \n",
            "-----------------------------------------------------------\n",
            "| epoch  37 |    50/  233 batches | accuracy    0.946\n",
            "| epoch  37 |   100/  233 batches | accuracy    0.948\n",
            "| epoch  37 |   150/  233 batches | accuracy    0.948\n",
            "| epoch  37 |   200/  233 batches | accuracy    0.951\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  37 | Time:  1.45s | Train Accuracy    0.949 | Train Loss    0.138 | Valid Accuracy    0.869 | Valid Loss    0.427 \n",
            "-----------------------------------------------------------\n",
            "| epoch  38 |    50/  233 batches | accuracy    0.953\n",
            "| epoch  38 |   100/  233 batches | accuracy    0.949\n",
            "| epoch  38 |   150/  233 batches | accuracy    0.950\n",
            "| epoch  38 |   200/  233 batches | accuracy    0.946\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  38 | Time:  1.46s | Train Accuracy    0.949 | Train Loss    0.133 | Valid Accuracy    0.864 | Valid Loss    0.445 \n",
            "-----------------------------------------------------------\n",
            "| epoch  39 |    50/  233 batches | accuracy    0.959\n",
            "| epoch  39 |   100/  233 batches | accuracy    0.950\n",
            "| epoch  39 |   150/  233 batches | accuracy    0.950\n",
            "| epoch  39 |   200/  233 batches | accuracy    0.950\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  39 | Time:  1.45s | Train Accuracy    0.952 | Train Loss    0.129 | Valid Accuracy    0.862 | Valid Loss    0.440 \n",
            "-----------------------------------------------------------\n",
            "| epoch  40 |    50/  233 batches | accuracy    0.956\n",
            "| epoch  40 |   100/  233 batches | accuracy    0.955\n",
            "| epoch  40 |   150/  233 batches | accuracy    0.952\n",
            "| epoch  40 |   200/  233 batches | accuracy    0.954\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  40 | Time:  1.46s | Train Accuracy    0.951 | Train Loss    0.124 | Valid Accuracy    0.868 | Valid Loss    0.461 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "num_class = len(set(train_df_vi['label']))\n",
        "vocab_size = len(vocabulary)\n",
        "embed_dim = 100\n",
        "model = TextClassificationModel(vocab_size, embed_dim, num_class).to(device)\n",
        "\n",
        "learning_rate = 3\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "num_epochs = 40\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    epoch_start_time = time.time()\n",
        "    train_acc, train_loss = train(model, optimizer, criterion, train_dataloader, epoch)\n",
        "    eval_acc, eval_loss = evaluate(model, criterion, valid_dataloader)\n",
        "    print(\"-\" * 59)\n",
        "    print(\n",
        "        \"| End of epoch {:3d} | Time: {:5.2f}s | Train Accuracy {:8.3f} | Train Loss {:8.3f} \"\n",
        "        \"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f} \".format(\n",
        "            epoch, time.time() - epoch_start_time, train_acc, train_loss, eval_acc, eval_loss\n",
        "        )\n",
        "    )\n",
        "    print(\"-\" * 59)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az6L8nW_rkrN"
      },
      "source": [
        "##**7. Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "9LrFrUplrkrN"
      },
      "outputs": [],
      "source": [
        "model = model.to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "x3A8X6bfrkrN"
      },
      "outputs": [],
      "source": [
        "def predict(text):\n",
        "    with torch.no_grad():\n",
        "        encoded = torch.tensor(vocabulary(tokenizer(text)))\n",
        "        output = model(encoded, torch.tensor([0]))\n",
        "        return output.argmax(1).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "sieLwBLtrkrN",
        "outputId": "e850d83a-dde0-4e6a-8d94-79375635f7ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentence               Quán này khá là nổi_tiếng nay mới có dịp ghé t...\n",
              "label                                                                  0\n",
              "preprocess_sentence    quán này khá là nổi tiếng nay mới có dịp ghé t...\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "t5fgiU4arkrO",
        "outputId": "559ece3f-ce12-4365-a25b-9452b8912c60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(test_df.iloc[0]['sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNLaRMtnrkrO",
        "outputId": "babfff75-bb94-4fca-9a7f-384ed1684ab7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.8639)"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# compute accuracy on test set\n",
        "\n",
        "predictions, labels = [], []\n",
        "for index, row in test_df.iterrows():\n",
        "    sentence = row['preprocess_sentence']\n",
        "    label = row['label']\n",
        "    prediction = predict(sentence)\n",
        "    predictions.append(prediction)\n",
        "    labels.append(label)\n",
        "\n",
        "sum(torch.tensor(predictions) == torch.tensor(labels))/len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv7NgrpJ5N9m"
      },
      "source": [
        "##**8. Compare: BoW, TF-IDF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Yu4LaR7UrK"
      },
      "source": [
        "###**8.1. BoW**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "hstpLbj154hI"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "4h6mAAFg52j2"
      },
      "outputs": [],
      "source": [
        "train_labels = np.array(train_df_vi['label'].tolist())\n",
        "test_labels = np.array(test_df['label'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjIDlF505UuU",
        "outputId": "4a946797-da0a-472f-fbe6-adadf7faa447"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15000"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "max_features = 15000\n",
        "vectorizer = CountVectorizer(max_features=max_features)\n",
        "\n",
        "train_sequences = vectorizer.fit_transform(train_df_vi['preprocess_sentence'])\n",
        "test_sequences = vectorizer.transform(test_df['preprocess_sentence'])\n",
        "vocab_size = len(vectorizer.vocabulary_)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "y2Ced26q5lTA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\cang_\\miniconda3\\envs\\yolo\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(train_sequences, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzF_IBu_6tLl",
        "outputId": "3b3f188c-ec00-451c-d947-33f630efd176"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8774"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logreg.score(test_sequences, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL16oFDP7Y6w"
      },
      "source": [
        "###**8.2. TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "o5LTXakq7cZ0"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "max_features = 10000\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=max_features)\n",
        "\n",
        "train_sequences = tfidf_vectorizer.fit_transform(train_df_vi['preprocess_sentence'])\n",
        "test_sequences = tfidf_vectorizer.transform(test_df['preprocess_sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "pB4Ah2Ht8t0f",
        "outputId": "5d2102cf-6836-4cb1-efcc-71ddbd84f24f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(train_sequences, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F5bLVb69NfT",
        "outputId": "ee1c164d-1eb5-46bd-e1c6-cfa7f9dc101d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8822"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logreg.score(test_sequences, test_labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
