{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taaQW5YzqXCf"
      },
      "source": [
        "\n",
        "#**Text Classification using Neural Network (Torchtext)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6VH4oC_qgd3"
      },
      "source": [
        "#**I. Pytorch & Torchtext**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrMGVUn0q6YT"
      },
      "source": [
        "##**1. Index-based Representation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "175VD-_CqnM-",
        "outputId": "2ba43813-1e7a-4e62-bca0-0b1f7228c824"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'food': 6,\n",
              " 'dog': 1,\n",
              " '<unk>': 0,\n",
              " 'man': 2,\n",
              " 'bites': 3,\n",
              " 'meat': 7,\n",
              " 'eats': 4,\n",
              " 'break': 5}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "data = [\"dog bites man\", \"man bites dog\", \"dog eats meat break\", \"man eats food\"]\n",
        "\n",
        "# Define the max vocabulary size\n",
        "vocab_size = 10\n",
        "\n",
        "# Define tokenizer function\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Create a function to yield list of tokens\n",
        "def yield_tokens(examples):\n",
        "    for text in examples:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Create vocabulary\n",
        "vocab = build_vocab_from_iterator(\n",
        "    yield_tokens(data),\n",
        "    max_tokens=vocab_size,\n",
        "    specials=[\"<unk>\"]\n",
        ")\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "vocab.get_stoi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5kUZZ8irLLx",
        "outputId": "231f2933-732b-4f39-bc84-c191bb944fd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 0, 2]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab(tokenizer(\"dog and man\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO0R_l0MrVdY"
      },
      "source": [
        "##**2. Padding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJSMYLmMrX1V",
        "outputId": "ef7f56df-bbc6-4617-b370-3084fdda29c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "data = [\"dog bites man\", \"man bites dog\", \"dog eats meat\", \"man eats food\"]\n",
        "\n",
        "# Define the max vocabulary size\n",
        "vocab_size = 8\n",
        "\n",
        "# Define tokenizer function\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Create a function to yield list of tokens\n",
        "def yield_tokens(examples):\n",
        "    for text in examples:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Create vocabulary\n",
        "vocab = build_vocab_from_iterator(\n",
        "    yield_tokens(data),\n",
        "    max_tokens=vocab_size,\n",
        "    specials=[\"<pad>\", \"<unk>\"]\n",
        ")\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "vocab.get_stoi()['<pad>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK6ETXOircBi",
        "outputId": "02accc67-06f2-45a3-9c92-62cbe7c066c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2, 4, 3, 0])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchtext.transforms import PadTransform\n",
        "\n",
        "# define padding\n",
        "max_len = 4\n",
        "pad_id = vocab.get_stoi()['<pad>']\n",
        "padder = PadTransform(max_len, pad_id)\n",
        "\n",
        "input = torch.tensor([2, 4, 3])\n",
        "padded_input = padder(input)\n",
        "padded_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2YWSqGnrmWb"
      },
      "source": [
        "##**3. Truncating**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMTbpkmyrpZN",
        "outputId": "22992c52-06eb-4818-95b9-e3485253068a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2, 2, 4]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchtext.transforms import Truncate\n",
        "\n",
        "# define padding\n",
        "max_len = 3\n",
        "truncater = Truncate(max_len)\n",
        "\n",
        "input = [2, 2, 4, 3]\n",
        "truncated_input = truncater(input)\n",
        "truncated_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cim-c7C0rvlb"
      },
      "source": [
        "##**4. Embedding Layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPVzaMwhryuM",
        "outputId": "fc6e4e06-a6fc-43e0-f4e4-bc6f1ecb2fd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.6559,  1.3594,  0.1479],\n",
              "        [-1.8895, -2.0806,  0.5763],\n",
              "        [ 0.3984, -0.4017,  0.2369],\n",
              "        [-0.4685,  0.4417,  0.2814],\n",
              "        [ 0.8080,  0.3747,  1.2526],\n",
              "        [ 1.4169, -0.2143,  1.6728],\n",
              "        [-0.1761,  0.8684,  0.6982]], requires_grad=True)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "vocab_size = 7\n",
        "embedding_dim = 3\n",
        "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "embedding.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNLfTWGQr3Yp",
        "outputId": "d48f3be9-74ed-48b4-ba7f-a5631a7dec0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-1.8895, -2.0806,  0.5763],\n",
              "         [ 0.3984, -0.4017,  0.2369],\n",
              "         [ 0.8080,  0.3747,  1.2526]],\n",
              "\n",
              "        [[ 0.8080,  0.3747,  1.2526],\n",
              "         [-0.4685,  0.4417,  0.2814],\n",
              "         [ 0.3984, -0.4017,  0.2369]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "input = torch.LongTensor([[1, 2, 4], [4, 3, 2]])\n",
        "embedding(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkAYWWrGr6KB"
      },
      "source": [
        "##**5. EmbeddingBag**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD5u7gcLr8pc",
        "outputId": "d28d8aa8-ebe9-4477-d5b2-07dbe27866d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1.1380, -1.0332,  0.3145,  0.3978],\n",
              "        [-0.2621,  0.5047,  0.6283, -0.9858],\n",
              "        [ 2.8303, -0.5140, -0.1121,  1.1000],\n",
              "        [-0.3895, -0.2760,  1.2807, -0.7265],\n",
              "        [-1.2690,  0.3354, -0.2880, -1.4561],\n",
              "        [-0.1139, -0.9135, -0.1265,  0.9945],\n",
              "        [-0.8233, -0.2780,  2.2734, -1.7664]], requires_grad=True)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "vocab_size = 7\n",
        "embedding_dim = 4\n",
        "embedding_sum = nn.EmbeddingBag(vocab_size, embedding_dim, mode='sum')\n",
        "embedding_sum.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdpnoMNysAwj",
        "outputId": "0187cdec-095d-4a40-c3de-12c0bc1c49e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.2992,  0.3261,  0.2283, -1.3419],\n",
              "        [-1.7724, -0.8541,  0.8663, -1.1881]], grad_fn=<EmbeddingBagBackward0>)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.tensor([1, 2, 4, 5, 4, 3], dtype=torch.long)\n",
        "offsets = torch.tensor([0, 3], dtype=torch.long)\n",
        "embedding_sum(inputs, offsets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rct1KtdysFDM",
        "outputId": "9786bc55-24a5-43b3-e003-e9e98cd872c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 3.0254e-01, -4.6935e-01,  4.4714e-01,  4.6225e-01],\n",
              "        [ 1.3913e+00,  8.4724e-03, -6.7528e-01,  8.6682e-01],\n",
              "        [ 5.6138e-01, -1.2469e-01,  1.4979e-03, -2.0303e-01],\n",
              "        [-2.6869e+00, -3.8463e-01,  2.4544e-01, -1.0190e+00],\n",
              "        [ 2.0376e+00,  3.3820e-01,  2.9438e+00, -3.0470e-01],\n",
              "        [ 4.9471e-02, -1.7743e+00,  1.9325e+00,  3.5303e-01],\n",
              "        [-3.3324e-01, -8.1543e-02,  4.9799e-01, -6.0619e-01]],\n",
              "       requires_grad=True)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "vocab_size = 7\n",
        "embedding_dim = 4\n",
        "embedding_sum = nn.EmbeddingBag(vocab_size, embedding_dim, mode='mean')\n",
        "embedding_sum.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHJXnxYxsHzs",
        "outputId": "4a9c3558-9faf-4513-a874-0a7d360c5763"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.3301,  0.0740,  0.7567,  0.1197],\n",
              "        [-0.2000, -0.6069,  1.7072, -0.3236]], grad_fn=<EmbeddingBagBackward0>)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.tensor([1, 2, 4, 5, 4, 3], dtype=torch.long)\n",
        "offsets = torch.tensor([0, 3], dtype=torch.long)\n",
        "embedding_sum(inputs, offsets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNLm4l85rQN4"
      },
      "source": [
        "#**II. Text Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbtPHUfVrkrB"
      },
      "source": [
        "##**1. Download Dataset from Github**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0DiBQK5rkrD",
        "outputId": "31e26d7e-fdd5-4531-fb03-95da3490b417"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'ntc-scv'...\n",
            "Updating files:  81% (9/11)\n",
            "Updating files:  90% (10/11)\n",
            "Updating files: 100% (11/11)\n",
            "Updating files: 100% (11/11), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/congnghia0609/ntc-scv.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU1hU_UvrkrE",
        "outputId": "bf5ef4fe-70bb-4b1e-fd47-406096ae64f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'rm' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!unzip ./ntc-scv/data/data_test.zip -d ./data\n",
        "!unzip ./ntc-scv/data/data_train.zip -d ./data\n",
        "!rm -rf ./ntc-scv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q0jHeUN7rkrE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def load_data_from_path(folder_path):\n",
        "    examples = []\n",
        "    for label in os.listdir(folder_path):\n",
        "        full_path = os.path.join(folder_path, label)\n",
        "        for file_name in os.listdir(full_path):\n",
        "            file_path = os.path.join(full_path, file_name)\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                lines = f.readlines()\n",
        "            sentence = \" \".join(lines)\n",
        "            if label == \"neg\":\n",
        "                label = 0\n",
        "            if label == \"pos\":\n",
        "                label = 1\n",
        "            data = {\n",
        "                'sentence': sentence,\n",
        "                'label': label\n",
        "            }\n",
        "            examples.append(data)\n",
        "    return pd.DataFrame(examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GZxIF6mCrkrF"
      },
      "outputs": [],
      "source": [
        "folder_paths = {\n",
        "    'train': './data_train/train',\n",
        "    'valid': './data_train/test',\n",
        "    'test': './data_test/test'\n",
        "}\n",
        "\n",
        "train_df = load_data_from_path(folder_paths['train'])\n",
        "valid_df = load_data_from_path(folder_paths['valid'])\n",
        "test_df = load_data_from_path(folder_paths['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YXEhAwXorkrF",
        "outputId": "dd125e80-639b-4eed-9f3f-524ee31f6338"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mua c√≥ m·ªói Bingsu th·∫≠p_c·∫©m 45k m√† m√¨nh f ƒë·ª£i h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Th·ª© 6 n√†o ta c√πng qu·∫©y üí£ üí£ üí£\\n Vuvuzela beer c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M√¨nh ƒëi v·ªõi nh√≥m , t·ªïng_c·ªông 4 ng∆∞·ªùi ƒÉn ch·ªâ c√≥...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nh√¢n_vi√™n ph·ª•c_v·ª• kh√¥ng m·∫•y t·∫≠n_t√¨nh , ƒë·ªì_ƒÉn r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>V√†o ƒë√¢y th√¨ h·∫øt b√†n , nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  label\n",
              "0  Mua c√≥ m·ªói Bingsu th·∫≠p_c·∫©m 45k m√† m√¨nh f ƒë·ª£i h...      0\n",
              "1  Th·ª© 6 n√†o ta c√πng qu·∫©y üí£ üí£ üí£\\n Vuvuzela beer c...      0\n",
              "2  M√¨nh ƒëi v·ªõi nh√≥m , t·ªïng_c·ªông 4 ng∆∞·ªùi ƒÉn ch·ªâ c√≥...      0\n",
              "3  nh√¢n_vi√™n ph·ª•c_v·ª• kh√¥ng m·∫•y t·∫≠n_t√¨nh , ƒë·ªì_ƒÉn r...      0\n",
              "4  V√†o ƒë√¢y th√¨ h·∫øt b√†n , nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i ...      0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC3Wgc0UrkrF"
      },
      "source": [
        "##**2. Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRer6QHhrkrG"
      },
      "source": [
        "###**2.1. Language Detection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "67SMB4OsrkrG"
      },
      "outputs": [],
      "source": [
        "from langid.langid import LanguageIdentifier, model\n",
        "\n",
        "def identify_vn(df):\n",
        "    identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)\n",
        "    not_vi_idx = set()\n",
        "    THRESHOLD = 0.9\n",
        "    for idx, row in df.iterrows():\n",
        "        score = identifier.classify(row[\"sentence\"])\n",
        "        if score[0] != \"vi\" or (score[0] == \"vi\" and score[1] <= THRESHOLD):\n",
        "            not_vi_idx.add(idx)\n",
        "    vi_df = df[~df.index.isin(not_vi_idx)]\n",
        "    not_vi_df = df[df.index.isin(not_vi_idx)]\n",
        "    return vi_df, not_vi_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8hR7Y4w8rkrG"
      },
      "outputs": [],
      "source": [
        "train_df_vi, train_df_other = identify_vn(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "w_9nfPzxrkrG",
        "outputId": "4d26d2b3-7213-46f0-ce85-b69cd514e83a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mua c√≥ m·ªói Bingsu th·∫≠p_c·∫©m 45k m√† m√¨nh f ƒë·ª£i h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Th·ª© 6 n√†o ta c√πng qu·∫©y üí£ üí£ üí£\\n Vuvuzela beer c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M√¨nh ƒëi v·ªõi nh√≥m , t·ªïng_c·ªông 4 ng∆∞·ªùi ƒÉn ch·ªâ c√≥...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nh√¢n_vi√™n ph·ª•c_v·ª• kh√¥ng m·∫•y t·∫≠n_t√¨nh , ƒë·ªì_ƒÉn r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>V√†o ƒë√¢y th√¨ h·∫øt b√†n , nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>2-9 m√¨nh ƒëi v·ªõi nh√≥m b·∫°n t·ªïng_c·ªông l√† 8ng.Thi·ªá...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>sushi b√¨nh_d√¢n m√† ch·∫•t_l∆∞·ª£ng kh√¥ng b√¨nh_d√¢n ch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>Tr·ªùi_∆°i t·ª´ b√© ƒë·∫øn l·ªõn ch∆∞a th·ª≠ m√≥n kem n√†o b·∫±n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>Nge mn c≈©ng ns ngon n√™n hni ƒë·∫øn coi th·∫ø_n√†o .\\...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>Ks ƒë·∫πp . Tho√°g m√°t . L·∫°i g·∫ßn vs ph·ªë c·ªï n·ªØa n√™n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29736 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence  label\n",
              "0      Mua c√≥ m·ªói Bingsu th·∫≠p_c·∫©m 45k m√† m√¨nh f ƒë·ª£i h...      0\n",
              "1      Th·ª© 6 n√†o ta c√πng qu·∫©y üí£ üí£ üí£\\n Vuvuzela beer c...      0\n",
              "2      M√¨nh ƒëi v·ªõi nh√≥m , t·ªïng_c·ªông 4 ng∆∞·ªùi ƒÉn ch·ªâ c√≥...      0\n",
              "3      nh√¢n_vi√™n ph·ª•c_v·ª• kh√¥ng m·∫•y t·∫≠n_t√¨nh , ƒë·ªì_ƒÉn r...      0\n",
              "4      V√†o ƒë√¢y th√¨ h·∫øt b√†n , nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i ...      0\n",
              "...                                                  ...    ...\n",
              "29995  2-9 m√¨nh ƒëi v·ªõi nh√≥m b·∫°n t·ªïng_c·ªông l√† 8ng.Thi·ªá...      1\n",
              "29996  sushi b√¨nh_d√¢n m√† ch·∫•t_l∆∞·ª£ng kh√¥ng b√¨nh_d√¢n ch...      1\n",
              "29997  Tr·ªùi_∆°i t·ª´ b√© ƒë·∫øn l·ªõn ch∆∞a th·ª≠ m√≥n kem n√†o b·∫±n...      1\n",
              "29998  Nge mn c≈©ng ns ngon n√™n hni ƒë·∫øn coi th·∫ø_n√†o .\\...      1\n",
              "29999  Ks ƒë·∫πp . Tho√°g m√°t . L·∫°i g·∫ßn vs ph·ªë c·ªï n·ªØa n√™n...      1\n",
              "\n",
              "[29736 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df_vi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "vajiWpYNrkrH",
        "outputId": "146ad0a1-b11e-476a-e0b2-2e69bd2d1297"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>Minh da den them 1 lan vao buoi trua ma van do...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>The drink taste not good as Shanghai . The tas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>I work in District 1 not far from Taco_King . ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>Service is worst . . waiter and waitress messi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>809</th>\n",
              "      <td>Day la lan dau cung nhu lan cuoi minh ghe quan...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29571</th>\n",
              "      <td>We had high expectations of this place and my ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29687</th>\n",
              "      <td>My name is Luan , ¬† A_Local_Travel_Consultant ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29757</th>\n",
              "      <td>Art of lanterns , super nice and acceptable pr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29853</th>\n",
              "      <td>The 200k buffet is really worth it ! Good meat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29940</th>\n",
              "      <td>Brilliant juices ! ! They have some mixes that...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>264 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence  label\n",
              "446    Minh da den them 1 lan vao buoi trua ma van do...      0\n",
              "523    The drink taste not good as Shanghai . The tas...      0\n",
              "582    I work in District 1 not far from Taco_King . ...      0\n",
              "802    Service is worst . . waiter and waitress messi...      0\n",
              "809    Day la lan dau cung nhu lan cuoi minh ghe quan...      0\n",
              "...                                                  ...    ...\n",
              "29571  We had high expectations of this place and my ...      1\n",
              "29687  My name is Luan , ¬† A_Local_Travel_Consultant ...      1\n",
              "29757  Art of lanterns , super nice and acceptable pr...      1\n",
              "29853  The 200k buffet is really worth it ! Good meat...      1\n",
              "29940  Brilliant juices ! ! They have some mixes that...      1\n",
              "\n",
              "[264 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df_other"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-g6dtCHrkrH"
      },
      "source": [
        "###**2.2. Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5-RIlCStrkrH"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    url_pattern = re.compile(r'https?://\\s+\\wwww\\.\\s+')\n",
        "    text = url_pattern.sub(r\" \", text)\n",
        "\n",
        "    html_pattern = re.compile(r'<[^<>]+>')\n",
        "    text = html_pattern.sub(\" \", text)\n",
        "\n",
        "    replace_chars = list(string.punctuation + string.digits)\n",
        "    for char in replace_chars:\n",
        "        text = text.replace(char, \" \")\n",
        "\n",
        "    \n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
        "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
        "        u\"\\U0001F600-\\U0001F64F\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U0001F1F2\"\n",
        "        u\"\\U0001F1F4\"\n",
        "        u\"\\U0001F620\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r\" \", text)\n",
        "\n",
        "    text = \" \".join(text.split())\n",
        "\n",
        "    return text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "5x3vZZwprkrH",
        "outputId": "a433746d-9b96-4c31-c72e-dc1bbf4260f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    Mua c√≥ m·ªói Bingsu th·∫≠p_c·∫©m 45k m√† m√¨nh f ƒë·ª£i h...\n",
              "1    Th·ª© 6 n√†o ta c√πng qu·∫©y üí£ üí£ üí£\\n Vuvuzela beer c...\n",
              "2    M√¨nh ƒëi v·ªõi nh√≥m , t·ªïng_c·ªông 4 ng∆∞·ªùi ƒÉn ch·ªâ c√≥...\n",
              "3    nh√¢n_vi√™n ph·ª•c_v·ª• kh√¥ng m·∫•y t·∫≠n_t√¨nh , ƒë·ªì_ƒÉn r...\n",
              "4    V√†o ƒë√¢y th√¨ h·∫øt b√†n , nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i ...\n",
              "Name: sentence, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df_vi['sentence'][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "9p825QUyrkrH",
        "outputId": "2267c95b-5820-4fd8-d618-ab4a92aece57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'mua c√≥ m·ªói bingsu th·∫≠p c·∫©m k m√† m√¨nh f ƒë·ª£i h∆°n h·ªèi l·∫°i th√¨ nv tl c√≥ r nhg b·∫£o ch·ªù th√™m n·ªØa t·ª•i e lm li·ªÅn m√¨nh k bi·∫øt c√≥ ngon k nhg c≈©ng mu·ªën ƒÉn th·ª≠ thi·∫øt nghƒ© nv qu√°n n√™n xem l·∫°i c√°ch pv v√† nc vs kh√°ch'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocess_text(train_df_vi['sentence'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxI--G8grkrH",
        "outputId": "335fecfb-a7a7-4279-ba15-b626d345d8c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\cang_\\AppData\\Local\\Temp\\ipykernel_21004\\1058621333.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df_vi['preprocess_sentence'] = [preprocess_text(row['sentence']) for index, row in train_df_vi.iterrows()]\n"
          ]
        }
      ],
      "source": [
        "train_df_vi['preprocess_sentence'] = [preprocess_text(row['sentence']) for index, row in train_df_vi.iterrows()]\n",
        "valid_df['preprocess_sentence'] = [preprocess_text(row['sentence']) for index, row in valid_df.iterrows()]\n",
        "test_df['preprocess_sentence'] = [preprocess_text(row['sentence']) for index, row in test_df.iterrows()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iI3r_zmmrkrH",
        "outputId": "d2627846-0c10-4211-a8d9-1f848c7a6e54"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>preprocess_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mua c√≥ m·ªói Bingsu th·∫≠p_c·∫©m 45k m√† m√¨nh f ƒë·ª£i h...</td>\n",
              "      <td>0</td>\n",
              "      <td>mua c√≥ m·ªói bingsu th·∫≠p c·∫©m k m√† m√¨nh f ƒë·ª£i h∆°n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Th·ª© 6 n√†o ta c√πng qu·∫©y üí£ üí£ üí£\\n Vuvuzela beer c...</td>\n",
              "      <td>0</td>\n",
              "      <td>th·ª© n√†o ta c√πng qu·∫©y vuvuzela beer club chung ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M√¨nh ƒëi v·ªõi nh√≥m , t·ªïng_c·ªông 4 ng∆∞·ªùi ƒÉn ch·ªâ c√≥...</td>\n",
              "      <td>0</td>\n",
              "      <td>m√¨nh ƒëi v·ªõi nh√≥m t·ªïng c·ªông ng∆∞·ªùi ƒÉn ch·ªâ c√≥ kh√¥...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nh√¢n_vi√™n ph·ª•c_v·ª• kh√¥ng m·∫•y t·∫≠n_t√¨nh , ƒë·ªì_ƒÉn r...</td>\n",
              "      <td>0</td>\n",
              "      <td>nh√¢n vi√™n ph·ª•c v·ª• kh√¥ng m·∫•y t·∫≠n t√¨nh ƒë·ªì ƒÉn ra ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>V√†o ƒë√¢y th√¨ h·∫øt b√†n , nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i ...</td>\n",
              "      <td>0</td>\n",
              "      <td>v√†o ƒë√¢y th√¨ h·∫øt b√†n nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i b√¨...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>2-9 m√¨nh ƒëi v·ªõi nh√≥m b·∫°n t·ªïng_c·ªông l√† 8ng.Thi·ªá...</td>\n",
              "      <td>1</td>\n",
              "      <td>m√¨nh ƒëi v·ªõi nh√≥m b·∫°n t·ªïng c·ªông l√† ng thi·ªát h·∫°i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>sushi b√¨nh_d√¢n m√† ch·∫•t_l∆∞·ª£ng kh√¥ng b√¨nh_d√¢n ch...</td>\n",
              "      <td>1</td>\n",
              "      <td>sushi b√¨nh d√¢n m√† ch·∫•t l∆∞·ª£ng kh√¥ng b√¨nh d√¢n ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>Tr·ªùi_∆°i t·ª´ b√© ƒë·∫øn l·ªõn ch∆∞a th·ª≠ m√≥n kem n√†o b·∫±n...</td>\n",
              "      <td>1</td>\n",
              "      <td>tr·ªùi ∆°i t·ª´ b√© ƒë·∫øn l·ªõn ch∆∞a th·ª≠ m√≥n kem n√†o b·∫±n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>Nge mn c≈©ng ns ngon n√™n hni ƒë·∫øn coi th·∫ø_n√†o .\\...</td>\n",
              "      <td>1</td>\n",
              "      <td>nge mn c≈©ng ns ngon n√™n hni ƒë·∫øn coi th·∫ø n√†o qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>Ks ƒë·∫πp . Tho√°g m√°t . L·∫°i g·∫ßn vs ph·ªë c·ªï n·ªØa n√™n...</td>\n",
              "      <td>1</td>\n",
              "      <td>ks ƒë·∫πp tho√°g m√°t l·∫°i g·∫ßn vs ph·ªë c·ªï n·ªØa n√™n r·∫•t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29736 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence  label  \\\n",
              "0      Mua c√≥ m·ªói Bingsu th·∫≠p_c·∫©m 45k m√† m√¨nh f ƒë·ª£i h...      0   \n",
              "1      Th·ª© 6 n√†o ta c√πng qu·∫©y üí£ üí£ üí£\\n Vuvuzela beer c...      0   \n",
              "2      M√¨nh ƒëi v·ªõi nh√≥m , t·ªïng_c·ªông 4 ng∆∞·ªùi ƒÉn ch·ªâ c√≥...      0   \n",
              "3      nh√¢n_vi√™n ph·ª•c_v·ª• kh√¥ng m·∫•y t·∫≠n_t√¨nh , ƒë·ªì_ƒÉn r...      0   \n",
              "4      V√†o ƒë√¢y th√¨ h·∫øt b√†n , nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i ...      0   \n",
              "...                                                  ...    ...   \n",
              "29995  2-9 m√¨nh ƒëi v·ªõi nh√≥m b·∫°n t·ªïng_c·ªông l√† 8ng.Thi·ªá...      1   \n",
              "29996  sushi b√¨nh_d√¢n m√† ch·∫•t_l∆∞·ª£ng kh√¥ng b√¨nh_d√¢n ch...      1   \n",
              "29997  Tr·ªùi_∆°i t·ª´ b√© ƒë·∫øn l·ªõn ch∆∞a th·ª≠ m√≥n kem n√†o b·∫±n...      1   \n",
              "29998  Nge mn c≈©ng ns ngon n√™n hni ƒë·∫øn coi th·∫ø_n√†o .\\...      1   \n",
              "29999  Ks ƒë·∫πp . Tho√°g m√°t . L·∫°i g·∫ßn vs ph·ªë c·ªï n·ªØa n√™n...      1   \n",
              "\n",
              "                                     preprocess_sentence  \n",
              "0      mua c√≥ m·ªói bingsu th·∫≠p c·∫©m k m√† m√¨nh f ƒë·ª£i h∆°n...  \n",
              "1      th·ª© n√†o ta c√πng qu·∫©y vuvuzela beer club chung ...  \n",
              "2      m√¨nh ƒëi v·ªõi nh√≥m t·ªïng c·ªông ng∆∞·ªùi ƒÉn ch·ªâ c√≥ kh√¥...  \n",
              "3      nh√¢n vi√™n ph·ª•c v·ª• kh√¥ng m·∫•y t·∫≠n t√¨nh ƒë·ªì ƒÉn ra ...  \n",
              "4      v√†o ƒë√¢y th√¨ h·∫øt b√†n nh∆∞ng m√¨nh v·∫´n ng·ªìi ƒë·ª£i b√¨...  \n",
              "...                                                  ...  \n",
              "29995  m√¨nh ƒëi v·ªõi nh√≥m b·∫°n t·ªïng c·ªông l√† ng thi·ªát h·∫°i...  \n",
              "29996  sushi b√¨nh d√¢n m√† ch·∫•t l∆∞·ª£ng kh√¥ng b√¨nh d√¢n ch...  \n",
              "29997  tr·ªùi ∆°i t·ª´ b√© ƒë·∫øn l·ªõn ch∆∞a th·ª≠ m√≥n kem n√†o b·∫±n...  \n",
              "29998  nge mn c≈©ng ns ngon n√™n hni ƒë·∫øn coi th·∫ø n√†o qu...  \n",
              "29999  ks ƒë·∫πp tho√°g m√°t l·∫°i g·∫ßn vs ph·ªë c·ªï n·ªØa n√™n r·∫•t...  \n",
              "\n",
              "[29736 rows x 3 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df_vi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vNMsPhdlrkrH",
        "outputId": "55937f23-7c72-4db5-ab4b-bdb500880f70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>preprocess_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L·∫ßn ƒë·∫ßu_ti√™n ƒÉn ch·∫Øc c≈©ng l√† l·∫ßn cu·ªëi ƒÉn_·ªü ƒë√¢y...</td>\n",
              "      <td>0</td>\n",
              "      <td>l·∫ßn ƒë·∫ßu ti√™n ƒÉn ch·∫Øc c≈©ng l√† l·∫ßn cu·ªëi ƒÉn ·ªü ƒë√¢y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Khi m√¨nh v√†o th√¨ b√†n ch∆∞a d·ªçn , d∆° kinh . C√°i ...</td>\n",
              "      <td>0</td>\n",
              "      <td>khi m√¨nh v√†o th√¨ b√†n ch∆∞a d·ªçn d∆° kinh c√°i b·∫øp ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Haiz ! Kh√¥ng bi·∫øt ƒë√∫ng h∆∞∆°ng_v·ªã c·ªßa b√°nh th·∫ø_n...</td>\n",
              "      <td>0</td>\n",
              "      <td>haiz kh√¥ng bi·∫øt ƒë√∫ng h∆∞∆°ng v·ªã c·ªßa b√°nh th·∫ø n√†o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M√¨nh gh√© qu√°n n√†y v√¨ th·∫•y c√≥ c∆°m theo ki·ªÉu Vi·ªá...</td>\n",
              "      <td>0</td>\n",
              "      <td>m√¨nh gh√© qu√°n n√†y v√¨ th·∫•y c√≥ c∆°m theo ki·ªÉu vi·ªá...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Qu√°n x·ªãn ·ªü Quan_Hoa - C·∫ßu_Gi·∫•y , bi·ªÉn_hi·ªáu m√†u...</td>\n",
              "      <td>0</td>\n",
              "      <td>qu√°n x·ªãn ·ªü quan hoa c·∫ßu gi·∫•y bi·ªÉn hi·ªáu m√†u xan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>Qu√°n kh√¥ng_gian nh·ªè nh∆∞ng kh√° l·ªãch_s·ª± , s·∫°ch_s...</td>\n",
              "      <td>1</td>\n",
              "      <td>qu√°n kh√¥ng gian nh·ªè nh∆∞ng kh√° l·ªãch s·ª± s·∫°ch s·∫Ω ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>ƒëi ƒÉn l·∫ßn 2 : ) ) ) l·∫ßn n√†y r√∫t kinh_nghi·ªám ki...</td>\n",
              "      <td>1</td>\n",
              "      <td>ƒëi ƒÉn l·∫ßn l·∫ßn n√†y r√∫t kinh nghi·ªám kiu ƒë·ªì ƒÉn √≠t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>M√¨nh ƒÉn 2 m√≥n , m√† qu√™n t√™n m·∫•t r·ªìi , to√†n t·ª´ ...</td>\n",
              "      <td>1</td>\n",
              "      <td>m√¨nh ƒÉn m√≥n m√† qu√™n t√™n m·∫•t r·ªìi to√†n t·ª´ c√° h·ªìi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Trong ·∫£nh l√†\\n ‚Ä¢ 1 ph·∫ßn m√¨ udon x√†o\\n ‚Ä¢ 1 ph·∫ßn...</td>\n",
              "      <td>1</td>\n",
              "      <td>trong ·∫£nh l√† ‚Ä¢ ph·∫ßn m√¨ udon x√†o ‚Ä¢ ph·∫ßn cu·ªën ki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>ƒë·ªãa_ƒëi·ªÉm : d·ªÖ t√¨m , m·∫≠u th√¢n qu·∫πo v√†o ƒë∆∞·ªùng b·ªù...</td>\n",
              "      <td>1</td>\n",
              "      <td>ƒë·ªãa ƒëi·ªÉm d·ªÖ t√¨m m·∫≠u th√¢n qu·∫πo v√†o ƒë∆∞·ªùng b·ªù h·ªì ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label  \\\n",
              "0     L·∫ßn ƒë·∫ßu_ti√™n ƒÉn ch·∫Øc c≈©ng l√† l·∫ßn cu·ªëi ƒÉn_·ªü ƒë√¢y...      0   \n",
              "1     Khi m√¨nh v√†o th√¨ b√†n ch∆∞a d·ªçn , d∆° kinh . C√°i ...      0   \n",
              "2     Haiz ! Kh√¥ng bi·∫øt ƒë√∫ng h∆∞∆°ng_v·ªã c·ªßa b√°nh th·∫ø_n...      0   \n",
              "3     M√¨nh gh√© qu√°n n√†y v√¨ th·∫•y c√≥ c∆°m theo ki·ªÉu Vi·ªá...      0   \n",
              "4     Qu√°n x·ªãn ·ªü Quan_Hoa - C·∫ßu_Gi·∫•y , bi·ªÉn_hi·ªáu m√†u...      0   \n",
              "...                                                 ...    ...   \n",
              "9995  Qu√°n kh√¥ng_gian nh·ªè nh∆∞ng kh√° l·ªãch_s·ª± , s·∫°ch_s...      1   \n",
              "9996  ƒëi ƒÉn l·∫ßn 2 : ) ) ) l·∫ßn n√†y r√∫t kinh_nghi·ªám ki...      1   \n",
              "9997  M√¨nh ƒÉn 2 m√≥n , m√† qu√™n t√™n m·∫•t r·ªìi , to√†n t·ª´ ...      1   \n",
              "9998  Trong ·∫£nh l√†\\n ‚Ä¢ 1 ph·∫ßn m√¨ udon x√†o\\n ‚Ä¢ 1 ph·∫ßn...      1   \n",
              "9999  ƒë·ªãa_ƒëi·ªÉm : d·ªÖ t√¨m , m·∫≠u th√¢n qu·∫πo v√†o ƒë∆∞·ªùng b·ªù...      1   \n",
              "\n",
              "                                    preprocess_sentence  \n",
              "0     l·∫ßn ƒë·∫ßu ti√™n ƒÉn ch·∫Øc c≈©ng l√† l·∫ßn cu·ªëi ƒÉn ·ªü ƒë√¢y...  \n",
              "1     khi m√¨nh v√†o th√¨ b√†n ch∆∞a d·ªçn d∆° kinh c√°i b·∫øp ...  \n",
              "2     haiz kh√¥ng bi·∫øt ƒë√∫ng h∆∞∆°ng v·ªã c·ªßa b√°nh th·∫ø n√†o...  \n",
              "3     m√¨nh gh√© qu√°n n√†y v√¨ th·∫•y c√≥ c∆°m theo ki·ªÉu vi·ªá...  \n",
              "4     qu√°n x·ªãn ·ªü quan hoa c·∫ßu gi·∫•y bi·ªÉn hi·ªáu m√†u xan...  \n",
              "...                                                 ...  \n",
              "9995  qu√°n kh√¥ng gian nh·ªè nh∆∞ng kh√° l·ªãch s·ª± s·∫°ch s·∫Ω ...  \n",
              "9996  ƒëi ƒÉn l·∫ßn l·∫ßn n√†y r√∫t kinh nghi·ªám kiu ƒë·ªì ƒÉn √≠t...  \n",
              "9997  m√¨nh ƒÉn m√≥n m√† qu√™n t√™n m·∫•t r·ªìi to√†n t·ª´ c√° h·ªìi...  \n",
              "9998  trong ·∫£nh l√† ‚Ä¢ ph·∫ßn m√¨ udon x√†o ‚Ä¢ ph·∫ßn cu·ªën ki...  \n",
              "9999  ƒë·ªãa ƒëi·ªÉm d·ªÖ t√¨m m·∫≠u th√¢n qu·∫πo v√†o ƒë∆∞·ªùng b·ªù h·ªì ...  \n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2E1Aor_QrkrH",
        "outputId": "a6082d23-c12f-449e-eacd-1aeca9c36143"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>preprocess_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Qu√°n n√†y kh√° l√† n·ªïi_ti·∫øng nay m·ªõi c√≥ d·ªãp gh√© t...</td>\n",
              "      <td>0</td>\n",
              "      <td>qu√°n n√†y kh√° l√† n·ªïi ti·∫øng nay m·ªõi c√≥ d·ªãp gh√© t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ƒê√¢y l√† l·∫ßn ƒë·∫ßu_ti√™n m√¨nh ƒÉn_·ªü ƒë√¢y , v√† c√≥_l·∫Ω c...</td>\n",
              "      <td>0</td>\n",
              "      <td>ƒë√¢y l√† l·∫ßn ƒë·∫ßu ti√™n m√¨nh ƒÉn ·ªü ƒë√¢y v√† c√≥ l·∫Ω c≈©n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tha ÃÅ i ƒë√¥ Ã£ phu Ã£ c vu Ã£ nh√¢n_vi√™n kh√¥ng t√¥ ÃÅ...</td>\n",
              "      <td>0</td>\n",
              "      <td>tha ÃÅ i ƒë√¥ Ã£ phu Ã£ c vu Ã£ nh√¢n vi√™n kh√¥ng t√¥ ÃÅ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ƒê·ªì_ƒÉn b√¨nh_th∆∞·ªùng . C·∫ßn chƒÉm_ch√∫t kh√¥ng_gian h...</td>\n",
              "      <td>0</td>\n",
              "      <td>ƒë·ªì ƒÉn b√¨nh th∆∞·ªùng c·∫ßn chƒÉm ch√∫t kh√¥ng gian h∆°n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ph·ª•c_v·ª• l√¢u , gi√° th√¨ ·ªïn th√¥i nh∆∞ng ch·∫•t_l∆∞·ª£ng...</td>\n",
              "      <td>0</td>\n",
              "      <td>ph·ª•c v·ª• l√¢u gi√° th√¨ ·ªïn th√¥i nh∆∞ng ch·∫•t l∆∞·ª£ng b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>Gia re , mon an ngon , view dep va nhan vien n...</td>\n",
              "      <td>1</td>\n",
              "      <td>gia re mon an ngon view dep va nhan vien nhiet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Qu√°n n·∫±m tr√™n ƒë∆∞·ªùng Th·∫°ch_Th·ªã_Thanh , d·ªÖ t√¨m ....</td>\n",
              "      <td>1</td>\n",
              "      <td>qu√°n n·∫±m tr√™n ƒë∆∞·ªùng th·∫°ch th·ªã thanh d·ªÖ t√¨m kh√¥...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>M√¨nh ƒë√£ ƒë·∫øn ƒÉn_·ªü qu√°n n√†y v√†i l·∫ßn . ƒê·ªì_ƒÉn ngon...</td>\n",
              "      <td>1</td>\n",
              "      <td>m√¨nh ƒë√£ ƒë·∫øn ƒÉn ·ªü qu√°n n√†y v√†i l·∫ßn ƒë·ªì ƒÉn ngon g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Nh√†_h√†ng trang_tr√≠ ƒë·ªôc_ƒë√°o .\\n M√≥n ƒÉn m·ªõi_l·∫° n...</td>\n",
              "      <td>1</td>\n",
              "      <td>nh√† h√†ng trang tr√≠ ƒë·ªôc ƒë√°o m√≥n ƒÉn m·ªõi l·∫° nhi·ªÅu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>Qu√°n c√≥ ƒë·ªì u·ªëng h·∫°t_d·∫ª nh·∫•t khu_v·ª±c TC . Si√™u ...</td>\n",
              "      <td>1</td>\n",
              "      <td>qu√°n c√≥ ƒë·ªì u·ªëng h·∫°t d·∫ª nh·∫•t khu v·ª±c tc si√™u r·∫ª...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label  \\\n",
              "0     Qu√°n n√†y kh√° l√† n·ªïi_ti·∫øng nay m·ªõi c√≥ d·ªãp gh√© t...      0   \n",
              "1     ƒê√¢y l√† l·∫ßn ƒë·∫ßu_ti√™n m√¨nh ƒÉn_·ªü ƒë√¢y , v√† c√≥_l·∫Ω c...      0   \n",
              "2     tha ÃÅ i ƒë√¥ Ã£ phu Ã£ c vu Ã£ nh√¢n_vi√™n kh√¥ng t√¥ ÃÅ...      0   \n",
              "3     ƒê·ªì_ƒÉn b√¨nh_th∆∞·ªùng . C·∫ßn chƒÉm_ch√∫t kh√¥ng_gian h...      0   \n",
              "4     Ph·ª•c_v·ª• l√¢u , gi√° th√¨ ·ªïn th√¥i nh∆∞ng ch·∫•t_l∆∞·ª£ng...      0   \n",
              "...                                                 ...    ...   \n",
              "9995  Gia re , mon an ngon , view dep va nhan vien n...      1   \n",
              "9996  Qu√°n n·∫±m tr√™n ƒë∆∞·ªùng Th·∫°ch_Th·ªã_Thanh , d·ªÖ t√¨m ....      1   \n",
              "9997  M√¨nh ƒë√£ ƒë·∫øn ƒÉn_·ªü qu√°n n√†y v√†i l·∫ßn . ƒê·ªì_ƒÉn ngon...      1   \n",
              "9998  Nh√†_h√†ng trang_tr√≠ ƒë·ªôc_ƒë√°o .\\n M√≥n ƒÉn m·ªõi_l·∫° n...      1   \n",
              "9999  Qu√°n c√≥ ƒë·ªì u·ªëng h·∫°t_d·∫ª nh·∫•t khu_v·ª±c TC . Si√™u ...      1   \n",
              "\n",
              "                                    preprocess_sentence  \n",
              "0     qu√°n n√†y kh√° l√† n·ªïi ti·∫øng nay m·ªõi c√≥ d·ªãp gh√© t...  \n",
              "1     ƒë√¢y l√† l·∫ßn ƒë·∫ßu ti√™n m√¨nh ƒÉn ·ªü ƒë√¢y v√† c√≥ l·∫Ω c≈©n...  \n",
              "2     tha ÃÅ i ƒë√¥ Ã£ phu Ã£ c vu Ã£ nh√¢n vi√™n kh√¥ng t√¥ ÃÅ...  \n",
              "3     ƒë·ªì ƒÉn b√¨nh th∆∞·ªùng c·∫ßn chƒÉm ch√∫t kh√¥ng gian h∆°n...  \n",
              "4     ph·ª•c v·ª• l√¢u gi√° th√¨ ·ªïn th√¥i nh∆∞ng ch·∫•t l∆∞·ª£ng b...  \n",
              "...                                                 ...  \n",
              "9995  gia re mon an ngon view dep va nhan vien nhiet...  \n",
              "9996  qu√°n n·∫±m tr√™n ƒë∆∞·ªùng th·∫°ch th·ªã thanh d·ªÖ t√¨m kh√¥...  \n",
              "9997  m√¨nh ƒë√£ ƒë·∫øn ƒÉn ·ªü qu√°n n√†y v√†i l·∫ßn ƒë·ªì ƒÉn ngon g...  \n",
              "9998  nh√† h√†ng trang tr√≠ ƒë·ªôc ƒë√°o m√≥n ƒÉn m·ªõi l·∫° nhi·ªÅu...  \n",
              "9999  qu√°n c√≥ ƒë·ªì u·ªëng h·∫°t d·∫ª nh·∫•t khu v·ª±c tc si√™u r·∫ª...  \n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTCMBQYBrkrH"
      },
      "source": [
        "###**2.3. EDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "COQLpMherkrI",
        "outputId": "a931d19e-1021-4224-99c7-47f69424c275"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist([len(sentence.split()) for sentence in train_df_vi['preprocess_sentence']], bins=128, range=(0, 500))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\cang_\\AppData\\Local\\Temp\\ipykernel_21004\\2327715662.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df_vi['word_length'] = [len(sentence.split()) for sentence in train_df_vi['preprocess_sentence']]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "96.07200026903416"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df_vi['word_length'] = [len(sentence.split()) for sentence in train_df_vi['preprocess_sentence']]\n",
        "train_df_vi['word_length'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gelwynLrkrI",
        "outputId": "302cfd5f-bee1-49be-b266-4e98b5ee105b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(17244, 2856797)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count: words and vocabulary\n",
        "from collections import Counter\n",
        "\n",
        "words = []\n",
        "[[words.append(word) for word in sentence.split()] for sentence in train_df_vi['preprocess_sentence']]\n",
        "vocabulary = Counter(words)\n",
        "len(vocabulary), len(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTngnKOjrkrI"
      },
      "source": [
        "##**3. Text Representation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLa5qvofrkrI"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchtext==0.16.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nZ4BdhivrkrI"
      },
      "outputs": [],
      "source": [
        "def yield_tokens(sentences, tokenizer):\n",
        "    for sentence in sentences:\n",
        "        yield tokenizer(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "p1UCYZoGrkrI"
      },
      "outputs": [],
      "source": [
        "# word-based tokenizer\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGFoXsI2rkrI",
        "outputId": "0b88db1f-0858-4d9a-e58b-a2f72d89b520"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['mua', 'c√≥', 'm·ªói', 'bingsu', 'th·∫≠p']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(train_df_vi['preprocess_sentence'][0])[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "u-wJZOkyrkrI"
      },
      "outputs": [],
      "source": [
        "# build vocabulary\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "vocab_size = 15000\n",
        "vocabulary = build_vocab_from_iterator(\n",
        "    yield_tokens(train_df_vi['preprocess_sentence'], tokenizer),\n",
        "    max_tokens=vocab_size,\n",
        "    specials=[\"<unk>\"]\n",
        ")\n",
        "vocabulary.set_default_index(vocabulary[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuUHX2ERrkrI",
        "outputId": "4a567df9-5016-44e7-8078-48af4b1d77df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15000"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<unk>', 'ƒÉn', 'm√¨nh', 'c√≥', 'l√†']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get 5 examples from vocabulary\n",
        "[vocabulary.get_itos()[idx] for idx in range(5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juODl39drkrI",
        "outputId": "cdf63648-2766-4adf-800b-d66910c7ad71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[140, 3, 205, 890, 913, 856, 13, 15, 2, 2556, 241, 76, 186, 20, 7, 369, 2495, 3, 565, 1280, 213, 282, 96, 56, 419, 606, 2777, 659, 2, 13, 120, 3, 10, 13, 1280, 9, 175, 1, 98, 648, 331, 369, 6, 17, 287, 20, 189, 1375, 8, 689, 277, 60]\n"
          ]
        }
      ],
      "source": [
        "# encode text\n",
        "\n",
        "print(vocabulary(tokenizer(train_df_vi['preprocess_sentence'][0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2mcguTvNrkrI"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "def prepare_dataset(df):\n",
        "    for index, row in df.iterrows():\n",
        "        sentence = row['preprocess_sentence']\n",
        "        encoded_sentence = vocabulary(tokenizer(sentence))\n",
        "        label = row['label']\n",
        "        yield encoded_sentence, label\n",
        "\n",
        "train_dataset = prepare_dataset(train_df_vi)\n",
        "train_dataset = to_map_style_dataset(train_dataset)\n",
        "\n",
        "valid_dataset = prepare_dataset(valid_df)\n",
        "valid_dataset = to_map_style_dataset(valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60vRr0MprkrI",
        "outputId": "2a976e01-c956-433e-d55c-8e24d7477dc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[([140, 3, 205, 890, 913, 856, 13, 15, 2, 2556, 241, 76, 186, 20, 7, 369, 2495, 3, 565, 1280, 213, 282, 96, 56, 419, 606, 2777, 659, 2, 13, 120, 3, 10, 13, 1280, 9, 175, 1, 98, 648, 331, 369, 6, 17, 287, 20, 189, 1375, 8, 689, 277, 60], 0), ([215, 77, 430, 183, 1519, 3539, 1606, 2040, 114, 1127, 875, 1783, 1847, 5774, 2415, 2415, 17, 30, 9, 125, 1386, 393, 921, 161, 988, 2588, 211, 136, 444, 164, 1, 171, 34, 136, 444, 9, 2454, 84, 539, 1264, 9, 193, 164, 1, 9, 249, 3, 92, 21, 475, 899, 130, 154, 1135, 1558, 94, 77, 195, 17, 159, 19, 1, 425, 15, 61, 92, 21, 78, 9, 25, 3, 110, 736, 1469, 530, 190, 364, 475, 200, 1469, 530, 15, 253, 790, 69, 23, 5589, 530, 5, 23, 107, 1469, 530, 186, 606, 369, 606, 377, 186, 101, 543, 136, 441, 474, 4, 135, 736, 136, 171, 921, 139, 126, 949, 325, 199, 3272, 157, 5, 51, 475, 200, 182, 552, 2296, 40, 115, 68, 819, 123, 333, 22, 1519, 67, 136, 533, 137, 10631, 1974, 136], 0)]\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMKuBpU5rkrI",
        "outputId": "a838e979-5f9a-4d33-9ec2-8b8bff95fccd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29736"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ko0lUrdrkrI"
      },
      "source": [
        "##**4. Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "jOW5Jb5arkrI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def collate_batch(batch):\n",
        "    encoded_sentences, labels, offsets = [], [], [0]\n",
        "    for encoded_sentence, label in batch:\n",
        "        labels.append(label)\n",
        "        encoded_sentence = torch.tensor(encoded_sentence, dtype=torch.int64)\n",
        "        encoded_sentences.append(encoded_sentence)\n",
        "        offsets.append(encoded_sentence.size(0))\n",
        "\n",
        "    labels = torch.tensor(labels, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    encoded_sentences = torch.cat(encoded_sentences)\n",
        "    return encoded_sentences.to(device), offsets.to(device), labels.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "cKL2q3jhrkrI"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni8qkz4ZrkrI",
        "outputId": "e2dfedc6-7e49-4139-ab1d-c8099ac918d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((tensor([141,  66,  65,  ..., 950,   8, 222]),\n",
              "  tensor([    0,    98,   182,   239,   774,   795,   845,  1015,  1084,  1168,\n",
              "           1323,  1394,  1459,  1494,  1523,  1545,  1654,  1690,  1724,  1878,\n",
              "           2185,  2226,  2335,  2424,  2462,  2522,  2637,  2769,  2797,  2862,\n",
              "           2892,  3039,  3110,  3172,  3395,  3516,  3688,  3769,  3799,  3860,\n",
              "           3956,  4066,  4186,  4242,  4266,  4342,  4366,  4732,  4971,  5003,\n",
              "           5125,  5226,  5334,  5448,  5576,  5595,  5622,  5687,  5753,  6340,\n",
              "           6593,  6749,  6846,  6878,  7062,  7118,  7163,  7225,  7315,  7351,\n",
              "           7644,  7666,  7716,  7757,  7789,  7842,  7862,  7905,  8010,  8075,\n",
              "           8112,  8277,  8303,  8342,  8471,  8490,  8517,  8762,  8779,  8850,\n",
              "           9094,  9205,  9318,  9406,  9488,  9546,  9654,  9699,  9714,  9783,\n",
              "           9828,  9956, 10036, 10062, 10252, 10294, 10403, 10449, 10523, 10942,\n",
              "          11026, 11051, 11122, 11168, 11354, 11401, 11451, 11543, 11574, 11643,\n",
              "          11823, 11848, 11955, 12027, 12058, 12205, 12308, 12390]),\n",
              "  tensor([1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "          1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "          1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "          0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "          0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
              "          1, 1, 1, 0, 1, 1, 1, 1])),\n",
              " 233)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(train_dataloader)), len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "fZZSwzRdrkrM"
      },
      "outputs": [],
      "source": [
        "encoded_sentences, offsets, labels = next(iter(train_dataloader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjwdFHzirkrM",
        "outputId": "13147d3e-97f7-4c7b-cb2c-86d9733c4e79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([13922])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_sentences.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWRRzmcsrkrM"
      },
      "source": [
        "##**4. Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cdw4BpxubgL"
      },
      "source": [
        "**Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "BAdJN-qNs4my"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class, seq_len):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.ft = nn.Flatten()\n",
        "        self.fc = nn.Linear(seq_len*embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embedded = self.embedding(inputs)\n",
        "        ouput = self.ft(embedded)\n",
        "        return self.fc(ouput)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUXrU8r1tbaF",
        "outputId": "d4ff0af8-0863-45cf-ff31-29e6d14d4e94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.int32)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 5\n",
        "seq_len = 10\n",
        "input = torch.ones([batch_size, seq_len], dtype=torch.int32)\n",
        "input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "iVj8TDKetVYP"
      },
      "outputs": [],
      "source": [
        "num_class = 2\n",
        "vocab_size = 5000\n",
        "embed_dim = 100\n",
        "model = TextClassificationModel(vocab_size, embed_dim, num_class, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBcAy0sPtZtY",
        "outputId": "93503e72-66d2-48ba-a38a-2ec746c21036"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TextClassificationModel(\n",
              "  (embedding): Embedding(5000, 100)\n",
              "  (ft): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc): Linear(in_features=1000, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXi-FvjqtudC",
        "outputId": "044a501a-0ce6-4dd7-aef3-211325afea3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-5.5052, -2.3935],\n",
              "        [-5.5052, -2.3935],\n",
              "        [-5.5052, -2.3935],\n",
              "        [-5.5052, -2.3935],\n",
              "        [-5.5052, -2.3935]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = model(input)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CO2WbmIuhvi"
      },
      "source": [
        "**EmbeddingBag**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "-MzIQJHHrkrM"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "        self.PReLU1 = nn.PReLU()\n",
        "        self.PReLU2 = nn.PReLU()\n",
        "        self.fc1 = nn.Linear(embed_dim, embed_dim)\n",
        "        self.fc = nn.Linear(embed_dim, embed_dim)\n",
        "        self.fc2 = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, inputs, offsets):\n",
        "        embedded = self.embedding(inputs, offsets)\n",
        "        x = self.fc1(embedded)\n",
        "        x = self.PReLU1(x)\n",
        "        x = self.fc(x)\n",
        "        x = self.PReLU2(x)\n",
        "        return self.fc2(x)\n",
        "        return self.fc(x)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "QCeXbqv_rkrM"
      },
      "outputs": [],
      "source": [
        "num_class = len(set(train_df_vi['label']))\n",
        "vocab_size = len(vocabulary)\n",
        "embed_dim = 100\n",
        "model = TextClassificationModel(vocab_size, embed_dim, num_class).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBQz8qHrrkrM",
        "outputId": "7a3c276e-f0ff-4eff-9b90-2a6147c55e3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TextClassificationModel(\n",
              "  (embedding): EmbeddingBag(15000, 100, mode='mean')\n",
              "  (fc): Linear(in_features=100, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "9-7uJ-BPrkrM"
      },
      "outputs": [],
      "source": [
        "predictions = model(encoded_sentences, offsets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RtSETL2rkrM",
        "outputId": "d2f0893f-9651-46b5-aa9a-57e97053c329"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-2.0086e-02,  2.8112e-01],\n",
              "        [-1.1832e-01, -3.6598e-02],\n",
              "        [-7.9191e-02, -5.1912e-02],\n",
              "        [-4.4154e-02, -6.3796e-03],\n",
              "        [-2.1491e-02, -7.9818e-02],\n",
              "        [-3.4681e-02,  1.6898e-01],\n",
              "        [-7.0273e-02,  8.4102e-02],\n",
              "        [ 7.5822e-02, -1.6786e-02],\n",
              "        [-2.3080e-01, -3.5009e-02],\n",
              "        [-7.4297e-02,  7.4112e-02],\n",
              "        [ 4.7225e-02,  1.4522e-01],\n",
              "        [-1.3493e-01,  3.9849e-01],\n",
              "        [-1.5540e-01, -5.7177e-02],\n",
              "        [ 3.5263e-02,  2.8159e-02],\n",
              "        [-1.0945e-01,  5.6283e-02],\n",
              "        [-1.1328e-01,  1.4030e-01],\n",
              "        [-8.7484e-02,  2.0849e-02],\n",
              "        [-1.1612e-01,  1.3141e-01],\n",
              "        [-1.1125e-01,  1.0637e-01],\n",
              "        [-1.6419e-01,  5.1804e-02],\n",
              "        [-1.1674e-02,  4.0329e-02],\n",
              "        [-2.0917e-02,  3.1015e-02],\n",
              "        [ 5.3730e-02,  2.4477e-01],\n",
              "        [-4.2205e-02,  4.0961e-02],\n",
              "        [-1.1060e-01,  9.4485e-02],\n",
              "        [ 1.6470e-02,  6.2281e-02],\n",
              "        [-1.6819e-02,  1.0195e-02],\n",
              "        [-3.9308e-01, -1.7733e-01],\n",
              "        [-3.5494e-01,  6.7854e-02],\n",
              "        [-1.2255e-02,  3.7442e-02],\n",
              "        [-1.3060e-01,  6.6450e-02],\n",
              "        [-1.2193e-01, -2.8930e-03],\n",
              "        [-7.8611e-02,  3.2768e-01],\n",
              "        [-1.0991e-01,  2.1643e-02],\n",
              "        [ 2.0932e-01,  2.4948e-01],\n",
              "        [-2.4361e-01,  9.0349e-02],\n",
              "        [ 2.3193e-01,  2.1571e-01],\n",
              "        [ 1.8482e-01,  2.5251e-01],\n",
              "        [-1.1528e-01, -4.8291e-02],\n",
              "        [-9.3133e-02, -2.7178e-01],\n",
              "        [-5.8590e-02,  2.9706e-01],\n",
              "        [ 5.5993e-02,  1.6682e-01],\n",
              "        [-4.4626e-02,  8.3575e-02],\n",
              "        [ 1.0078e-01,  7.1908e-02],\n",
              "        [-1.8862e-01, -5.9811e-02],\n",
              "        [-1.4937e-01,  8.6183e-02],\n",
              "        [ 3.9891e-02,  1.2196e-01],\n",
              "        [-7.9986e-02, -4.7731e-02],\n",
              "        [ 7.1763e-02,  2.0720e-01],\n",
              "        [-1.3423e-01,  1.3414e-01],\n",
              "        [-1.0483e-02,  1.9503e-01],\n",
              "        [ 8.8690e-02,  3.6986e-02],\n",
              "        [-2.1095e-01, -1.8589e-02],\n",
              "        [-1.1484e-02,  6.5056e-02],\n",
              "        [-4.8300e-02,  9.3513e-02],\n",
              "        [-1.5765e-02,  3.2029e-02],\n",
              "        [-3.1812e-02, -3.9906e-02],\n",
              "        [-1.1663e-01, -5.1290e-02],\n",
              "        [-1.6945e-01, -5.6626e-02],\n",
              "        [ 1.0760e-02,  1.7561e-01],\n",
              "        [-4.7273e-02,  5.1946e-02],\n",
              "        [ 6.8652e-02, -8.1606e-02],\n",
              "        [-4.0931e-02, -8.1522e-02],\n",
              "        [-4.8149e-03,  8.9452e-02],\n",
              "        [-3.9659e-02, -1.2903e-02],\n",
              "        [ 2.8440e-02,  1.1973e-01],\n",
              "        [-3.7248e-01, -8.6012e-02],\n",
              "        [-3.7654e-02,  2.2554e-03],\n",
              "        [-4.8186e-02,  3.1785e-01],\n",
              "        [-1.0161e-01, -5.1499e-03],\n",
              "        [-1.6588e-01,  1.0249e-01],\n",
              "        [-1.9146e-01, -8.4164e-03],\n",
              "        [ 6.0436e-02,  1.9791e-01],\n",
              "        [-3.2401e-02,  4.4452e-02],\n",
              "        [-4.5664e-02, -2.3181e-01],\n",
              "        [-1.9077e-01,  4.2699e-02],\n",
              "        [-9.3399e-02,  1.1221e-01],\n",
              "        [-1.8259e-02,  1.7193e-01],\n",
              "        [ 6.1982e-02,  1.6600e-01],\n",
              "        [-5.9066e-02,  6.7129e-02],\n",
              "        [-1.3553e-01, -5.9215e-02],\n",
              "        [-1.4257e-01, -3.7592e-01],\n",
              "        [-1.4338e-01,  6.6390e-02],\n",
              "        [-1.1701e-01, -1.3440e-01],\n",
              "        [-2.2381e-01, -1.6785e-04],\n",
              "        [ 6.5010e-02, -4.5415e-03],\n",
              "        [-1.0022e-01,  1.4779e-01],\n",
              "        [ 1.5547e-02,  1.4659e-01],\n",
              "        [ 7.9926e-03,  7.5317e-03],\n",
              "        [-3.5602e-02,  1.1100e-01],\n",
              "        [-1.4009e-01,  3.0540e-01],\n",
              "        [-5.0302e-02,  3.7541e-02],\n",
              "        [ 4.3030e-02,  3.8421e-02],\n",
              "        [ 4.3067e-02, -4.7873e-02],\n",
              "        [-2.2912e-02,  4.1931e-02],\n",
              "        [ 6.2461e-02,  5.5371e-02],\n",
              "        [ 2.3861e-01,  1.0963e-01],\n",
              "        [ 7.6591e-02, -1.5334e-02],\n",
              "        [-1.5997e-01,  8.0801e-02],\n",
              "        [-3.6718e-01, -1.3104e-01],\n",
              "        [ 1.3321e-01, -3.9333e-02],\n",
              "        [ 7.5887e-03, -4.9044e-03],\n",
              "        [-1.0885e-01, -6.0251e-02],\n",
              "        [-2.5074e-01,  4.0423e-01],\n",
              "        [ 3.3658e-01,  1.8214e-01],\n",
              "        [-1.1735e-02, -1.9083e-01],\n",
              "        [-1.3979e-01,  1.8413e-02],\n",
              "        [-1.1995e-01,  9.5046e-02],\n",
              "        [ 1.6863e-01,  6.6369e-02],\n",
              "        [ 3.0960e-03,  3.2615e-02],\n",
              "        [ 3.8231e-02,  9.0653e-02],\n",
              "        [-1.8756e-01, -3.0852e-01],\n",
              "        [-4.6239e-02,  4.3557e-02],\n",
              "        [-1.3610e-01,  7.1738e-02],\n",
              "        [-5.8093e-02,  7.1149e-02],\n",
              "        [ 6.4261e-03,  2.3657e-01],\n",
              "        [-1.4445e-01, -1.5560e-01],\n",
              "        [-7.9740e-02,  9.9143e-02],\n",
              "        [-1.5742e-01, -1.5830e-01],\n",
              "        [ 4.3392e-02,  9.0839e-02],\n",
              "        [-4.4258e-02,  1.4109e-01],\n",
              "        [-6.4203e-02,  4.1162e-02],\n",
              "        [-2.8703e-01,  6.2007e-02],\n",
              "        [ 5.3472e-02,  6.2674e-03],\n",
              "        [-8.2442e-02,  2.7334e-03],\n",
              "        [-1.3759e-01,  6.0443e-02],\n",
              "        [-9.4425e-02, -5.6637e-02],\n",
              "        [-7.5266e-02,  2.0603e-02]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "PqmzZd4LrkrM"
      },
      "outputs": [],
      "source": [
        "learning_rate = 2e-5\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "N35e3MAbrkrN"
      },
      "outputs": [],
      "source": [
        "loss = criterion(predictions, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "o5H5qOf4rkrN",
        "outputId": "88c9251d-1aae-48df-de42-d0b1bc41339e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.6988, grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xk3-L3vrkrN"
      },
      "source": [
        "##**5. Trainer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "_w8deMpMrkrN"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train(model, optimizer, criterion, train_dataloader, epoch=0, log_interval=50):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    losses = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (inputs, offsets, labels) in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(inputs, offsets)\n",
        "\n",
        "        # compute loss\n",
        "        loss = criterion(predictions, labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predictions.argmax(1) == labels).sum().item()\n",
        "        total_count += labels.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
        "                \"| accuracy {:8.3f}\".format(\n",
        "                    epoch, idx, len(train_dataloader), total_acc / total_count\n",
        "                )\n",
        "            )\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "    epoch_acc = total_acc / total_count\n",
        "    epoch_loss = sum(losses) / len(losses)\n",
        "    return epoch_acc, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "oYfPqPCHrkrN",
        "outputId": "df3a401b-3ff2-4c59-88a9-420ecf0a9278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   0 |    50/  233 batches | accuracy    0.516\n",
            "| epoch   0 |   100/  233 batches | accuracy    0.504\n",
            "| epoch   0 |   150/  233 batches | accuracy    0.510\n",
            "| epoch   0 |   200/  233 batches | accuracy    0.519\n"
          ]
        }
      ],
      "source": [
        "epoch_acc, epoch_loss = train(model, optimizer, criterion, train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "a9X0KkvbrkrN",
        "outputId": "db873b22-a20e-4983-c0fa-7260197193cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.5032435129740519, 0.6948716149309674)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epoch_acc, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "hnzySNicrkrN"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, criterion, valid_dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (inputs, offsets, labels) in enumerate(valid_dataloader):\n",
        "            predictions = model(inputs, offsets)\n",
        "            loss = criterion(predictions, labels)\n",
        "            losses.append(loss)\n",
        "            total_acc += (predictions.argmax(1) == labels).sum().item()\n",
        "            total_count += labels.size(0)\n",
        "\n",
        "    epoch_acc = total_acc / total_count\n",
        "    epoch_loss = sum(losses) / len(losses)\n",
        "    return epoch_acc, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "8SrvGy7IrkrN"
      },
      "outputs": [],
      "source": [
        "eval_acc, eval_loss = evaluate(model, criterion, valid_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "uXhewV1WrkrN",
        "outputId": "46851bf5-d939-4a2f-81a0-0117f5bde952"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.5119, tensor(0.6939))"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_acc, eval_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn8cMmQwrkrN"
      },
      "source": [
        "##**6. Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wiGb67FrkrN",
        "outputId": "e7e25301-b9b8-43f1-fc16-55ba3dfc463f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |    50/  233 batches | accuracy    0.545\n",
            "| epoch   1 |   100/  233 batches | accuracy    0.636\n",
            "| epoch   1 |   150/  233 batches | accuracy    0.714\n",
            "| epoch   1 |   200/  233 batches | accuracy    0.759\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   1 | Time:  1.51s | Train Accuracy    0.769 | Train Loss    0.569 | Valid Accuracy    0.792 | Valid Loss    0.464 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |    50/  233 batches | accuracy    0.790\n",
            "| epoch   2 |   100/  233 batches | accuracy    0.796\n",
            "| epoch   2 |   150/  233 batches | accuracy    0.811\n",
            "| epoch   2 |   200/  233 batches | accuracy    0.809\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   2 | Time:  1.45s | Train Accuracy    0.830 | Train Loss    0.433 | Valid Accuracy    0.834 | Valid Loss    0.400 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |    50/  233 batches | accuracy    0.829\n",
            "| epoch   3 |   100/  233 batches | accuracy    0.837\n",
            "| epoch   3 |   150/  233 batches | accuracy    0.843\n",
            "| epoch   3 |   200/  233 batches | accuracy    0.844\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   3 | Time:  1.50s | Train Accuracy    0.851 | Train Loss    0.377 | Valid Accuracy    0.843 | Valid Loss    0.383 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |    50/  233 batches | accuracy    0.851\n",
            "| epoch   4 |   100/  233 batches | accuracy    0.852\n",
            "| epoch   4 |   150/  233 batches | accuracy    0.859\n",
            "| epoch   4 |   200/  233 batches | accuracy    0.855\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   4 | Time:  1.50s | Train Accuracy    0.851 | Train Loss    0.351 | Valid Accuracy    0.851 | Valid Loss    0.371 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |    50/  233 batches | accuracy    0.856\n",
            "| epoch   5 |   100/  233 batches | accuracy    0.862\n",
            "| epoch   5 |   150/  233 batches | accuracy    0.867\n",
            "| epoch   5 |   200/  233 batches | accuracy    0.863\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   5 | Time:  1.41s | Train Accuracy    0.856 | Train Loss    0.331 | Valid Accuracy    0.858 | Valid Loss    0.349 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |    50/  233 batches | accuracy    0.872\n",
            "| epoch   6 |   100/  233 batches | accuracy    0.873\n",
            "| epoch   6 |   150/  233 batches | accuracy    0.872\n",
            "| epoch   6 |   200/  233 batches | accuracy    0.866\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   6 | Time:  1.43s | Train Accuracy    0.869 | Train Loss    0.317 | Valid Accuracy    0.866 | Valid Loss    0.328 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |    50/  233 batches | accuracy    0.885\n",
            "| epoch   7 |   100/  233 batches | accuracy    0.877\n",
            "| epoch   7 |   150/  233 batches | accuracy    0.868\n",
            "| epoch   7 |   200/  233 batches | accuracy    0.871\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   7 | Time:  1.43s | Train Accuracy    0.883 | Train Loss    0.304 | Valid Accuracy    0.860 | Valid Loss    0.348 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |    50/  233 batches | accuracy    0.878\n",
            "| epoch   8 |   100/  233 batches | accuracy    0.875\n",
            "| epoch   8 |   150/  233 batches | accuracy    0.881\n",
            "| epoch   8 |   200/  233 batches | accuracy    0.883\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   8 | Time:  1.43s | Train Accuracy    0.880 | Train Loss    0.297 | Valid Accuracy    0.869 | Valid Loss    0.327 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |    50/  233 batches | accuracy    0.884\n",
            "| epoch   9 |   100/  233 batches | accuracy    0.881\n",
            "| epoch   9 |   150/  233 batches | accuracy    0.885\n",
            "| epoch   9 |   200/  233 batches | accuracy    0.878\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   9 | Time:  1.46s | Train Accuracy    0.883 | Train Loss    0.287 | Valid Accuracy    0.867 | Valid Loss    0.333 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |    50/  233 batches | accuracy    0.881\n",
            "| epoch  10 |   100/  233 batches | accuracy    0.888\n",
            "| epoch  10 |   150/  233 batches | accuracy    0.887\n",
            "| epoch  10 |   200/  233 batches | accuracy    0.888\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  10 | Time:  1.43s | Train Accuracy    0.887 | Train Loss    0.279 | Valid Accuracy    0.859 | Valid Loss    0.332 \n",
            "-----------------------------------------------------------\n",
            "| epoch  11 |    50/  233 batches | accuracy    0.889\n",
            "| epoch  11 |   100/  233 batches | accuracy    0.896\n",
            "| epoch  11 |   150/  233 batches | accuracy    0.880\n",
            "| epoch  11 |   200/  233 batches | accuracy    0.886\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  11 | Time:  1.41s | Train Accuracy    0.891 | Train Loss    0.273 | Valid Accuracy    0.864 | Valid Loss    0.332 \n",
            "-----------------------------------------------------------\n",
            "| epoch  12 |    50/  233 batches | accuracy    0.891\n",
            "| epoch  12 |   100/  233 batches | accuracy    0.900\n",
            "| epoch  12 |   150/  233 batches | accuracy    0.892\n",
            "| epoch  12 |   200/  233 batches | accuracy    0.887\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  12 | Time:  1.42s | Train Accuracy    0.890 | Train Loss    0.267 | Valid Accuracy    0.865 | Valid Loss    0.327 \n",
            "-----------------------------------------------------------\n",
            "| epoch  13 |    50/  233 batches | accuracy    0.891\n",
            "| epoch  13 |   100/  233 batches | accuracy    0.888\n",
            "| epoch  13 |   150/  233 batches | accuracy    0.889\n",
            "| epoch  13 |   200/  233 batches | accuracy    0.899\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  13 | Time:  1.45s | Train Accuracy    0.905 | Train Loss    0.261 | Valid Accuracy    0.872 | Valid Loss    0.337 \n",
            "-----------------------------------------------------------\n",
            "| epoch  14 |    50/  233 batches | accuracy    0.900\n",
            "| epoch  14 |   100/  233 batches | accuracy    0.892\n",
            "| epoch  14 |   150/  233 batches | accuracy    0.896\n",
            "| epoch  14 |   200/  233 batches | accuracy    0.895\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  14 | Time:  1.43s | Train Accuracy    0.890 | Train Loss    0.257 | Valid Accuracy    0.867 | Valid Loss    0.324 \n",
            "-----------------------------------------------------------\n",
            "| epoch  15 |    50/  233 batches | accuracy    0.898\n",
            "| epoch  15 |   100/  233 batches | accuracy    0.897\n",
            "| epoch  15 |   150/  233 batches | accuracy    0.900\n",
            "| epoch  15 |   200/  233 batches | accuracy    0.907\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  15 | Time:  1.46s | Train Accuracy    0.896 | Train Loss    0.250 | Valid Accuracy    0.872 | Valid Loss    0.340 \n",
            "-----------------------------------------------------------\n",
            "| epoch  16 |    50/  233 batches | accuracy    0.904\n",
            "| epoch  16 |   100/  233 batches | accuracy    0.902\n",
            "| epoch  16 |   150/  233 batches | accuracy    0.902\n",
            "| epoch  16 |   200/  233 batches | accuracy    0.900\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  16 | Time:  1.43s | Train Accuracy    0.903 | Train Loss    0.244 | Valid Accuracy    0.873 | Valid Loss    0.358 \n",
            "-----------------------------------------------------------\n",
            "| epoch  17 |    50/  233 batches | accuracy    0.902\n",
            "| epoch  17 |   100/  233 batches | accuracy    0.898\n",
            "| epoch  17 |   150/  233 batches | accuracy    0.902\n",
            "| epoch  17 |   200/  233 batches | accuracy    0.907\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  17 | Time:  1.46s | Train Accuracy    0.906 | Train Loss    0.241 | Valid Accuracy    0.874 | Valid Loss    0.326 \n",
            "-----------------------------------------------------------\n",
            "| epoch  18 |    50/  233 batches | accuracy    0.905\n",
            "| epoch  18 |   100/  233 batches | accuracy    0.906\n",
            "| epoch  18 |   150/  233 batches | accuracy    0.907\n",
            "| epoch  18 |   200/  233 batches | accuracy    0.906\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  18 | Time:  1.45s | Train Accuracy    0.905 | Train Loss    0.235 | Valid Accuracy    0.875 | Valid Loss    0.308 \n",
            "-----------------------------------------------------------\n",
            "| epoch  19 |    50/  233 batches | accuracy    0.909\n",
            "| epoch  19 |   100/  233 batches | accuracy    0.910\n",
            "| epoch  19 |   150/  233 batches | accuracy    0.902\n",
            "| epoch  19 |   200/  233 batches | accuracy    0.907\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  19 | Time:  1.41s | Train Accuracy    0.909 | Train Loss    0.231 | Valid Accuracy    0.875 | Valid Loss    0.318 \n",
            "-----------------------------------------------------------\n",
            "| epoch  20 |    50/  233 batches | accuracy    0.916\n",
            "| epoch  20 |   100/  233 batches | accuracy    0.907\n",
            "| epoch  20 |   150/  233 batches | accuracy    0.910\n",
            "| epoch  20 |   200/  233 batches | accuracy    0.907\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  20 | Time:  1.44s | Train Accuracy    0.906 | Train Loss    0.226 | Valid Accuracy    0.876 | Valid Loss    0.317 \n",
            "-----------------------------------------------------------\n",
            "| epoch  21 |    50/  233 batches | accuracy    0.914\n",
            "| epoch  21 |   100/  233 batches | accuracy    0.911\n",
            "| epoch  21 |   150/  233 batches | accuracy    0.913\n",
            "| epoch  21 |   200/  233 batches | accuracy    0.910\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  21 | Time:  1.44s | Train Accuracy    0.909 | Train Loss    0.221 | Valid Accuracy    0.850 | Valid Loss    0.384 \n",
            "-----------------------------------------------------------\n",
            "| epoch  22 |    50/  233 batches | accuracy    0.908\n",
            "| epoch  22 |   100/  233 batches | accuracy    0.923\n",
            "| epoch  22 |   150/  233 batches | accuracy    0.914\n",
            "| epoch  22 |   200/  233 batches | accuracy    0.913\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  22 | Time:  1.44s | Train Accuracy    0.907 | Train Loss    0.217 | Valid Accuracy    0.876 | Valid Loss    0.330 \n",
            "-----------------------------------------------------------\n",
            "| epoch  23 |    50/  233 batches | accuracy    0.919\n",
            "| epoch  23 |   100/  233 batches | accuracy    0.910\n",
            "| epoch  23 |   150/  233 batches | accuracy    0.912\n",
            "| epoch  23 |   200/  233 batches | accuracy    0.917\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  23 | Time:  1.44s | Train Accuracy    0.923 | Train Loss    0.212 | Valid Accuracy    0.873 | Valid Loss    0.340 \n",
            "-----------------------------------------------------------\n",
            "| epoch  24 |    50/  233 batches | accuracy    0.919\n",
            "| epoch  24 |   100/  233 batches | accuracy    0.915\n",
            "| epoch  24 |   150/  233 batches | accuracy    0.911\n",
            "| epoch  24 |   200/  233 batches | accuracy    0.920\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  24 | Time:  1.45s | Train Accuracy    0.918 | Train Loss    0.209 | Valid Accuracy    0.858 | Valid Loss    0.358 \n",
            "-----------------------------------------------------------\n",
            "| epoch  25 |    50/  233 batches | accuracy    0.922\n",
            "| epoch  25 |   100/  233 batches | accuracy    0.918\n",
            "| epoch  25 |   150/  233 batches | accuracy    0.919\n",
            "| epoch  25 |   200/  233 batches | accuracy    0.917\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  25 | Time:  1.45s | Train Accuracy    0.918 | Train Loss    0.203 | Valid Accuracy    0.866 | Valid Loss    0.365 \n",
            "-----------------------------------------------------------\n",
            "| epoch  26 |    50/  233 batches | accuracy    0.921\n",
            "| epoch  26 |   100/  233 batches | accuracy    0.924\n",
            "| epoch  26 |   150/  233 batches | accuracy    0.916\n",
            "| epoch  26 |   200/  233 batches | accuracy    0.924\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  26 | Time:  1.45s | Train Accuracy    0.918 | Train Loss    0.197 | Valid Accuracy    0.868 | Valid Loss    0.350 \n",
            "-----------------------------------------------------------\n",
            "| epoch  27 |    50/  233 batches | accuracy    0.928\n",
            "| epoch  27 |   100/  233 batches | accuracy    0.924\n",
            "| epoch  27 |   150/  233 batches | accuracy    0.919\n",
            "| epoch  27 |   200/  233 batches | accuracy    0.922\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  27 | Time:  1.45s | Train Accuracy    0.924 | Train Loss    0.194 | Valid Accuracy    0.871 | Valid Loss    0.359 \n",
            "-----------------------------------------------------------\n",
            "| epoch  28 |    50/  233 batches | accuracy    0.930\n",
            "| epoch  28 |   100/  233 batches | accuracy    0.928\n",
            "| epoch  28 |   150/  233 batches | accuracy    0.922\n",
            "| epoch  28 |   200/  233 batches | accuracy    0.928\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  28 | Time:  1.43s | Train Accuracy    0.925 | Train Loss    0.185 | Valid Accuracy    0.873 | Valid Loss    0.342 \n",
            "-----------------------------------------------------------\n",
            "| epoch  29 |    50/  233 batches | accuracy    0.933\n",
            "| epoch  29 |   100/  233 batches | accuracy    0.929\n",
            "| epoch  29 |   150/  233 batches | accuracy    0.932\n",
            "| epoch  29 |   200/  233 batches | accuracy    0.925\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  29 | Time:  1.42s | Train Accuracy    0.929 | Train Loss    0.183 | Valid Accuracy    0.850 | Valid Loss    0.431 \n",
            "-----------------------------------------------------------\n",
            "| epoch  30 |    50/  233 batches | accuracy    0.934\n",
            "| epoch  30 |   100/  233 batches | accuracy    0.934\n",
            "| epoch  30 |   150/  233 batches | accuracy    0.928\n",
            "| epoch  30 |   200/  233 batches | accuracy    0.931\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  30 | Time:  1.42s | Train Accuracy    0.930 | Train Loss    0.175 | Valid Accuracy    0.860 | Valid Loss    0.386 \n",
            "-----------------------------------------------------------\n",
            "| epoch  31 |    50/  233 batches | accuracy    0.932\n",
            "| epoch  31 |   100/  233 batches | accuracy    0.936\n",
            "| epoch  31 |   150/  233 batches | accuracy    0.935\n",
            "| epoch  31 |   200/  233 batches | accuracy    0.927\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  31 | Time:  1.46s | Train Accuracy    0.934 | Train Loss    0.173 | Valid Accuracy    0.869 | Valid Loss    0.359 \n",
            "-----------------------------------------------------------\n",
            "| epoch  32 |    50/  233 batches | accuracy    0.938\n",
            "| epoch  32 |   100/  233 batches | accuracy    0.936\n",
            "| epoch  32 |   150/  233 batches | accuracy    0.935\n",
            "| epoch  32 |   200/  233 batches | accuracy    0.932\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  32 | Time:  1.41s | Train Accuracy    0.930 | Train Loss    0.166 | Valid Accuracy    0.873 | Valid Loss    0.369 \n",
            "-----------------------------------------------------------\n",
            "| epoch  33 |    50/  233 batches | accuracy    0.938\n",
            "| epoch  33 |   100/  233 batches | accuracy    0.939\n",
            "| epoch  33 |   150/  233 batches | accuracy    0.939\n",
            "| epoch  33 |   200/  233 batches | accuracy    0.938\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  33 | Time:  1.45s | Train Accuracy    0.935 | Train Loss    0.160 | Valid Accuracy    0.865 | Valid Loss    0.400 \n",
            "-----------------------------------------------------------\n",
            "| epoch  34 |    50/  233 batches | accuracy    0.938\n",
            "| epoch  34 |   100/  233 batches | accuracy    0.942\n",
            "| epoch  34 |   150/  233 batches | accuracy    0.936\n",
            "| epoch  34 |   200/  233 batches | accuracy    0.936\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  34 | Time:  1.44s | Train Accuracy    0.940 | Train Loss    0.157 | Valid Accuracy    0.853 | Valid Loss    0.407 \n",
            "-----------------------------------------------------------\n",
            "| epoch  35 |    50/  233 batches | accuracy    0.946\n",
            "| epoch  35 |   100/  233 batches | accuracy    0.939\n",
            "| epoch  35 |   150/  233 batches | accuracy    0.941\n",
            "| epoch  35 |   200/  233 batches | accuracy    0.942\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  35 | Time:  1.46s | Train Accuracy    0.941 | Train Loss    0.149 | Valid Accuracy    0.854 | Valid Loss    0.500 \n",
            "-----------------------------------------------------------\n",
            "| epoch  36 |    50/  233 batches | accuracy    0.946\n",
            "| epoch  36 |   100/  233 batches | accuracy    0.943\n",
            "| epoch  36 |   150/  233 batches | accuracy    0.946\n",
            "| epoch  36 |   200/  233 batches | accuracy    0.942\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  36 | Time:  1.47s | Train Accuracy    0.942 | Train Loss    0.145 | Valid Accuracy    0.867 | Valid Loss    0.441 \n",
            "-----------------------------------------------------------\n",
            "| epoch  37 |    50/  233 batches | accuracy    0.946\n",
            "| epoch  37 |   100/  233 batches | accuracy    0.948\n",
            "| epoch  37 |   150/  233 batches | accuracy    0.948\n",
            "| epoch  37 |   200/  233 batches | accuracy    0.951\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  37 | Time:  1.45s | Train Accuracy    0.949 | Train Loss    0.138 | Valid Accuracy    0.869 | Valid Loss    0.427 \n",
            "-----------------------------------------------------------\n",
            "| epoch  38 |    50/  233 batches | accuracy    0.953\n",
            "| epoch  38 |   100/  233 batches | accuracy    0.949\n",
            "| epoch  38 |   150/  233 batches | accuracy    0.950\n",
            "| epoch  38 |   200/  233 batches | accuracy    0.946\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  38 | Time:  1.46s | Train Accuracy    0.949 | Train Loss    0.133 | Valid Accuracy    0.864 | Valid Loss    0.445 \n",
            "-----------------------------------------------------------\n",
            "| epoch  39 |    50/  233 batches | accuracy    0.959\n",
            "| epoch  39 |   100/  233 batches | accuracy    0.950\n",
            "| epoch  39 |   150/  233 batches | accuracy    0.950\n",
            "| epoch  39 |   200/  233 batches | accuracy    0.950\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  39 | Time:  1.45s | Train Accuracy    0.952 | Train Loss    0.129 | Valid Accuracy    0.862 | Valid Loss    0.440 \n",
            "-----------------------------------------------------------\n",
            "| epoch  40 |    50/  233 batches | accuracy    0.956\n",
            "| epoch  40 |   100/  233 batches | accuracy    0.955\n",
            "| epoch  40 |   150/  233 batches | accuracy    0.952\n",
            "| epoch  40 |   200/  233 batches | accuracy    0.954\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  40 | Time:  1.46s | Train Accuracy    0.951 | Train Loss    0.124 | Valid Accuracy    0.868 | Valid Loss    0.461 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "num_class = len(set(train_df_vi['label']))\n",
        "vocab_size = len(vocabulary)\n",
        "embed_dim = 100\n",
        "model = TextClassificationModel(vocab_size, embed_dim, num_class).to(device)\n",
        "\n",
        "learning_rate = 3\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "num_epochs = 40\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    epoch_start_time = time.time()\n",
        "    train_acc, train_loss = train(model, optimizer, criterion, train_dataloader, epoch)\n",
        "    eval_acc, eval_loss = evaluate(model, criterion, valid_dataloader)\n",
        "    print(\"-\" * 59)\n",
        "    print(\n",
        "        \"| End of epoch {:3d} | Time: {:5.2f}s | Train Accuracy {:8.3f} | Train Loss {:8.3f} \"\n",
        "        \"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f} \".format(\n",
        "            epoch, time.time() - epoch_start_time, train_acc, train_loss, eval_acc, eval_loss\n",
        "        )\n",
        "    )\n",
        "    print(\"-\" * 59)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az6L8nW_rkrN"
      },
      "source": [
        "##**7. Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "9LrFrUplrkrN"
      },
      "outputs": [],
      "source": [
        "model = model.to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "x3A8X6bfrkrN"
      },
      "outputs": [],
      "source": [
        "def predict(text):\n",
        "    with torch.no_grad():\n",
        "        encoded = torch.tensor(vocabulary(tokenizer(text)))\n",
        "        output = model(encoded, torch.tensor([0]))\n",
        "        return output.argmax(1).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "sieLwBLtrkrN",
        "outputId": "e850d83a-dde0-4e6a-8d94-79375635f7ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentence               Qu√°n n√†y kh√° l√† n·ªïi_ti·∫øng nay m·ªõi c√≥ d·ªãp gh√© t...\n",
              "label                                                                  0\n",
              "preprocess_sentence    qu√°n n√†y kh√° l√† n·ªïi ti·∫øng nay m·ªõi c√≥ d·ªãp gh√© t...\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "t5fgiU4arkrO",
        "outputId": "559ece3f-ce12-4365-a25b-9452b8912c60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(test_df.iloc[0]['sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNLaRMtnrkrO",
        "outputId": "babfff75-bb94-4fca-9a7f-384ed1684ab7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.8639)"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# compute accuracy on test set\n",
        "\n",
        "predictions, labels = [], []\n",
        "for index, row in test_df.iterrows():\n",
        "    sentence = row['preprocess_sentence']\n",
        "    label = row['label']\n",
        "    prediction = predict(sentence)\n",
        "    predictions.append(prediction)\n",
        "    labels.append(label)\n",
        "\n",
        "sum(torch.tensor(predictions) == torch.tensor(labels))/len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv7NgrpJ5N9m"
      },
      "source": [
        "##**8. Compare: BoW, TF-IDF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Yu4LaR7UrK"
      },
      "source": [
        "###**8.1. BoW**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "hstpLbj154hI"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "4h6mAAFg52j2"
      },
      "outputs": [],
      "source": [
        "train_labels = np.array(train_df_vi['label'].tolist())\n",
        "test_labels = np.array(test_df['label'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjIDlF505UuU",
        "outputId": "4a946797-da0a-472f-fbe6-adadf7faa447"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15000"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "max_features = 15000\n",
        "vectorizer = CountVectorizer(max_features=max_features)\n",
        "\n",
        "train_sequences = vectorizer.fit_transform(train_df_vi['preprocess_sentence'])\n",
        "test_sequences = vectorizer.transform(test_df['preprocess_sentence'])\n",
        "vocab_size = len(vectorizer.vocabulary_)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "y2Ced26q5lTA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\cang_\\miniconda3\\envs\\yolo\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(train_sequences, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzF_IBu_6tLl",
        "outputId": "3b3f188c-ec00-451c-d947-33f630efd176"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8774"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logreg.score(test_sequences, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL16oFDP7Y6w"
      },
      "source": [
        "###**8.2. TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "o5LTXakq7cZ0"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "max_features = 10000\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=max_features)\n",
        "\n",
        "train_sequences = tfidf_vectorizer.fit_transform(train_df_vi['preprocess_sentence'])\n",
        "test_sequences = tfidf_vectorizer.transform(test_df['preprocess_sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "pB4Ah2Ht8t0f",
        "outputId": "5d2102cf-6836-4cb1-efcc-71ddbd84f24f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(train_sequences, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F5bLVb69NfT",
        "outputId": "ee1c164d-1eb5-46bd-e1c6-cfa7f9dc101d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8822"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logreg.score(test_sequences, test_labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
